{
  "id": "20260219_100125",
  "timestamp": "2026-02-19T10:01:25.206294",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26200-SP0",
      "python_version": "3.11.9"
    },
    "cpu": {
      "physical_cores": 12,
      "logical_cores": 24,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier sp√©cifi√© est introuvable",
      "model": "AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 3701.0,
        "min": null,
        "max": 3701.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "NVIDIA",
          "name": "NVIDIA GeForce RTX 4070",
          "vram_total_mb": 12282.0,
          "vram_free_mb": 10452.0,
          "driver_version": "591.74",
          "compute_capability": "8.9",
          "backend": "cuda",
          "device_index": 0,
          "gpu_index": 0
        }
      ],
      "backends": [
        "cuda",
        "cpu"
      ],
      "primary_backend": "cuda",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.5.1+cu121",
        "pytorch_cuda": true,
        "pytorch_cuda_version": "12.1",
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": true,
        "llama_cpp_version": "0.3.4",
        "llama_server": false,
        "pytorch_rocm": false,
        "ipex": false,
        "directml": false
      }
    },
    "ram": {
      "total_gb": 63.93,
      "available_gb": 50.11,
      "used_gb": 13.81,
      "percent_used": 21.6,
      "swap_total_gb": 4.0,
      "swap_used_gb": 0.0,
      "unified_memory": false
    },
    "selected_gpu": {
      "gpu_index": 0,
      "name": "NVIDIA GeForce RTX 4070",
      "backend": "cuda"
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 9.94,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread, subprocess isol√©)",
        "results": {
          "512x512": {
            "times_s": [
              0.0022,
              0.0022,
              0.0022
            ],
            "mean_s": 0.0022,
            "median_s": 0.0022,
            "std_s": 0.0,
            "gflops": 122.26
          },
          "1024x1024": {
            "times_s": [
              0.0165,
              0.0174,
              0.0177
            ],
            "mean_s": 0.0172,
            "median_s": 0.0174,
            "std_s": 0.0005,
            "gflops": 123.62
          },
          "2048x2048": {
            "times_s": [
              0.1255,
              0.1269,
              0.1247
            ],
            "mean_s": 0.1257,
            "median_s": 0.1255,
            "std_s": 0.0009,
            "gflops": 136.93
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 24 threads, subprocess isol√©)",
        "n_threads": 24,
        "results": {
          "512x512": {
            "times_s": [
              0.0011,
              0.0009,
              0.0009
            ],
            "mean_s": 0.001,
            "median_s": 0.0009,
            "std_s": 0.0001,
            "gflops": 289.14
          },
          "1024x1024": {
            "times_s": [
              0.0045,
              0.0052,
              0.0053
            ],
            "mean_s": 0.005,
            "median_s": 0.0052,
            "std_s": 0.0004,
            "gflops": 415.03
          },
          "2048x2048": {
            "times_s": [
              0.0214,
              0.0227,
              0.022
            ],
            "mean_s": 0.022,
            "median_s": 0.022,
            "std_s": 0.0005,
            "gflops": 779.87
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0398,
            "median_s": 0.0394,
            "bandwidth_gb_s": 6.34
          },
          "read": {
            "mean_s": 0.0346,
            "median_s": 0.0344,
            "bandwidth_gb_s": 7.27
          },
          "copy": {
            "mean_s": 0.0442,
            "median_s": 0.044,
            "bandwidth_gb_s": 5.68
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute (Raw)",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 4070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "times_s": [
              0.0008,
              0.0009,
              0.0009
            ],
            "mean_s": 0.0009,
            "median_s": 0.0009,
            "gflops": 2461.3
          },
          "2048x2048": {
            "times_s": [
              0.0085,
              0.0073,
              0.0084
            ],
            "mean_s": 0.008,
            "median_s": 0.0084,
            "gflops": 2049.74
          },
          "4096x4096": {
            "times_s": [
              0.0511,
              0.0068,
              0.0072
            ],
            "mean_s": 0.0217,
            "median_s": 0.0072,
            "gflops": 19113.96
          }
        }
      },
      "gpu_system": {
        "test": "GPU System Score",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 4070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "pipeline_times_s": [
              0.0012,
              0.0013,
              0.0012
            ],
            "pipeline_median_s": 0.0012,
            "transfer_to_median_s": 0.0006,
            "compute_median_s": 0.0002,
            "transfer_back_median_s": 0.0004,
            "gflops_pipeline": 1793.31,
            "gflops_compute": 9068.77,
            "transfer_bandwidth_gb_s": 12.01,
            "data_transferred_gb": 0.0117,
            "pct_transfer_to": 49.8,
            "pct_compute": 19.8,
            "pct_transfer_back": 31.7
          },
          "2048x2048": {
            "pipeline_times_s": [
              0.0064,
              0.006,
              0.0062
            ],
            "pipeline_median_s": 0.0062,
            "transfer_to_median_s": 0.0034,
            "compute_median_s": 0.0011,
            "transfer_back_median_s": 0.0015,
            "gflops_pipeline": 2763.99,
            "gflops_compute": 15548.8,
            "transfer_bandwidth_gb_s": 9.66,
            "data_transferred_gb": 0.0469,
            "pct_transfer_to": 54.0,
            "pct_compute": 17.8,
            "pct_transfer_back": 24.1
          },
          "4096x4096": {
            "pipeline_times_s": [
              0.0307,
              0.04,
              0.041
            ],
            "pipeline_median_s": 0.04,
            "transfer_to_median_s": 0.0111,
            "compute_median_s": 0.0163,
            "transfer_back_median_s": 0.0125,
            "gflops_pipeline": 3433.59,
            "gflops_compute": 8414.13,
            "transfer_bandwidth_gb_s": 7.96,
            "data_transferred_gb": 0.1875,
            "pct_transfer_to": 27.6,
            "pct_compute": 40.8,
            "pct_transfer_back": 31.2
          }
        }
      }
    },
    "resource_usage": {
      "n_samples": 18,
      "duration_s": 9.395074367523193,
      "cpu": {
        "avg_percent": 6.8,
        "max_percent": 18.0,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 22.1,
        "max_percent": 22.5,
        "peak_used_gb": 14.39
      },
      "gpu": {
        "avg_utilization_percent": 3.3,
        "max_utilization_percent": 21.0,
        "peak_memory_mb": 2025.0,
        "max_temperature_c": 38.0
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 2,
      "n_benchmark_runs": 3
    },
    "total_time_s": 106.95,
    "models_tested": 1,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 0.6032,
            "first_token_latency_s": 0.0059,
            "tokens_per_second": 424.44,
            "memory_before_gb": 1.787,
            "memory_after_gb": 1.787,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 0.932,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.34,
            "p90_inter_token_latency_ms": 2.39
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.6427,
            "first_token_latency_s": 0.0182,
            "tokens_per_second": 398.32,
            "memory_before_gb": 1.787,
            "memory_after_gb": 1.794,
            "memory_delta_gb": 0.007,
            "server_memory_gb": 0.939,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.45,
            "p90_inter_token_latency_ms": 2.75
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.6734,
            "first_token_latency_s": 0.0286,
            "tokens_per_second": 380.16,
            "memory_before_gb": 1.794,
            "memory_after_gb": 1.794,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 0.939,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.53,
            "p90_inter_token_latency_ms": 2.83
          }
        ],
        "model_load_time_s": 3.03,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 4,
          "duration_s": 1.6870393753051758,
          "cpu": {
            "avg_percent": 9.8,
            "max_percent": 16.5,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 24.0,
            "max_percent": 24.0,
            "peak_used_gb": 15.36
          },
          "gpu": {
            "avg_utilization_percent": 61.8,
            "max_utilization_percent": 84.0,
            "peak_memory_mb": 2707.0,
            "max_temperature_c": 49.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 400.97,
          "std_tokens_per_second": 18.17,
          "avg_first_token_latency_s": 0.0176,
          "avg_total_time_s": 0.6398,
          "peak_memory_gb": 1.794,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6672,
                "first_token_latency_s": 0.0302,
                "tokens_per_second": 383.71,
                "memory_before_gb": 1.63,
                "memory_after_gb": 1.63,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.775,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6784,
                "first_token_latency_s": 0.0235,
                "tokens_per_second": 377.38,
                "memory_before_gb": 1.63,
                "memory_after_gb": 1.637,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.781,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.57,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6506,
                "first_token_latency_s": 0.0172,
                "tokens_per_second": 393.48,
                "memory_before_gb": 1.637,
                "memory_after_gb": 1.637,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.781,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.75
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 0.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.603,
            "server_memory_after_load_gb": 0.747,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.662365436553955,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 14.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.6,
                "max_percent": 23.7,
                "peak_used_gb": 15.18
              },
              "gpu": {
                "avg_utilization_percent": 75.8,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2549.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 384.86,
              "std_tokens_per_second": 6.62,
              "min_tokens_per_second": 377.38,
              "max_tokens_per_second": 393.48,
              "avg_first_token_latency_s": 0.0236,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6654,
              "peak_memory_gb": 1.637,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6333,
                "first_token_latency_s": 0.0055,
                "tokens_per_second": 404.22,
                "memory_before_gb": 1.693,
                "memory_after_gb": 1.693,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.838,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.46,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6558,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 390.39,
                "memory_before_gb": 1.693,
                "memory_after_gb": 1.7,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.844,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6803,
                "first_token_latency_s": 0.0191,
                "tokens_per_second": 376.28,
                "memory_before_gb": 1.7,
                "memory_after_gb": 1.7,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.844,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.59,
                "p90_inter_token_latency_ms": 2.83
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.66,
            "server_memory_after_load_gb": 0.804,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6698992252349854,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 11.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.7,
                "max_percent": 23.7,
                "peak_used_gb": 15.15
              },
              "gpu": {
                "avg_utilization_percent": 80.0,
                "max_utilization_percent": 86.0,
                "peak_memory_mb": 2570.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 390.3,
              "std_tokens_per_second": 11.41,
              "min_tokens_per_second": 376.28,
              "max_tokens_per_second": 404.22,
              "avg_first_token_latency_s": 0.0157,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6565,
              "peak_memory_gb": 1.7,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.64,
                "first_token_latency_s": 0.0288,
                "tokens_per_second": 399.98,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.787,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.4,
                "p90_inter_token_latency_ms": 2.6
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6523,
                "first_token_latency_s": 0.0318,
                "tokens_per_second": 392.45,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.43,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6598,
                "first_token_latency_s": 0.0195,
                "tokens_per_second": 388.01,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.74
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 1.55,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.761,
            "server_memory_after_load_gb": 0.905,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.665316104888916,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.8,
                "max_percent": 23.9,
                "peak_used_gb": 15.25
              },
              "gpu": {
                "avg_utilization_percent": 54.2,
                "max_utilization_percent": 84.0,
                "peak_memory_mb": 2672.0,
                "max_temperature_c": 52.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 393.48,
              "std_tokens_per_second": 4.94,
              "min_tokens_per_second": 388.01,
              "max_tokens_per_second": 399.98,
              "avg_first_token_latency_s": 0.0267,
              "avg_inter_token_latency_ms": 2.45,
              "avg_total_time_s": 0.6507,
              "peak_memory_gb": 1.794,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6809,
                "first_token_latency_s": 0.0057,
                "tokens_per_second": 375.97,
                "memory_before_gb": 1.886,
                "memory_after_gb": 1.886,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.031,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.65,
                "p90_inter_token_latency_ms": 2.89
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6882,
                "first_token_latency_s": 0.0082,
                "tokens_per_second": 372.0,
                "memory_before_gb": 1.886,
                "memory_after_gb": 1.893,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.037,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.67,
                "p90_inter_token_latency_ms": 2.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7212,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 354.95,
                "memory_before_gb": 1.893,
                "memory_after_gb": 1.893,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.037,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.74,
                "p90_inter_token_latency_ms": 2.96
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.86,
            "server_memory_after_load_gb": 1.004,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6731085777282715,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.35
              },
              "gpu": {
                "avg_utilization_percent": 61.0,
                "max_utilization_percent": 87.0,
                "peak_memory_mb": 2774.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 367.64,
              "std_tokens_per_second": 9.12,
              "min_tokens_per_second": 354.95,
              "max_tokens_per_second": 375.97,
              "avg_first_token_latency_s": 0.0122,
              "avg_inter_token_latency_ms": 2.69,
              "avg_total_time_s": 0.6968,
              "peak_memory_gb": 1.893,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7783,
                "first_token_latency_s": 0.0271,
                "tokens_per_second": 328.91,
                "memory_before_gb": 1.983,
                "memory_after_gb": 1.984,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.128,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.95,
                "p90_inter_token_latency_ms": 3.19
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8063,
                "first_token_latency_s": 0.0341,
                "tokens_per_second": 317.5,
                "memory_before_gb": 1.984,
                "memory_after_gb": 1.991,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.135,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.03,
                "p90_inter_token_latency_ms": 3.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.798,
                "first_token_latency_s": 0.0297,
                "tokens_per_second": 320.79,
                "memory_before_gb": 1.991,
                "memory_after_gb": 1.991,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.135,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.01,
                "p90_inter_token_latency_ms": 3.24
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 1.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.965,
            "server_memory_after_load_gb": 1.109,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2508931159973145,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.1,
                "max_percent": 24.2,
                "peak_used_gb": 15.45
              },
              "gpu": {
                "avg_utilization_percent": 68.8,
                "max_utilization_percent": 86.0,
                "peak_memory_mb": 2880.0,
                "max_temperature_c": 56.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 322.4,
              "std_tokens_per_second": 4.8,
              "min_tokens_per_second": 317.5,
              "max_tokens_per_second": 328.91,
              "avg_first_token_latency_s": 0.0303,
              "avg_inter_token_latency_ms": 3.0,
              "avg_total_time_s": 0.7942,
              "peak_memory_gb": 1.991,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.9108,
                "first_token_latency_s": 0.0266,
                "tokens_per_second": 281.08,
                "memory_before_gb": 2.216,
                "memory_after_gb": 2.216,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.361,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.47,
                "p90_inter_token_latency_ms": 3.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9365,
                "first_token_latency_s": 0.0205,
                "tokens_per_second": 273.36,
                "memory_before_gb": 2.216,
                "memory_after_gb": 2.223,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.368,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.59,
                "p90_inter_token_latency_ms": 4.0
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.925,
                "first_token_latency_s": 0.0163,
                "tokens_per_second": 276.77,
                "memory_before_gb": 2.223,
                "memory_after_gb": 2.223,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.368,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.56,
                "p90_inter_token_latency_ms": 4.0
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 1.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 2.198,
            "server_memory_after_load_gb": 1.343,
            "resource_usage": {
              "n_samples": 6,
              "duration_s": 2.773709774017334,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.5,
                "max_percent": 24.5,
                "peak_used_gb": 15.69
              },
              "gpu": {
                "avg_utilization_percent": 70.0,
                "max_utilization_percent": 87.0,
                "peak_memory_mb": 3119.0,
                "max_temperature_c": 54.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 277.07,
              "std_tokens_per_second": 3.16,
              "min_tokens_per_second": 273.36,
              "max_tokens_per_second": 281.08,
              "avg_first_token_latency_s": 0.0211,
              "avg_inter_token_latency_ms": 3.54,
              "avg_total_time_s": 0.9241,
              "peak_memory_gb": 2.223,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 384.86,
            "first_token_latency_s": 0.0236,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.637,
            "model_load_time_s": 0.54,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 390.3,
            "first_token_latency_s": 0.0157,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.7,
            "model_load_time_s": 1.56,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 393.48,
            "first_token_latency_s": 0.0267,
            "inter_token_latency_ms": 2.45,
            "peak_memory_gb": 1.794,
            "model_load_time_s": 1.55,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 367.64,
            "first_token_latency_s": 0.0122,
            "inter_token_latency_ms": 2.69,
            "peak_memory_gb": 1.893,
            "model_load_time_s": 1.56,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 322.4,
            "first_token_latency_s": 0.0303,
            "inter_token_latency_ms": 3.0,
            "peak_memory_gb": 1.991,
            "model_load_time_s": 1.58,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 277.07,
            "first_token_latency_s": 0.0211,
            "inter_token_latency_ms": 3.54,
            "peak_memory_gb": 2.223,
            "model_load_time_s": 1.58,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6336,
                "first_token_latency_s": 0.0169,
                "tokens_per_second": 404.05,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.787,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.42,
                "p90_inter_token_latency_ms": 2.64
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6479,
                "first_token_latency_s": 0.0257,
                "tokens_per_second": 395.12,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.44,
                "p90_inter_token_latency_ms": 2.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6629,
                "first_token_latency_s": 0.0199,
                "tokens_per_second": 386.17,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.73
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 395.11,
              "std_tokens_per_second": 7.3,
              "avg_first_token_latency_s": 0.0208,
              "avg_inter_token_latency_ms": 2.46,
              "avg_total_time_s": 0.6481,
              "peak_memory_gb": 1.794,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6697773933410645,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 16.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.29
              },
              "gpu": {
                "avg_utilization_percent": 74.8,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2678.0,
                "max_temperature_c": 56.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6743,
                "first_token_latency_s": 0.029,
                "tokens_per_second": 379.64,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.78
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6691,
                "first_token_latency_s": 0.0272,
                "tokens_per_second": 382.61,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.801,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.672,
                "first_token_latency_s": 0.029,
                "tokens_per_second": 380.97,
                "memory_before_gb": 1.801,
                "memory_after_gb": 1.801,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 381.07,
              "std_tokens_per_second": 1.21,
              "avg_first_token_latency_s": 0.0284,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6718,
              "peak_memory_gb": 1.801,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6489222049713135,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 11.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.29
              },
              "gpu": {
                "avg_utilization_percent": 81.8,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2678.0,
                "max_temperature_c": 57.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6706,
                "first_token_latency_s": 0.0288,
                "tokens_per_second": 381.72,
                "memory_before_gb": 1.801,
                "memory_after_gb": 1.802,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6614,
                "first_token_latency_s": 0.018,
                "tokens_per_second": 387.04,
                "memory_before_gb": 1.802,
                "memory_after_gb": 1.808,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.953,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6702,
                "first_token_latency_s": 0.0248,
                "tokens_per_second": 381.97,
                "memory_before_gb": 1.808,
                "memory_after_gb": 1.808,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.953,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.76
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 383.58,
              "std_tokens_per_second": 2.45,
              "avg_first_token_latency_s": 0.0239,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6674,
              "peak_memory_gb": 1.808,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6797208786010742,
              "cpu": {
                "avg_percent": 7.1,
                "max_percent": 10.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.29
              },
              "gpu": {
                "avg_utilization_percent": 81.5,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2677.0,
                "max_temperature_c": 58.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 395.11,
            "first_token_latency_s": 0.0208,
            "inter_token_latency_ms": 2.46,
            "peak_memory_gb": 1.794,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 381.07,
            "first_token_latency_s": 0.0284,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.801,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 383.58,
            "first_token_latency_s": 0.0239,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.808,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6236,
                "first_token_latency_s": 0.0052,
                "tokens_per_second": 410.5,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.787,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.42,
                "p90_inter_token_latency_ms": 2.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6352,
                "first_token_latency_s": 0.0209,
                "tokens_per_second": 403.04,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.41,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6457,
                "first_token_latency_s": 0.0266,
                "tokens_per_second": 396.48,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.43,
                "p90_inter_token_latency_ms": 2.64
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 403.34,
              "std_tokens_per_second": 5.73,
              "avg_first_token_latency_s": 0.0176,
              "avg_inter_token_latency_ms": 2.42,
              "avg_total_time_s": 0.6348,
              "peak_memory_gb": 1.794,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.678248405456543,
              "cpu": {
                "avg_percent": 8.7,
                "max_percent": 15.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.8,
                "max_percent": 23.9,
                "peak_used_gb": 15.26
              },
              "gpu": {
                "avg_utilization_percent": 69.8,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2670.0,
                "max_temperature_c": 58.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6523,
                "first_token_latency_s": 0.011,
                "tokens_per_second": 392.47,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.94,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6765,
                "first_token_latency_s": 0.0321,
                "tokens_per_second": 378.42,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.803,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.947,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6669,
                "first_token_latency_s": 0.0292,
                "tokens_per_second": 383.88,
                "memory_before_gb": 1.803,
                "memory_after_gb": 1.81,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.954,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.73
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 384.92,
              "std_tokens_per_second": 5.78,
              "avg_first_token_latency_s": 0.0241,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6652,
              "peak_memory_gb": 1.81,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.652052640914917,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.28
              },
              "gpu": {
                "avg_utilization_percent": 61.5,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2670.0,
                "max_temperature_c": 58.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6748,
                "first_token_latency_s": 0.0322,
                "tokens_per_second": 379.39,
                "memory_before_gb": 1.81,
                "memory_after_gb": 1.811,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.955,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6671,
                "first_token_latency_s": 0.0085,
                "tokens_per_second": 383.76,
                "memory_before_gb": 1.811,
                "memory_after_gb": 1.818,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.963,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.58,
                "p90_inter_token_latency_ms": 2.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6736,
                "first_token_latency_s": 0.0328,
                "tokens_per_second": 380.07,
                "memory_before_gb": 1.818,
                "memory_after_gb": 1.826,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.97,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.75
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 381.07,
              "std_tokens_per_second": 1.92,
              "avg_first_token_latency_s": 0.0245,
              "avg_inter_token_latency_ms": 2.54,
              "avg_total_time_s": 0.6718,
              "peak_memory_gb": 1.826,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.66749906539917,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 14.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.31
              },
              "gpu": {
                "avg_utilization_percent": 81.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2670.0,
                "max_temperature_c": 59.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6741,
                "first_token_latency_s": 0.0353,
                "tokens_per_second": 379.79,
                "memory_before_gb": 1.826,
                "memory_after_gb": 1.826,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.971,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6735,
                "first_token_latency_s": 0.0323,
                "tokens_per_second": 380.09,
                "memory_before_gb": 1.826,
                "memory_after_gb": 1.834,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.978,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6758,
                "first_token_latency_s": 0.0302,
                "tokens_per_second": 378.84,
                "memory_before_gb": 1.834,
                "memory_after_gb": 1.841,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.985,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 379.57,
              "std_tokens_per_second": 0.53,
              "avg_first_token_latency_s": 0.0326,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6745,
              "peak_memory_gb": 1.841,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.643301010131836,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 24.0,
                "peak_used_gb": 15.33
              },
              "gpu": {
                "avg_utilization_percent": 53.8,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2670.0,
                "max_temperature_c": 60.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6527,
                "first_token_latency_s": 0.0111,
                "tokens_per_second": 392.19,
                "memory_before_gb": 1.841,
                "memory_after_gb": 1.842,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6552,
                "first_token_latency_s": 0.0105,
                "tokens_per_second": 390.69,
                "memory_before_gb": 1.842,
                "memory_after_gb": 1.849,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.993,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6746,
                "first_token_latency_s": 0.0254,
                "tokens_per_second": 379.47,
                "memory_before_gb": 1.849,
                "memory_after_gb": 1.856,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.001,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.55,
                "p90_inter_token_latency_ms": 2.8
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 387.45,
              "std_tokens_per_second": 5.68,
              "avg_first_token_latency_s": 0.0157,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6608,
              "peak_memory_gb": 1.856,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6507627964019775,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 12.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.33
              },
              "gpu": {
                "avg_utilization_percent": 75.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2669.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.657,
                "first_token_latency_s": 0.0141,
                "tokens_per_second": 389.63,
                "memory_before_gb": 1.856,
                "memory_after_gb": 1.857,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.002,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6635,
                "first_token_latency_s": 0.0229,
                "tokens_per_second": 385.81,
                "memory_before_gb": 1.857,
                "memory_after_gb": 1.866,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 1.01,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6522,
                "first_token_latency_s": 0.0087,
                "tokens_per_second": 392.52,
                "memory_before_gb": 1.866,
                "memory_after_gb": 1.874,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.019,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 389.32,
              "std_tokens_per_second": 2.75,
              "avg_first_token_latency_s": 0.0152,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6576,
              "peak_memory_gb": 1.874,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6629412174224854,
              "cpu": {
                "avg_percent": 6.8,
                "max_percent": 10.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.35
              },
              "gpu": {
                "avg_utilization_percent": 64.8,
                "max_utilization_percent": 81.0,
                "peak_memory_mb": 2671.0,
                "max_temperature_c": 60.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "tokens_per_second": 403.34,
            "first_token_latency_s": 0.0176,
            "inter_token_latency_ms": 2.42,
            "peak_memory_gb": 1.794,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "tokens_per_second": 384.92,
            "first_token_latency_s": 0.0241,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.81,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "tokens_per_second": 381.07,
            "first_token_latency_s": 0.0245,
            "inter_token_latency_ms": 2.54,
            "peak_memory_gb": 1.826,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "tokens_per_second": 379.57,
            "first_token_latency_s": 0.0326,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.841,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "tokens_per_second": 387.45,
            "first_token_latency_s": 0.0157,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.856,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "tokens_per_second": 389.32,
            "first_token_latency_s": 0.0152,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.874,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6528,
                "first_token_latency_s": 0.0202,
                "tokens_per_second": 392.16,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.787,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6835,
                "first_token_latency_s": 0.0338,
                "tokens_per_second": 374.54,
                "memory_before_gb": 1.787,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.938,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.55,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6455,
                "first_token_latency_s": 0.0263,
                "tokens_per_second": 396.61,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.794,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.43,
                "p90_inter_token_latency_ms": 2.68
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 387.77,
              "std_tokens_per_second": 9.53,
              "avg_first_token_latency_s": 0.0268,
              "avg_inter_token_latency_ms": 2.49,
              "avg_total_time_s": 0.6606,
              "peak_memory_gb": 1.794,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.701807975769043,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 12.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.27
              },
              "gpu": {
                "avg_utilization_percent": 67.0,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2677.0,
                "max_temperature_c": 57.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6512,
                "first_token_latency_s": 0.012,
                "tokens_per_second": 393.11,
                "memory_before_gb": 1.794,
                "memory_after_gb": 1.796,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.94,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6661,
                "first_token_latency_s": 0.0258,
                "tokens_per_second": 384.35,
                "memory_before_gb": 1.796,
                "memory_after_gb": 1.803,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.947,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6645,
                "first_token_latency_s": 0.0216,
                "tokens_per_second": 385.23,
                "memory_before_gb": 1.803,
                "memory_after_gb": 1.81,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.955,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 387.56,
              "std_tokens_per_second": 3.94,
              "avg_first_token_latency_s": 0.0198,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6606,
              "peak_memory_gb": 1.81,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6917779445648193,
              "cpu": {
                "avg_percent": 6.6,
                "max_percent": 9.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.28
              },
              "gpu": {
                "avg_utilization_percent": 71.2,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2677.0,
                "max_temperature_c": 58.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6545,
                "first_token_latency_s": 0.0128,
                "tokens_per_second": 391.15,
                "memory_before_gb": 1.81,
                "memory_after_gb": 1.811,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.956,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6658,
                "first_token_latency_s": 0.0252,
                "tokens_per_second": 384.47,
                "memory_before_gb": 1.811,
                "memory_after_gb": 1.819,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.964,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6707,
                "first_token_latency_s": 0.0279,
                "tokens_per_second": 381.68,
                "memory_before_gb": 1.819,
                "memory_after_gb": 1.827,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.971,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 385.77,
              "std_tokens_per_second": 3.97,
              "avg_first_token_latency_s": 0.022,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6637,
              "peak_memory_gb": 1.827,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6352696418762207,
              "cpu": {
                "avg_percent": 9.4,
                "max_percent": 10.8,
                "min_percent": 8.1
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.33
              },
              "gpu": {
                "avg_utilization_percent": 81.8,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2679.0,
                "max_temperature_c": 58.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6625,
                "first_token_latency_s": 0.0116,
                "tokens_per_second": 386.4,
                "memory_before_gb": 1.827,
                "memory_after_gb": 1.827,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.972,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.55,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6758,
                "first_token_latency_s": 0.0331,
                "tokens_per_second": 378.82,
                "memory_before_gb": 1.827,
                "memory_after_gb": 1.835,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.979,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.662,
                "first_token_latency_s": 0.0205,
                "tokens_per_second": 386.69,
                "memory_before_gb": 1.835,
                "memory_after_gb": 1.842,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.74
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 383.97,
              "std_tokens_per_second": 3.64,
              "avg_first_token_latency_s": 0.0217,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6668,
              "peak_memory_gb": 1.842,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6674718856811523,
              "cpu": {
                "avg_percent": 9.9,
                "max_percent": 13.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.34
              },
              "gpu": {
                "avg_utilization_percent": 69.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2680.0,
                "max_temperature_c": 58.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6532,
                "first_token_latency_s": 0.0125,
                "tokens_per_second": 391.89,
                "memory_before_gb": 1.842,
                "memory_after_gb": 1.842,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6604,
                "first_token_latency_s": 0.0187,
                "tokens_per_second": 387.62,
                "memory_before_gb": 1.842,
                "memory_after_gb": 1.85,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.994,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6526,
                "first_token_latency_s": 0.0101,
                "tokens_per_second": 392.26,
                "memory_before_gb": 1.85,
                "memory_after_gb": 1.858,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.002,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.75
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 390.59,
              "std_tokens_per_second": 2.11,
              "avg_first_token_latency_s": 0.0138,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6554,
              "peak_memory_gb": 1.858,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6527326107025146,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.0,
                "max_percent": 24.0,
                "peak_used_gb": 15.33
              },
              "gpu": {
                "avg_utilization_percent": 81.2,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2679.0,
                "max_temperature_c": 58.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "tokens_per_second": 387.77,
            "first_token_latency_s": 0.0268,
            "inter_token_latency_ms": 2.49,
            "peak_memory_gb": 1.794,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "tokens_per_second": 387.56,
            "first_token_latency_s": 0.0198,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.81,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "tokens_per_second": 385.77,
            "first_token_latency_s": 0.022,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.827,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "tokens_per_second": 383.97,
            "first_token_latency_s": 0.0217,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.842,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "tokens_per_second": 390.59,
            "first_token_latency_s": 0.0138,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.858,
            "stability": "stable"
          }
        ]
      }
    }
  }
}