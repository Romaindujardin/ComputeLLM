{
  "id": "20260217_151007",
  "timestamp": "2026-02-17T15:10:07.401166",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26100",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26100-SP0",
      "python_version": "3.10.11"
    },
    "cpu": {
      "physical_cores": 4,
      "logical_cores": 8,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier sp√©cifi√© est introuvable",
      "model": "Intel64 Family 6 Model 140 Stepping 1, GenuineIntel",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 2419.0,
        "min": null,
        "max": 2419.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "Intel",
          "name": "Intel(R) Iris(R) Xe Graphics",
          "backend": "sycl",
          "detected_via": "pytorch_xpu",
          "vram_total_mb": 3273
        }
      ],
      "backends": [
        "sycl",
        "cpu"
      ],
      "primary_backend": "sycl",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.10.0+xpu",
        "pytorch_cuda": false,
        "pytorch_mps": false,
        "pytorch_xpu": true,
        "pytorch_xpu_device": "Intel(R) Iris(R) Xe Graphics",
        "llama_cpp": false,
        "llama_server": false,
        "ipex": false
      }
    },
    "ram": {
      "total_gb": 7.73,
      "available_gb": 0.75,
      "used_gb": 6.98,
      "percent_used": 90.2,
      "swap_total_gb": 14.5,
      "swap_used_gb": 3.61,
      "unified_memory": false
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 10.13,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread)",
        "results": {
          "512x512": {
            "times_s": [
              0.0057,
              0.0013,
              0.0013
            ],
            "mean_s": 0.0028,
            "std_s": 0.0021,
            "gflops": 96.61
          },
          "1024x1024": {
            "times_s": [
              0.0103,
              0.0114,
              0.0106
            ],
            "mean_s": 0.0108,
            "std_s": 0.0005,
            "gflops": 199.68
          },
          "2048x2048": {
            "times_s": [
              0.077,
              0.0663,
              0.0652
            ],
            "mean_s": 0.0695,
            "std_s": 0.0053,
            "gflops": 247.15
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 8 threads)",
        "n_threads": 8,
        "results": {
          "512x512": {
            "times_s": [
              0.0018,
              0.0017,
              0.0018
            ],
            "mean_s": 0.0018,
            "std_s": 0.0001,
            "gflops": 151.11
          },
          "1024x1024": {
            "times_s": [
              0.0081,
              0.0075,
              0.0101
            ],
            "mean_s": 0.0086,
            "std_s": 0.0011,
            "gflops": 251.01
          },
          "2048x2048": {
            "times_s": [
              0.0531,
              0.0585,
              0.0566
            ],
            "mean_s": 0.0561,
            "std_s": 0.0023,
            "gflops": 306.43
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.1021,
            "bandwidth_gb_s": 2.45
          },
          "read": {
            "mean_s": 0.0499,
            "bandwidth_gb_s": 5.01
          },
          "copy": {
            "mean_s": 0.1157,
            "bandwidth_gb_s": 2.16
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute",
        "status": "completed",
        "device": "Intel(R) Iris(R) Xe Graphics",
        "backend": "SYCL/XPU",
        "results": {
          "1024x1024": {
            "times_s": [
              0.0028,
              0.0037,
              0.0027
            ],
            "mean_s": 0.0031,
            "gflops": 700.32
          },
          "2048x2048": {
            "times_s": [
              0.0388,
              0.0374,
              0.0374
            ],
            "mean_s": 0.0378,
            "gflops": 454.1
          },
          "4096x4096": {
            "times_s": [
              0.2796,
              0.3091,
              0.3346
            ],
            "mean_s": 0.3078,
            "gflops": 446.59
          }
        }
      }
    },
    "resource_usage": {
      "n_samples": 18,
      "duration_s": 9.529144763946533,
      "cpu": {
        "avg_percent": 40.0,
        "max_percent": 83.6,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 88.6,
        "max_percent": 95.3,
        "peak_used_gb": 7.37
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 1,
      "n_benchmark_runs": 3
    },
    "total_time_s": 2077.06,
    "models_tested": 1,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 21.9227,
            "first_token_latency_s": 0.0958,
            "tokens_per_second": 11.68,
            "memory_before_gb": 0.877,
            "memory_after_gb": 0.575,
            "memory_delta_gb": -0.302,
            "server_memory_gb": 0.543,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 85.59,
            "p90_inter_token_latency_ms": 91.15
          },
          {
            "tokens_generated": 256,
            "total_time_s": 19.2249,
            "first_token_latency_s": 0.1242,
            "tokens_per_second": 13.32,
            "memory_before_gb": 0.575,
            "memory_after_gb": 0.548,
            "memory_delta_gb": -0.027,
            "server_memory_gb": 0.518,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 74.9,
            "p90_inter_token_latency_ms": 79.76
          },
          {
            "tokens_generated": 256,
            "total_time_s": 20.1556,
            "first_token_latency_s": 0.0812,
            "tokens_per_second": 12.7,
            "memory_before_gb": 0.548,
            "memory_after_gb": 0.517,
            "memory_delta_gb": -0.031,
            "server_memory_gb": 0.487,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 78.72,
            "p90_inter_token_latency_ms": 85.29
          }
        ],
        "model_load_time_s": 17.66,
        "backend": {
          "backend": "sycl",
          "n_gpu_layers": -1,
          "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
          "intel_device": "Intel(R) Iris(R) Xe Graphics",
          "intel_vram_mb": 3273,
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 106,
          "duration_s": 60.98743391036987,
          "cpu": {
            "avg_percent": 58.5,
            "max_percent": 100.0,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 91.0,
            "max_percent": 94.8,
            "peak_used_gb": 7.34
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 12.57,
          "std_tokens_per_second": 0.68,
          "avg_first_token_latency_s": 0.1004,
          "avg_total_time_s": 20.4344,
          "peak_memory_gb": 0.575,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 36.2634,
                "first_token_latency_s": 0.1451,
                "tokens_per_second": 7.06,
                "memory_before_gb": 0.948,
                "memory_after_gb": 0.745,
                "memory_delta_gb": -0.203,
                "server_memory_gb": 0.697,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 141.64,
                "p90_inter_token_latency_ms": 152.56
              },
              {
                "tokens_generated": 256,
                "total_time_s": 35.4689,
                "first_token_latency_s": 0.1953,
                "tokens_per_second": 7.22,
                "memory_before_gb": 0.745,
                "memory_after_gb": 0.522,
                "memory_delta_gb": -0.223,
                "server_memory_gb": 0.497,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 138.32,
                "p90_inter_token_latency_ms": 145.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 37.9638,
                "first_token_latency_s": 0.1489,
                "tokens_per_second": 6.74,
                "memory_before_gb": 0.522,
                "memory_after_gb": 0.043,
                "memory_delta_gb": -0.48,
                "server_memory_gb": 0.024,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 148.29,
                "p90_inter_token_latency_ms": 152.33
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 4.6,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.909,
            "server_memory_after_load_gb": 0.798,
            "resource_usage": {
              "n_samples": 193,
              "duration_s": 109.76981401443481,
              "cpu": {
                "avg_percent": 60.0,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 91.3,
                "max_percent": 95.5,
                "peak_used_gb": 7.39
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 7.01,
              "std_tokens_per_second": 0.2,
              "min_tokens_per_second": 6.74,
              "max_tokens_per_second": 7.22,
              "avg_first_token_latency_s": 0.1631,
              "avg_inter_token_latency_ms": 142.75,
              "avg_total_time_s": 36.5654,
              "peak_memory_gb": 0.745,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 45.9836,
                "first_token_latency_s": 0.1452,
                "tokens_per_second": 5.57,
                "memory_before_gb": 1.404,
                "memory_after_gb": 0.061,
                "memory_delta_gb": -1.343,
                "server_memory_gb": 0.042,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 179.71,
                "p90_inter_token_latency_ms": 289.36
              },
              {
                "tokens_generated": 256,
                "total_time_s": 51.0039,
                "first_token_latency_s": 0.2922,
                "tokens_per_second": 5.02,
                "memory_before_gb": 0.063,
                "memory_after_gb": 0.032,
                "memory_delta_gb": -0.031,
                "server_memory_gb": 0.017,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 198.81,
                "p90_inter_token_latency_ms": 247.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 33.8465,
                "first_token_latency_s": 0.3637,
                "tokens_per_second": 7.56,
                "memory_before_gb": 0.037,
                "memory_after_gb": 0.049,
                "memory_delta_gb": 0.012,
                "server_memory_gb": 0.025,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 131.3,
                "p90_inter_token_latency_ms": 144.66
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 3.56,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.322,
            "server_memory_after_load_gb": 1.211,
            "resource_usage": {
              "n_samples": 201,
              "duration_s": 131.22904253005981,
              "cpu": {
                "avg_percent": 76.3,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 92.9,
                "max_percent": 95.8,
                "peak_used_gb": 7.41
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 6.05,
              "std_tokens_per_second": 1.09,
              "min_tokens_per_second": 5.02,
              "max_tokens_per_second": 7.56,
              "avg_first_token_latency_s": 0.267,
              "avg_inter_token_latency_ms": 169.94,
              "avg_total_time_s": 43.6113,
              "peak_memory_gb": 0.061,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 24.273,
                "first_token_latency_s": 0.0928,
                "tokens_per_second": 10.55,
                "memory_before_gb": 1.116,
                "memory_after_gb": 1.033,
                "memory_delta_gb": -0.083,
                "server_memory_gb": 1.005,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 94.82,
                "p90_inter_token_latency_ms": 122.4
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.0251,
                "first_token_latency_s": 0.1354,
                "tokens_per_second": 10.66,
                "memory_before_gb": 1.035,
                "memory_after_gb": 0.945,
                "memory_delta_gb": -0.09,
                "server_memory_gb": 0.919,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 93.68,
                "p90_inter_token_latency_ms": 110.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 22.191,
                "first_token_latency_s": 0.0845,
                "tokens_per_second": 11.54,
                "memory_before_gb": 0.945,
                "memory_after_gb": 0.704,
                "memory_delta_gb": -0.241,
                "server_memory_gb": 0.677,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 86.69,
                "p90_inter_token_latency_ms": 88.37
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 5.64,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.47,
            "server_memory_after_load_gb": 1.36,
            "resource_usage": {
              "n_samples": 118,
              "duration_s": 70.5132429599762,
              "cpu": {
                "avg_percent": 68.9,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 91.5,
                "max_percent": 94.7,
                "peak_used_gb": 7.32
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.92,
              "std_tokens_per_second": 0.44,
              "min_tokens_per_second": 10.55,
              "max_tokens_per_second": 11.54,
              "avg_first_token_latency_s": 0.1042,
              "avg_inter_token_latency_ms": 91.73,
              "avg_total_time_s": 23.4964,
              "peak_memory_gb": 1.033,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 55.2851,
                "first_token_latency_s": 0.1832,
                "tokens_per_second": 4.63,
                "memory_before_gb": 1.197,
                "memory_after_gb": 0.048,
                "memory_delta_gb": -1.148,
                "server_memory_gb": 0.032,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 215.98,
                "p90_inter_token_latency_ms": 244.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 61.4096,
                "first_token_latency_s": 0.2667,
                "tokens_per_second": 4.17,
                "memory_before_gb": 0.053,
                "memory_after_gb": 0.024,
                "memory_delta_gb": -0.028,
                "server_memory_gb": 0.012,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 238.59,
                "p90_inter_token_latency_ms": 351.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 63.4589,
                "first_token_latency_s": 0.4013,
                "tokens_per_second": 4.03,
                "memory_before_gb": 0.03,
                "memory_after_gb": 0.025,
                "memory_delta_gb": -0.004,
                "server_memory_gb": 0.013,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 247.17,
                "p90_inter_token_latency_ms": 341.49
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 6.64,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.794,
            "server_memory_after_load_gb": 1.684,
            "resource_usage": {
              "n_samples": 291,
              "duration_s": 182.9416527748108,
              "cpu": {
                "avg_percent": 80.7,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 94.4,
                "max_percent": 99.2,
                "peak_used_gb": 7.68
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 4.28,
              "std_tokens_per_second": 0.26,
              "min_tokens_per_second": 4.03,
              "max_tokens_per_second": 4.63,
              "avg_first_token_latency_s": 0.2837,
              "avg_inter_token_latency_ms": 233.91,
              "avg_total_time_s": 60.0512,
              "peak_memory_gb": 0.048,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 52.1778,
                "first_token_latency_s": 0.4975,
                "tokens_per_second": 4.91,
                "memory_before_gb": 0.042,
                "memory_after_gb": 0.038,
                "memory_delta_gb": -0.004,
                "server_memory_gb": 0.025,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 202.57,
                "p90_inter_token_latency_ms": 364.1
              },
              {
                "tokens_generated": 256,
                "total_time_s": 44.9047,
                "first_token_latency_s": 0.2333,
                "tokens_per_second": 5.7,
                "memory_before_gb": 0.044,
                "memory_after_gb": 0.024,
                "memory_delta_gb": -0.019,
                "server_memory_gb": 0.012,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 175.09,
                "p90_inter_token_latency_ms": 272.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 53.1474,
                "first_token_latency_s": 0.4046,
                "tokens_per_second": 4.82,
                "memory_before_gb": 0.03,
                "memory_after_gb": 0.029,
                "memory_delta_gb": -0.001,
                "server_memory_gb": 0.014,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 206.78,
                "p90_inter_token_latency_ms": 321.0
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 7.7,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.736,
            "server_memory_after_load_gb": 0.688,
            "resource_usage": {
              "n_samples": 238,
              "duration_s": 150.53653073310852,
              "cpu": {
                "avg_percent": 91.5,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 96.5,
                "max_percent": 99.8,
                "peak_used_gb": 7.72
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 5.14,
              "std_tokens_per_second": 0.4,
              "min_tokens_per_second": 4.82,
              "max_tokens_per_second": 5.7,
              "avg_first_token_latency_s": 0.3785,
              "avg_inter_token_latency_ms": 194.81,
              "avg_total_time_s": 50.0766,
              "peak_memory_gb": 0.038,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 44.1658,
                "first_token_latency_s": 0.1779,
                "tokens_per_second": 5.8,
                "memory_before_gb": 0.626,
                "memory_after_gb": 0.037,
                "memory_delta_gb": -0.589,
                "server_memory_gb": 0.025,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 172.39,
                "p90_inter_token_latency_ms": 234.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 60.5062,
                "first_token_latency_s": 2.9617,
                "tokens_per_second": 4.23,
                "memory_before_gb": 0.033,
                "memory_after_gb": 0.029,
                "memory_delta_gb": -0.005,
                "server_memory_gb": 0.015,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 225.56,
                "p90_inter_token_latency_ms": 397.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 39.4277,
                "first_token_latency_s": 0.2347,
                "tokens_per_second": 6.49,
                "memory_before_gb": 0.034,
                "memory_after_gb": 0.033,
                "memory_delta_gb": -0.001,
                "server_memory_gb": 0.017,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 153.69,
                "p90_inter_token_latency_ms": 184.52
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 13.0,
            "backend": {
              "backend": "sycl",
              "n_gpu_layers": -1,
              "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
              "intel_device": "Intel(R) Iris(R) Xe Graphics",
              "intel_vram_mb": 3273,
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.702,
            "server_memory_after_load_gb": 0.683,
            "resource_usage": {
              "n_samples": 200,
              "duration_s": 146.64377617835999,
              "cpu": {
                "avg_percent": 90.6,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 94.6,
                "max_percent": 98.5,
                "peak_used_gb": 7.62
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 5.51,
              "std_tokens_per_second": 0.95,
              "min_tokens_per_second": 4.23,
              "max_tokens_per_second": 6.49,
              "avg_first_token_latency_s": 1.1248,
              "avg_inter_token_latency_ms": 183.88,
              "avg_total_time_s": 48.0332,
              "peak_memory_gb": 0.037,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 7.01,
            "first_token_latency_s": 0.1631,
            "inter_token_latency_ms": 142.75,
            "peak_memory_gb": 0.745,
            "model_load_time_s": 4.6,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 6.05,
            "first_token_latency_s": 0.267,
            "inter_token_latency_ms": 169.94,
            "peak_memory_gb": 0.061,
            "model_load_time_s": 3.56,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 10.92,
            "first_token_latency_s": 0.1042,
            "inter_token_latency_ms": 91.73,
            "peak_memory_gb": 1.033,
            "model_load_time_s": 5.64,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 4.28,
            "first_token_latency_s": 0.2837,
            "inter_token_latency_ms": 233.91,
            "peak_memory_gb": 0.048,
            "model_load_time_s": 6.64,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 5.14,
            "first_token_latency_s": 0.3785,
            "inter_token_latency_ms": 194.81,
            "peak_memory_gb": 0.038,
            "model_load_time_s": 7.7,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 5.51,
            "first_token_latency_s": 1.1248,
            "inter_token_latency_ms": 183.88,
            "peak_memory_gb": 0.037,
            "model_load_time_s": 13.0,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 21.5884,
                "first_token_latency_s": 0.0983,
                "tokens_per_second": 11.86,
                "memory_before_gb": 1.842,
                "memory_after_gb": 1.321,
                "memory_delta_gb": -0.521,
                "server_memory_gb": 1.288,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 84.27,
                "p90_inter_token_latency_ms": 99.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.4331,
                "first_token_latency_s": 0.1597,
                "tokens_per_second": 10.48,
                "memory_before_gb": 1.321,
                "memory_after_gb": 0.511,
                "memory_delta_gb": -0.81,
                "server_memory_gb": 0.493,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 95.17,
                "p90_inter_token_latency_ms": 124.46
              },
              {
                "tokens_generated": 256,
                "total_time_s": 22.2558,
                "first_token_latency_s": 0.1055,
                "tokens_per_second": 11.5,
                "memory_before_gb": 0.515,
                "memory_after_gb": 0.476,
                "memory_delta_gb": -0.04,
                "server_memory_gb": 0.447,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 86.86,
                "p90_inter_token_latency_ms": 111.56
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 11.28,
              "std_tokens_per_second": 0.58,
              "avg_first_token_latency_s": 0.1212,
              "avg_inter_token_latency_ms": 88.77,
              "avg_total_time_s": 22.7591,
              "peak_memory_gb": 1.321,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 119,
              "duration_s": 68.05696249008179,
              "cpu": {
                "avg_percent": 67.0,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 92.4,
                "max_percent": 95.4,
                "peak_used_gb": 7.38
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 21.5141,
                "first_token_latency_s": 0.098,
                "tokens_per_second": 11.9,
                "memory_before_gb": 0.477,
                "memory_after_gb": 0.421,
                "memory_delta_gb": -0.055,
                "server_memory_gb": 0.392,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 83.98,
                "p90_inter_token_latency_ms": 101.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 28.0229,
                "first_token_latency_s": 0.1315,
                "tokens_per_second": 9.14,
                "memory_before_gb": 0.349,
                "memory_after_gb": 0.037,
                "memory_delta_gb": -0.312,
                "server_memory_gb": 0.019,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 109.37,
                "p90_inter_token_latency_ms": 137.04
              },
              {
                "tokens_generated": 256,
                "total_time_s": 23.468,
                "first_token_latency_s": 0.1587,
                "tokens_per_second": 10.91,
                "memory_before_gb": 0.041,
                "memory_after_gb": 0.048,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.022,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 91.4,
                "p90_inter_token_latency_ms": 98.33
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.65,
              "std_tokens_per_second": 1.14,
              "avg_first_token_latency_s": 0.1294,
              "avg_inter_token_latency_ms": 94.92,
              "avg_total_time_s": 24.335,
              "peak_memory_gb": 0.421,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 122,
              "duration_s": 72.95524787902832,
              "cpu": {
                "avg_percent": 65.4,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 91.0,
                "max_percent": 94.8,
                "peak_used_gb": 7.33
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 22.2524,
                "first_token_latency_s": 0.0908,
                "tokens_per_second": 11.5,
                "memory_before_gb": 0.051,
                "memory_after_gb": 0.052,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.022,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 86.91,
                "p90_inter_token_latency_ms": 99.52
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.9159,
                "first_token_latency_s": 0.1464,
                "tokens_per_second": 10.27,
                "memory_before_gb": 0.052,
                "memory_after_gb": 0.055,
                "memory_delta_gb": 0.004,
                "server_memory_gb": 0.027,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 97.1,
                "p90_inter_token_latency_ms": 107.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 23.722,
                "first_token_latency_s": 0.1134,
                "tokens_per_second": 10.79,
                "memory_before_gb": 0.056,
                "memory_after_gb": 0.045,
                "memory_delta_gb": -0.011,
                "server_memory_gb": 0.022,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 92.58,
                "p90_inter_token_latency_ms": 104.15
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.85,
              "std_tokens_per_second": 0.5,
              "avg_first_token_latency_s": 0.1169,
              "avg_inter_token_latency_ms": 92.2,
              "avg_total_time_s": 23.6301,
              "peak_memory_gb": 0.055,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 117,
              "duration_s": 70.77016043663025,
              "cpu": {
                "avg_percent": 59.0,
                "max_percent": 99.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 89.9,
                "max_percent": 94.0,
                "peak_used_gb": 7.28
              }
            }
          }
        },
        "backend": {
          "backend": "sycl",
          "n_gpu_layers": -1,
          "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
          "intel_device": "Intel(R) Iris(R) Xe Graphics",
          "intel_vram_mb": 3273,
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 11.28,
            "first_token_latency_s": 0.1212,
            "inter_token_latency_ms": 88.77,
            "peak_memory_gb": 1.321,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 10.65,
            "first_token_latency_s": 0.1294,
            "inter_token_latency_ms": 94.92,
            "peak_memory_gb": 0.421,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 10.85,
            "first_token_latency_s": 0.1169,
            "inter_token_latency_ms": 92.2,
            "peak_memory_gb": 0.055,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 22.6668,
                "first_token_latency_s": 0.1055,
                "tokens_per_second": 11.29,
                "memory_before_gb": 1.592,
                "memory_after_gb": 1.558,
                "memory_delta_gb": -0.034,
                "server_memory_gb": 1.446,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 88.47,
                "p90_inter_token_latency_ms": 99.49
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.2985,
                "first_token_latency_s": 0.1247,
                "tokens_per_second": 10.54,
                "memory_before_gb": 1.559,
                "memory_after_gb": 1.271,
                "memory_delta_gb": -0.288,
                "server_memory_gb": 1.191,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 94.8,
                "p90_inter_token_latency_ms": 101.98
              },
              {
                "tokens_generated": 256,
                "total_time_s": 23.2609,
                "first_token_latency_s": 0.0999,
                "tokens_per_second": 11.01,
                "memory_before_gb": 1.271,
                "memory_after_gb": 1.15,
                "memory_delta_gb": -0.121,
                "server_memory_gb": 1.096,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 90.82,
                "p90_inter_token_latency_ms": 99.84
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.95,
              "std_tokens_per_second": 0.31,
              "avg_first_token_latency_s": 0.11,
              "avg_inter_token_latency_ms": 91.36,
              "avg_total_time_s": 23.4087,
              "peak_memory_gb": 1.558,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 115,
              "duration_s": 70.20743894577026,
              "cpu": {
                "avg_percent": 51.0,
                "max_percent": 98.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 89.3,
                "max_percent": 93.9,
                "peak_used_gb": 7.27
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 31.0141,
                "first_token_latency_s": 0.8237,
                "tokens_per_second": 8.25,
                "memory_before_gb": 1.15,
                "memory_after_gb": 0.612,
                "memory_delta_gb": -0.539,
                "server_memory_gb": 0.596,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 118.38,
                "p90_inter_token_latency_ms": 189.6
              },
              {
                "tokens_generated": 256,
                "total_time_s": 41.1374,
                "first_token_latency_s": 0.178,
                "tokens_per_second": 6.22,
                "memory_before_gb": 0.617,
                "memory_after_gb": 0.145,
                "memory_delta_gb": -0.471,
                "server_memory_gb": 0.126,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 160.61,
                "p90_inter_token_latency_ms": 249.1
              },
              {
                "tokens_generated": 256,
                "total_time_s": 34.117,
                "first_token_latency_s": 0.3323,
                "tokens_per_second": 7.5,
                "memory_before_gb": 0.149,
                "memory_after_gb": 0.036,
                "memory_delta_gb": -0.113,
                "server_memory_gb": 0.022,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 132.48,
                "p90_inter_token_latency_ms": 166.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 7.32,
              "std_tokens_per_second": 0.84,
              "avg_first_token_latency_s": 0.4447,
              "avg_inter_token_latency_ms": 137.16,
              "avg_total_time_s": 35.4228,
              "peak_memory_gb": 0.612,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 167,
              "duration_s": 106.20590496063232,
              "cpu": {
                "avg_percent": 81.1,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 91.5,
                "max_percent": 95.4,
                "peak_used_gb": 7.38
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 23.3888,
                "first_token_latency_s": 0.871,
                "tokens_per_second": 10.95,
                "memory_before_gb": 0.044,
                "memory_after_gb": 0.055,
                "memory_delta_gb": 0.01,
                "server_memory_gb": 0.026,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 88.28,
                "p90_inter_token_latency_ms": 100.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.7458,
                "first_token_latency_s": 0.1416,
                "tokens_per_second": 10.35,
                "memory_before_gb": 0.055,
                "memory_after_gb": 0.061,
                "memory_delta_gb": 0.006,
                "server_memory_gb": 0.032,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 96.48,
                "p90_inter_token_latency_ms": 108.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.6981,
                "first_token_latency_s": 0.1445,
                "tokens_per_second": 10.37,
                "memory_before_gb": 0.053,
                "memory_after_gb": 0.054,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 0.029,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 96.29,
                "p90_inter_token_latency_ms": 114.64
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.56,
              "std_tokens_per_second": 0.28,
              "avg_first_token_latency_s": 0.3857,
              "avg_inter_token_latency_ms": 93.68,
              "avg_total_time_s": 24.2776,
              "peak_memory_gb": 0.061,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 119,
              "duration_s": 72.87247014045715,
              "cpu": {
                "avg_percent": 59.6,
                "max_percent": 100.0,
                "min_percent": 23.3
              },
              "ram": {
                "avg_percent": 87.4,
                "max_percent": 94.0,
                "peak_used_gb": 7.27
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 23.576,
                "first_token_latency_s": 0.8144,
                "tokens_per_second": 10.86,
                "memory_before_gb": 0.058,
                "memory_after_gb": 0.064,
                "memory_delta_gb": 0.006,
                "server_memory_gb": 0.035,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 89.25,
                "p90_inter_token_latency_ms": 102.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 22.5985,
                "first_token_latency_s": 0.1609,
                "tokens_per_second": 11.33,
                "memory_before_gb": 0.064,
                "memory_after_gb": 0.074,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 0.043,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 87.98,
                "p90_inter_token_latency_ms": 100.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.0147,
                "first_token_latency_s": 0.1328,
                "tokens_per_second": 10.66,
                "memory_before_gb": 0.074,
                "memory_after_gb": 0.072,
                "memory_delta_gb": -0.002,
                "server_memory_gb": 0.044,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 93.65,
                "p90_inter_token_latency_ms": 109.22
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.95,
              "std_tokens_per_second": 0.28,
              "avg_first_token_latency_s": 0.3694,
              "avg_inter_token_latency_ms": 90.29,
              "avg_total_time_s": 23.3964,
              "peak_memory_gb": 0.074,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 116,
              "duration_s": 70.41870069503784,
              "cpu": {
                "avg_percent": 51.9,
                "max_percent": 96.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 90.2,
                "max_percent": 93.3,
                "peak_used_gb": 7.22
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 24.8026,
                "first_token_latency_s": 0.8249,
                "tokens_per_second": 10.32,
                "memory_before_gb": 0.074,
                "memory_after_gb": 0.077,
                "memory_delta_gb": 0.004,
                "server_memory_gb": 0.047,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 94.02,
                "p90_inter_token_latency_ms": 107.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 25.2781,
                "first_token_latency_s": 0.1792,
                "tokens_per_second": 10.13,
                "memory_before_gb": 0.067,
                "memory_after_gb": 0.066,
                "memory_delta_gb": -0.001,
                "server_memory_gb": 0.036,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 98.42,
                "p90_inter_token_latency_ms": 114.46
              },
              {
                "tokens_generated": 256,
                "total_time_s": 26.5332,
                "first_token_latency_s": 0.1765,
                "tokens_per_second": 9.65,
                "memory_before_gb": 0.066,
                "memory_after_gb": 0.066,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.038,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 103.35,
                "p90_inter_token_latency_ms": 127.1
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.03,
              "std_tokens_per_second": 0.28,
              "avg_first_token_latency_s": 0.3935,
              "avg_inter_token_latency_ms": 98.6,
              "avg_total_time_s": 25.538,
              "peak_memory_gb": 0.077,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 125,
              "duration_s": 76.45203638076782,
              "cpu": {
                "avg_percent": 61.9,
                "max_percent": 99.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 90.3,
                "max_percent": 93.9,
                "peak_used_gb": 7.26
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "runs": [
              {
                "tokens_generated": 242,
                "total_time_s": 24.8007,
                "first_token_latency_s": 1.0205,
                "tokens_per_second": 9.76,
                "memory_before_gb": 0.067,
                "memory_after_gb": 0.069,
                "memory_delta_gb": 0.003,
                "server_memory_gb": 0.04,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 98.67,
                "p90_inter_token_latency_ms": 110.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.791,
                "first_token_latency_s": 0.1252,
                "tokens_per_second": 10.33,
                "memory_before_gb": 0.069,
                "memory_after_gb": 0.066,
                "memory_delta_gb": -0.004,
                "server_memory_gb": 0.038,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 96.73,
                "p90_inter_token_latency_ms": 110.54
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.7998,
                "first_token_latency_s": 0.1521,
                "tokens_per_second": 10.32,
                "memory_before_gb": 0.066,
                "memory_after_gb": 0.056,
                "memory_delta_gb": -0.01,
                "server_memory_gb": 0.029,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 96.65,
                "p90_inter_token_latency_ms": 105.95
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.14,
              "std_tokens_per_second": 0.27,
              "avg_first_token_latency_s": 0.4326,
              "avg_inter_token_latency_ms": 97.35,
              "avg_total_time_s": 24.7972,
              "peak_memory_gb": 0.069,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 122,
              "duration_s": 74.7278220653534,
              "cpu": {
                "avg_percent": 57.5,
                "max_percent": 99.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 88.5,
                "max_percent": 93.3,
                "peak_used_gb": 7.22
              }
            }
          }
        },
        "backend": {
          "backend": "sycl",
          "n_gpu_layers": -1,
          "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
          "intel_device": "Intel(R) Iris(R) Xe Graphics",
          "intel_vram_mb": 3273,
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "tokens_per_second": 10.95,
            "first_token_latency_s": 0.11,
            "inter_token_latency_ms": 91.36,
            "peak_memory_gb": 1.558,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "tokens_per_second": 7.32,
            "first_token_latency_s": 0.4447,
            "inter_token_latency_ms": 137.16,
            "peak_memory_gb": 0.612,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "tokens_per_second": 10.56,
            "first_token_latency_s": 0.3857,
            "inter_token_latency_ms": 93.68,
            "peak_memory_gb": 0.061,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "tokens_per_second": 10.95,
            "first_token_latency_s": 0.3694,
            "inter_token_latency_ms": 90.29,
            "peak_memory_gb": 0.074,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "tokens_per_second": 10.03,
            "first_token_latency_s": 0.3935,
            "inter_token_latency_ms": 98.6,
            "peak_memory_gb": 0.077,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "tokens_per_second": 10.14,
            "first_token_latency_s": 0.4326,
            "inter_token_latency_ms": 97.35,
            "peak_memory_gb": 0.069,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 24.4991,
                "first_token_latency_s": 0.118,
                "tokens_per_second": 10.45,
                "memory_before_gb": 1.296,
                "memory_after_gb": 1.13,
                "memory_delta_gb": -0.166,
                "server_memory_gb": 1.062,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 95.61,
                "p90_inter_token_latency_ms": 110.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 24.4188,
                "first_token_latency_s": 0.2817,
                "tokens_per_second": 10.48,
                "memory_before_gb": 1.13,
                "memory_after_gb": 0.841,
                "memory_delta_gb": -0.288,
                "server_memory_gb": 0.803,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 94.65,
                "p90_inter_token_latency_ms": 107.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 22.0486,
                "first_token_latency_s": 0.1125,
                "tokens_per_second": 11.61,
                "memory_before_gb": 0.842,
                "memory_after_gb": 0.755,
                "memory_delta_gb": -0.086,
                "server_memory_gb": 0.728,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 86.02,
                "p90_inter_token_latency_ms": 111.17
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.85,
              "std_tokens_per_second": 0.54,
              "avg_first_token_latency_s": 0.1707,
              "avg_inter_token_latency_ms": 92.09,
              "avg_total_time_s": 23.6555,
              "peak_memory_gb": 1.13,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 119,
              "duration_s": 70.98512363433838,
              "cpu": {
                "avg_percent": 58.4,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 92.5,
                "max_percent": 96.2,
                "peak_used_gb": 7.44
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 20.7979,
                "first_token_latency_s": 0.8389,
                "tokens_per_second": 12.31,
                "memory_before_gb": 0.757,
                "memory_after_gb": 0.777,
                "memory_delta_gb": 0.02,
                "server_memory_gb": 0.746,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 78.27,
                "p90_inter_token_latency_ms": 90.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 19.7688,
                "first_token_latency_s": 0.1105,
                "tokens_per_second": 12.95,
                "memory_before_gb": 0.777,
                "memory_after_gb": 0.694,
                "memory_delta_gb": -0.083,
                "server_memory_gb": 0.667,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 77.09,
                "p90_inter_token_latency_ms": 81.02
              },
              {
                "tokens_generated": 256,
                "total_time_s": 19.6154,
                "first_token_latency_s": 0.121,
                "tokens_per_second": 13.05,
                "memory_before_gb": 0.694,
                "memory_after_gb": 0.703,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.674,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 76.45,
                "p90_inter_token_latency_ms": 77.91
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 12.77,
              "std_tokens_per_second": 0.33,
              "avg_first_token_latency_s": 0.3568,
              "avg_inter_token_latency_ms": 77.27,
              "avg_total_time_s": 20.0607,
              "peak_memory_gb": 0.777,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 108,
              "duration_s": 59.844749212265015,
              "cpu": {
                "avg_percent": 49.1,
                "max_percent": 91.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 90.0,
                "max_percent": 94.2,
                "peak_used_gb": 7.29
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "runs": [
              {
                "tokens_generated": 228,
                "total_time_s": 18.1207,
                "first_token_latency_s": 0.874,
                "tokens_per_second": 12.58,
                "memory_before_gb": 0.703,
                "memory_after_gb": 0.689,
                "memory_delta_gb": -0.014,
                "server_memory_gb": 0.66,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 75.65,
                "p90_inter_token_latency_ms": 80.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 18.7739,
                "first_token_latency_s": 0.1275,
                "tokens_per_second": 13.64,
                "memory_before_gb": 0.689,
                "memory_after_gb": 0.698,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 0.667,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 73.12,
                "p90_inter_token_latency_ms": 77.26
              },
              {
                "tokens_generated": 256,
                "total_time_s": 19.4419,
                "first_token_latency_s": 0.1069,
                "tokens_per_second": 13.17,
                "memory_before_gb": 0.698,
                "memory_after_gb": 0.631,
                "memory_delta_gb": -0.067,
                "server_memory_gb": 0.6,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 75.82,
                "p90_inter_token_latency_ms": 79.21
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 13.13,
              "std_tokens_per_second": 0.43,
              "avg_first_token_latency_s": 0.3695,
              "avg_inter_token_latency_ms": 74.86,
              "avg_total_time_s": 18.7788,
              "peak_memory_gb": 0.698,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 102,
              "duration_s": 55.98910903930664,
              "cpu": {
                "avg_percent": 44.1,
                "max_percent": 85.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 90.4,
                "max_percent": 93.6,
                "peak_used_gb": 7.24
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 23.5117,
                "first_token_latency_s": 0.7335,
                "tokens_per_second": 10.89,
                "memory_before_gb": 0.631,
                "memory_after_gb": 0.359,
                "memory_delta_gb": -0.272,
                "server_memory_gb": 0.332,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 89.32,
                "p90_inter_token_latency_ms": 116.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 22.7209,
                "first_token_latency_s": 0.2127,
                "tokens_per_second": 11.27,
                "memory_before_gb": 0.361,
                "memory_after_gb": 0.282,
                "memory_delta_gb": -0.079,
                "server_memory_gb": 0.256,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 88.26,
                "p90_inter_token_latency_ms": 102.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 28.2126,
                "first_token_latency_s": 0.1325,
                "tokens_per_second": 9.07,
                "memory_before_gb": 0.282,
                "memory_after_gb": 0.053,
                "memory_delta_gb": -0.229,
                "server_memory_gb": 0.037,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 110.1,
                "p90_inter_token_latency_ms": 147.57
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 10.41,
              "std_tokens_per_second": 0.96,
              "avg_first_token_latency_s": 0.3596,
              "avg_inter_token_latency_ms": 95.89,
              "avg_total_time_s": 24.8151,
              "peak_memory_gb": 0.359,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 127,
              "duration_s": 74.06908082962036,
              "cpu": {
                "avg_percent": 64.8,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 91.3,
                "max_percent": 95.1,
                "peak_used_gb": 7.36
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 30.8851,
                "first_token_latency_s": 1.0541,
                "tokens_per_second": 8.29,
                "memory_before_gb": 0.048,
                "memory_after_gb": 0.033,
                "memory_delta_gb": -0.015,
                "server_memory_gb": 0.019,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 116.97,
                "p90_inter_token_latency_ms": 156.93
              },
              {
                "tokens_generated": 256,
                "total_time_s": 23.9936,
                "first_token_latency_s": 0.156,
                "tokens_per_second": 10.67,
                "memory_before_gb": 0.038,
                "memory_after_gb": 0.056,
                "memory_delta_gb": 0.018,
                "server_memory_gb": 0.031,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 93.48,
                "p90_inter_token_latency_ms": 101.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 25.8696,
                "first_token_latency_s": 0.2938,
                "tokens_per_second": 9.9,
                "memory_before_gb": 0.056,
                "memory_after_gb": 0.038,
                "memory_delta_gb": -0.018,
                "server_memory_gb": 0.021,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 100.29,
                "p90_inter_token_latency_ms": 152.12
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 9.62,
              "std_tokens_per_second": 0.99,
              "avg_first_token_latency_s": 0.5013,
              "avg_inter_token_latency_ms": 103.58,
              "avg_total_time_s": 26.9161,
              "peak_memory_gb": 0.056,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 135,
              "duration_s": 80.6861572265625,
              "cpu": {
                "avg_percent": 73.2,
                "max_percent": 100.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 90.1,
                "max_percent": 94.3,
                "peak_used_gb": 7.29
              }
            }
          }
        },
        "backend": {
          "backend": "sycl",
          "n_gpu_layers": -1,
          "details": "Intel GPU d√©tect√© (Intel(R) Iris(R) Xe Graphics via pytorch_xpu), utilisation de SYCL",
          "intel_device": "Intel(R) Iris(R) Xe Graphics",
          "intel_vram_mb": 3273,
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "tokens_per_second": 10.85,
            "first_token_latency_s": 0.1707,
            "inter_token_latency_ms": 92.09,
            "peak_memory_gb": 1.13,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "tokens_per_second": 12.77,
            "first_token_latency_s": 0.3568,
            "inter_token_latency_ms": 77.27,
            "peak_memory_gb": 0.777,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "tokens_per_second": 13.13,
            "first_token_latency_s": 0.3695,
            "inter_token_latency_ms": 74.86,
            "peak_memory_gb": 0.698,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "tokens_per_second": 10.41,
            "first_token_latency_s": 0.3596,
            "inter_token_latency_ms": 95.89,
            "peak_memory_gb": 0.359,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "tokens_per_second": 9.62,
            "first_token_latency_s": 0.5013,
            "inter_token_latency_ms": 103.58,
            "peak_memory_gb": 0.056,
            "stability": "stable"
          }
        ]
      }
    }
  }
}