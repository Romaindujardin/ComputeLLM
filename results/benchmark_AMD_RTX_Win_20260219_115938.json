{
  "id": "20260219_115938",
  "timestamp": "2026-02-19T11:59:38.813519",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "11",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-11-10.0.26200-SP0",
      "python_version": "3.14.3"
    },
    "cpu": {
      "physical_cores": 12,
      "logical_cores": 24,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier sp√©cifi√© est introuvable",
      "model": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 4400.0,
        "min": null,
        "max": 4400.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "NVIDIA",
          "name": "NVIDIA GeForce RTX 3070",
          "vram_total_mb": 8192.0,
          "vram_free_mb": 6980.0,
          "driver_version": "591.74",
          "compute_capability": "8.6",
          "backend": "cuda",
          "device_index": 0,
          "gpu_index": 0
        },
        {
          "type": "AMD",
          "name": "AMD Radeon(TM) Graphics",
          "backend": "directml",
          "detected_via": "wmi",
          "vram_total_mb": 512,
          "driver_version": "32.0.21041.1000",
          "gpu_index": 1
        }
      ],
      "backends": [
        "cuda",
        "directml",
        "cpu"
      ],
      "primary_backend": "cuda",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.10.0+cpu",
        "pytorch_cuda": false,
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": false,
        "llama_server": false,
        "pytorch_rocm": false,
        "ipex": false,
        "directml": false
      }
    },
    "ram": {
      "total_gb": 31.11,
      "available_gb": 20.43,
      "used_gb": 10.68,
      "percent_used": 34.3,
      "swap_total_gb": 2.0,
      "swap_used_gb": 0.0,
      "unified_memory": false
    },
    "selected_gpu": {
      "gpu_index": 0,
      "name": "NVIDIA GeForce RTX 3070",
      "backend": "cuda"
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 8.78,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread, subprocess isol√©)",
        "results": {
          "512x512": {
            "times_s": [
              0.001,
              0.001,
              0.0011
            ],
            "mean_s": 0.001,
            "median_s": 0.001,
            "std_s": 0.0,
            "gflops": 262.27
          },
          "1024x1024": {
            "times_s": [
              0.0076,
              0.0074,
              0.0077
            ],
            "mean_s": 0.0076,
            "median_s": 0.0076,
            "std_s": 0.0001,
            "gflops": 281.37
          },
          "2048x2048": {
            "times_s": [
              0.0614,
              0.0553,
              0.0541
            ],
            "mean_s": 0.057,
            "median_s": 0.0553,
            "std_s": 0.0032,
            "gflops": 310.39
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 24 threads, subprocess isol√©)",
        "n_threads": 24,
        "results": {
          "512x512": {
            "times_s": [
              0.001,
              0.0007,
              0.0009
            ],
            "mean_s": 0.0009,
            "median_s": 0.0009,
            "std_s": 0.0001,
            "gflops": 287.93
          },
          "1024x1024": {
            "times_s": [
              0.002,
              0.002,
              0.0019
            ],
            "mean_s": 0.002,
            "median_s": 0.002,
            "std_s": 0.0,
            "gflops": 1088.38
          },
          "2048x2048": {
            "times_s": [
              0.0127,
              0.013,
              0.0132
            ],
            "mean_s": 0.013,
            "median_s": 0.013,
            "std_s": 0.0002,
            "gflops": 1323.08
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0383,
            "median_s": 0.039,
            "bandwidth_gb_s": 6.41
          },
          "read": {
            "mean_s": 0.0209,
            "median_s": 0.021,
            "bandwidth_gb_s": 11.9
          },
          "copy": {
            "mean_s": 0.0388,
            "median_s": 0.037,
            "bandwidth_gb_s": 6.76
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute (Raw)",
        "status": "skipped",
        "reason": "GPU AMD (AMD Radeon(TM) Graphics) d√©tect√©, mais PyTorch n'a pas le support ROCm activ√©.",
        "advice": "ROCm n'est pas disponible sur Windows. Installez torch-directml pour activer le support GPU AMD :\npip install torch-directml"
      },
      "gpu_system": {
        "test": "GPU System Score",
        "status": "skipped",
        "reason": "GPU AMD (AMD Radeon(TM) Graphics) d√©tect√©, mais PyTorch n'a pas le support ROCm activ√©.",
        "advice": "ROCm n'est pas disponible sur Windows. Installez torch-directml pour activer le support GPU AMD :\npip install torch-directml"
      }
    },
    "resource_usage": {
      "n_samples": 16,
      "duration_s": 8.244670391082764,
      "cpu": {
        "avg_percent": 6.8,
        "max_percent": 17.0,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 34.3,
        "max_percent": 35.8,
        "peak_used_gb": 11.13
      },
      "gpu": {
        "avg_utilization_percent": 32.8,
        "max_utilization_percent": 39.0,
        "peak_memory_mb": 1078.0,
        "max_temperature_c": 44.0
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 2,
      "n_benchmark_runs": 3
    },
    "total_time_s": 245.07,
    "models_tested": 1,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 2.5435,
            "first_token_latency_s": 0.0287,
            "tokens_per_second": 100.65,
            "memory_before_gb": 1.404,
            "memory_after_gb": 1.405,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 1.108,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 9.86,
            "p90_inter_token_latency_ms": 10.36
          },
          {
            "tokens_generated": 256,
            "total_time_s": 2.5405,
            "first_token_latency_s": 0.0274,
            "tokens_per_second": 100.77,
            "memory_before_gb": 1.405,
            "memory_after_gb": 1.412,
            "memory_delta_gb": 0.007,
            "server_memory_gb": 1.115,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 9.85,
            "p90_inter_token_latency_ms": 10.48
          },
          {
            "tokens_generated": 256,
            "total_time_s": 2.5416,
            "first_token_latency_s": 0.0374,
            "tokens_per_second": 100.72,
            "memory_before_gb": 1.412,
            "memory_after_gb": 1.412,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 1.115,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 9.82,
            "p90_inter_token_latency_ms": 10.43
          }
        ],
        "model_load_time_s": 11.24,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 14,
          "duration_s": 7.202273845672607,
          "cpu": {
            "avg_percent": 51.1,
            "max_percent": 59.4,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 38.4,
            "max_percent": 38.4,
            "peak_used_gb": 11.95
          },
          "gpu": {
            "avg_utilization_percent": 11.0,
            "max_utilization_percent": 34.0,
            "peak_memory_mb": 1155.0,
            "max_temperature_c": 45.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 100.71,
          "std_tokens_per_second": 0.05,
          "avg_first_token_latency_s": 0.0312,
          "avg_total_time_s": 2.5419,
          "peak_memory_gb": 1.412,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.9668,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 130.16,
                "memory_before_gb": 0.833,
                "memory_after_gb": 0.834,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.536,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.62,
                "p90_inter_token_latency_ms": 8.0
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.9822,
                "first_token_latency_s": 0.0349,
                "tokens_per_second": 129.15,
                "memory_before_gb": 0.834,
                "memory_after_gb": 0.841,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.543,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.64,
                "p90_inter_token_latency_ms": 8.08
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.0416,
                "first_token_latency_s": 0.0347,
                "tokens_per_second": 125.39,
                "memory_before_gb": 0.841,
                "memory_after_gb": 0.842,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.543,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.87,
                "p90_inter_token_latency_ms": 8.74
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 0.51,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.821,
            "server_memory_after_load_gb": 0.524,
            "resource_usage": {
              "n_samples": 11,
              "duration_s": 5.496644735336304,
              "cpu": {
                "avg_percent": 50.2,
                "max_percent": 57.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 36.5,
                "max_percent": 36.6,
                "peak_used_gb": 11.38
              },
              "gpu": {
                "avg_utilization_percent": 14.3,
                "max_utilization_percent": 34.0,
                "peak_memory_mb": 1164.0,
                "max_temperature_c": 45.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 128.23,
              "std_tokens_per_second": 2.05,
              "min_tokens_per_second": 125.39,
              "max_tokens_per_second": 130.16,
              "avg_first_token_latency_s": 0.0314,
              "avg_inter_token_latency_ms": 7.71,
              "avg_total_time_s": 1.9969,
              "peak_memory_gb": 0.842,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.2657,
                "first_token_latency_s": 0.0116,
                "tokens_per_second": 112.99,
                "memory_before_gb": 1.034,
                "memory_after_gb": 1.035,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.736,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 8.84,
                "p90_inter_token_latency_ms": 9.44
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.2864,
                "first_token_latency_s": 0.0253,
                "tokens_per_second": 111.97,
                "memory_before_gb": 1.035,
                "memory_after_gb": 1.042,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.743,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 8.87,
                "p90_inter_token_latency_ms": 9.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.2884,
                "first_token_latency_s": 0.0329,
                "tokens_per_second": 111.87,
                "memory_before_gb": 1.042,
                "memory_after_gb": 1.042,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.743,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 8.84,
                "p90_inter_token_latency_ms": 9.58
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 0.52,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.022,
            "server_memory_after_load_gb": 0.724,
            "resource_usage": {
              "n_samples": 13,
              "duration_s": 6.593944549560547,
              "cpu": {
                "avg_percent": 54.2,
                "max_percent": 60.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 37.2,
                "max_percent": 37.3,
                "peak_used_gb": 11.59
              },
              "gpu": {
                "avg_utilization_percent": 30.4,
                "max_utilization_percent": 37.0,
                "peak_memory_mb": 1164.0,
                "max_temperature_c": 45.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 112.28,
              "std_tokens_per_second": 0.51,
              "min_tokens_per_second": 111.87,
              "max_tokens_per_second": 112.99,
              "avg_first_token_latency_s": 0.0233,
              "avg_inter_token_latency_ms": 8.85,
              "avg_total_time_s": 2.2802,
              "peak_memory_gb": 1.042,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6244,
                "first_token_latency_s": 0.0138,
                "tokens_per_second": 97.55,
                "memory_before_gb": 1.406,
                "memory_after_gb": 1.406,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.107,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.24,
                "p90_inter_token_latency_ms": 10.78
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6795,
                "first_token_latency_s": 0.0349,
                "tokens_per_second": 95.54,
                "memory_before_gb": 1.406,
                "memory_after_gb": 1.413,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.37,
                "p90_inter_token_latency_ms": 11.13
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6071,
                "first_token_latency_s": 0.0383,
                "tokens_per_second": 98.19,
                "memory_before_gb": 1.413,
                "memory_after_gb": 1.413,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.07,
                "p90_inter_token_latency_ms": 10.67
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 0.51,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.394,
            "server_memory_after_load_gb": 1.095,
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.8357555866241455,
              "cpu": {
                "avg_percent": 54.3,
                "max_percent": 64.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.4,
                "peak_used_gb": 11.95
              },
              "gpu": {
                "avg_utilization_percent": 14.2,
                "max_utilization_percent": 37.0,
                "peak_memory_mb": 1202.0,
                "max_temperature_c": 45.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.09,
              "std_tokens_per_second": 1.13,
              "min_tokens_per_second": 95.54,
              "max_tokens_per_second": 98.19,
              "avg_first_token_latency_s": 0.029,
              "avg_inter_token_latency_ms": 10.23,
              "avg_total_time_s": 2.637,
              "peak_memory_gb": 1.413,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.0145,
                "first_token_latency_s": 0.0273,
                "tokens_per_second": 84.92,
                "memory_before_gb": 1.06,
                "memory_after_gb": 1.061,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.762,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.71,
                "p90_inter_token_latency_ms": 12.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0187,
                "first_token_latency_s": 0.0268,
                "tokens_per_second": 84.8,
                "memory_before_gb": 1.061,
                "memory_after_gb": 1.068,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.769,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.73,
                "p90_inter_token_latency_ms": 12.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0234,
                "first_token_latency_s": 0.0313,
                "tokens_per_second": 84.67,
                "memory_before_gb": 1.068,
                "memory_after_gb": 1.068,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.769,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.73,
                "p90_inter_token_latency_ms": 12.51
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 0.52,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.048,
            "server_memory_after_load_gb": 0.749,
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.879603862762451,
              "cpu": {
                "avg_percent": 55.2,
                "max_percent": 63.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 37.3,
                "max_percent": 37.3,
                "peak_used_gb": 11.61
              },
              "gpu": {
                "avg_utilization_percent": 15.5,
                "max_utilization_percent": 40.0,
                "peak_memory_mb": 1184.0,
                "max_temperature_c": 44.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 84.8,
              "std_tokens_per_second": 0.1,
              "min_tokens_per_second": 84.67,
              "max_tokens_per_second": 84.92,
              "avg_first_token_latency_s": 0.0285,
              "avg_inter_token_latency_ms": 11.72,
              "avg_total_time_s": 3.0189,
              "peak_memory_gb": 1.068,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.542,
                "first_token_latency_s": 0.0289,
                "tokens_per_second": 72.28,
                "memory_before_gb": 1.165,
                "memory_after_gb": 1.166,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.867,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.78,
                "p90_inter_token_latency_ms": 14.37
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.5406,
                "first_token_latency_s": 0.0271,
                "tokens_per_second": 72.3,
                "memory_before_gb": 1.166,
                "memory_after_gb": 1.172,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.873,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.78,
                "p90_inter_token_latency_ms": 14.57
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.5336,
                "first_token_latency_s": 0.0338,
                "tokens_per_second": 72.45,
                "memory_before_gb": 1.172,
                "memory_after_gb": 1.173,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.873,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.72,
                "p90_inter_token_latency_ms": 14.39
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 0.52,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.153,
            "server_memory_after_load_gb": 0.854,
            "resource_usage": {
              "n_samples": 20,
              "duration_s": 10.619062423706055,
              "cpu": {
                "avg_percent": 56.7,
                "max_percent": 62.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 37.6,
                "max_percent": 37.6,
                "peak_used_gb": 11.71
              },
              "gpu": {
                "avg_utilization_percent": 32.6,
                "max_utilization_percent": 48.0,
                "peak_memory_mb": 1181.0,
                "max_temperature_c": 44.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 72.34,
              "std_tokens_per_second": 0.08,
              "min_tokens_per_second": 72.28,
              "max_tokens_per_second": 72.45,
              "avg_first_token_latency_s": 0.0299,
              "avg_inter_token_latency_ms": 13.76,
              "avg_total_time_s": 3.5387,
              "peak_memory_gb": 1.173,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.2775,
                "first_token_latency_s": 0.0325,
                "tokens_per_second": 59.85,
                "memory_before_gb": 1.398,
                "memory_after_gb": 1.399,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.1,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 16.65,
                "p90_inter_token_latency_ms": 17.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.2861,
                "first_token_latency_s": 0.0351,
                "tokens_per_second": 59.73,
                "memory_before_gb": 1.399,
                "memory_after_gb": 1.406,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.107,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 16.67,
                "p90_inter_token_latency_ms": 17.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.3255,
                "first_token_latency_s": 0.0341,
                "tokens_per_second": 59.18,
                "memory_before_gb": 1.406,
                "memory_after_gb": 1.406,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.107,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 16.83,
                "p90_inter_token_latency_ms": 17.7
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 0.52,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.387,
            "server_memory_after_load_gb": 1.088,
            "resource_usage": {
              "n_samples": 24,
              "duration_s": 12.781620502471924,
              "cpu": {
                "avg_percent": 55.5,
                "max_percent": 60.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.9
              },
              "gpu": {
                "avg_utilization_percent": 31.5,
                "max_utilization_percent": 36.0,
                "peak_memory_mb": 1172.0,
                "max_temperature_c": 44.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 59.59,
              "std_tokens_per_second": 0.29,
              "min_tokens_per_second": 59.18,
              "max_tokens_per_second": 59.85,
              "avg_first_token_latency_s": 0.0339,
              "avg_inter_token_latency_ms": 16.72,
              "avg_total_time_s": 4.2964,
              "peak_memory_gb": 1.406,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 128.23,
            "first_token_latency_s": 0.0314,
            "inter_token_latency_ms": 7.71,
            "peak_memory_gb": 0.842,
            "model_load_time_s": 0.51,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 112.28,
            "first_token_latency_s": 0.0233,
            "inter_token_latency_ms": 8.85,
            "peak_memory_gb": 1.042,
            "model_load_time_s": 0.52,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 97.09,
            "first_token_latency_s": 0.029,
            "inter_token_latency_ms": 10.23,
            "peak_memory_gb": 1.413,
            "model_load_time_s": 0.51,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 84.8,
            "first_token_latency_s": 0.0285,
            "inter_token_latency_ms": 11.72,
            "peak_memory_gb": 1.068,
            "model_load_time_s": 0.52,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 72.34,
            "first_token_latency_s": 0.0299,
            "inter_token_latency_ms": 13.76,
            "peak_memory_gb": 1.173,
            "model_load_time_s": 0.52,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 59.59,
            "first_token_latency_s": 0.0339,
            "inter_token_latency_ms": 16.72,
            "peak_memory_gb": 1.406,
            "model_load_time_s": 0.52,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6503,
                "first_token_latency_s": 0.0284,
                "tokens_per_second": 96.59,
                "memory_before_gb": 1.406,
                "memory_after_gb": 1.407,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.108,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.28,
                "p90_inter_token_latency_ms": 10.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6366,
                "first_token_latency_s": 0.0297,
                "tokens_per_second": 97.09,
                "memory_before_gb": 1.407,
                "memory_after_gb": 1.414,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.22,
                "p90_inter_token_latency_ms": 10.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6368,
                "first_token_latency_s": 0.0329,
                "tokens_per_second": 97.09,
                "memory_before_gb": 1.414,
                "memory_after_gb": 1.414,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.21,
                "p90_inter_token_latency_ms": 10.76
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.92,
              "std_tokens_per_second": 0.24,
              "avg_first_token_latency_s": 0.0303,
              "avg_inter_token_latency_ms": 10.24,
              "avg_total_time_s": 2.6412,
              "peak_memory_gb": 1.414,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.7468483448028564,
              "cpu": {
                "avg_percent": 52.9,
                "max_percent": 59.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.91
              },
              "gpu": {
                "avg_utilization_percent": 30.5,
                "max_utilization_percent": 38.0,
                "peak_memory_mb": 1155.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6774,
                "first_token_latency_s": 0.0313,
                "tokens_per_second": 95.62,
                "memory_before_gb": 1.414,
                "memory_after_gb": 1.414,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.115,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.38,
                "p90_inter_token_latency_ms": 10.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.629,
                "first_token_latency_s": 0.037,
                "tokens_per_second": 97.38,
                "memory_before_gb": 1.414,
                "memory_after_gb": 1.421,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.121,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.16,
                "p90_inter_token_latency_ms": 10.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6378,
                "first_token_latency_s": 0.0364,
                "tokens_per_second": 97.05,
                "memory_before_gb": 1.421,
                "memory_after_gb": 1.421,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.122,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.2,
                "p90_inter_token_latency_ms": 10.73
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.68,
              "std_tokens_per_second": 0.76,
              "avg_first_token_latency_s": 0.0349,
              "avg_inter_token_latency_ms": 10.25,
              "avg_total_time_s": 2.6481,
              "peak_memory_gb": 1.421,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.7093000411987305,
              "cpu": {
                "avg_percent": 53.3,
                "max_percent": 59.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.92
              },
              "gpu": {
                "avg_utilization_percent": 32.4,
                "max_utilization_percent": 41.0,
                "peak_memory_mb": 1155.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6832,
                "first_token_latency_s": 0.0288,
                "tokens_per_second": 95.41,
                "memory_before_gb": 1.421,
                "memory_after_gb": 1.422,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.122,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.41,
                "p90_inter_token_latency_ms": 10.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6612,
                "first_token_latency_s": 0.0255,
                "tokens_per_second": 96.2,
                "memory_before_gb": 1.422,
                "memory_after_gb": 1.429,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.129,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.34,
                "p90_inter_token_latency_ms": 10.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.7083,
                "first_token_latency_s": 0.0343,
                "tokens_per_second": 94.52,
                "memory_before_gb": 1.429,
                "memory_after_gb": 1.429,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.129,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.49,
                "p90_inter_token_latency_ms": 11.14
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 95.38,
              "std_tokens_per_second": 0.69,
              "avg_first_token_latency_s": 0.0295,
              "avg_inter_token_latency_ms": 10.41,
              "avg_total_time_s": 2.6842,
              "peak_memory_gb": 1.429,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.733867168426514,
              "cpu": {
                "avg_percent": 53.2,
                "max_percent": 61.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.93
              },
              "gpu": {
                "avg_utilization_percent": 32.8,
                "max_utilization_percent": 39.0,
                "peak_memory_mb": 1155.0,
                "max_temperature_c": 44.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 96.92,
            "first_token_latency_s": 0.0303,
            "inter_token_latency_ms": 10.24,
            "peak_memory_gb": 1.414,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 96.68,
            "first_token_latency_s": 0.0349,
            "inter_token_latency_ms": 10.25,
            "peak_memory_gb": 1.421,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 95.38,
            "first_token_latency_s": 0.0295,
            "inter_token_latency_ms": 10.41,
            "peak_memory_gb": 1.429,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6243,
                "first_token_latency_s": 0.032,
                "tokens_per_second": 97.55,
                "memory_before_gb": 1.408,
                "memory_after_gb": 1.409,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.108,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.17,
                "p90_inter_token_latency_ms": 10.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6009,
                "first_token_latency_s": 0.0132,
                "tokens_per_second": 98.43,
                "memory_before_gb": 1.409,
                "memory_after_gb": 1.415,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.115,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.15,
                "p90_inter_token_latency_ms": 10.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6227,
                "first_token_latency_s": 0.0315,
                "tokens_per_second": 97.61,
                "memory_before_gb": 1.415,
                "memory_after_gb": 1.415,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.115,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.16,
                "p90_inter_token_latency_ms": 10.8
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.86,
              "std_tokens_per_second": 0.4,
              "avg_first_token_latency_s": 0.0256,
              "avg_inter_token_latency_ms": 10.16,
              "avg_total_time_s": 2.616,
              "peak_memory_gb": 1.415,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.794240236282349,
              "cpu": {
                "avg_percent": 53.1,
                "max_percent": 59.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.2,
                "max_percent": 38.2,
                "peak_used_gb": 11.88
              },
              "gpu": {
                "avg_utilization_percent": 30.7,
                "max_utilization_percent": 37.0,
                "peak_memory_mb": 1155.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6972,
                "first_token_latency_s": 0.0724,
                "tokens_per_second": 94.91,
                "memory_before_gb": 1.415,
                "memory_after_gb": 1.416,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.115,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.29,
                "p90_inter_token_latency_ms": 10.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6623,
                "first_token_latency_s": 0.0354,
                "tokens_per_second": 96.16,
                "memory_before_gb": 1.416,
                "memory_after_gb": 1.423,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.122,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.3,
                "p90_inter_token_latency_ms": 10.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6373,
                "first_token_latency_s": 0.0373,
                "tokens_per_second": 97.07,
                "memory_before_gb": 1.423,
                "memory_after_gb": 1.423,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.122,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.2,
                "p90_inter_token_latency_ms": 10.75
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.05,
              "std_tokens_per_second": 0.89,
              "avg_first_token_latency_s": 0.0484,
              "avg_inter_token_latency_ms": 10.26,
              "avg_total_time_s": 2.6656,
              "peak_memory_gb": 1.423,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.778398036956787,
              "cpu": {
                "avg_percent": 53.0,
                "max_percent": 61.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.92
              },
              "gpu": {
                "avg_utilization_percent": 21.0,
                "max_utilization_percent": 52.0,
                "peak_memory_mb": 1165.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.7016,
                "first_token_latency_s": 0.0732,
                "tokens_per_second": 94.76,
                "memory_before_gb": 1.423,
                "memory_after_gb": 1.427,
                "memory_delta_gb": 0.004,
                "server_memory_gb": 1.126,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.31,
                "p90_inter_token_latency_ms": 10.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6196,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 97.72,
                "memory_before_gb": 1.427,
                "memory_after_gb": 1.435,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.134,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.18,
                "p90_inter_token_latency_ms": 10.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6386,
                "first_token_latency_s": 0.027,
                "tokens_per_second": 97.02,
                "memory_before_gb": 1.435,
                "memory_after_gb": 1.442,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.141,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.24,
                "p90_inter_token_latency_ms": 10.74
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.5,
              "std_tokens_per_second": 1.26,
              "avg_first_token_latency_s": 0.0409,
              "avg_inter_token_latency_ms": 10.24,
              "avg_total_time_s": 2.6533,
              "peak_memory_gb": 1.442,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.717960596084595,
              "cpu": {
                "avg_percent": 52.4,
                "max_percent": 58.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.4,
                "peak_used_gb": 11.94
              },
              "gpu": {
                "avg_utilization_percent": 29.7,
                "max_utilization_percent": 34.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6785,
                "first_token_latency_s": 0.0725,
                "tokens_per_second": 95.58,
                "memory_before_gb": 1.442,
                "memory_after_gb": 1.443,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.142,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.22,
                "p90_inter_token_latency_ms": 10.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6309,
                "first_token_latency_s": 0.0265,
                "tokens_per_second": 97.3,
                "memory_before_gb": 1.443,
                "memory_after_gb": 1.45,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.149,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.21,
                "p90_inter_token_latency_ms": 10.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6352,
                "first_token_latency_s": 0.0338,
                "tokens_per_second": 97.15,
                "memory_before_gb": 1.45,
                "memory_after_gb": 1.45,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.149,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.2,
                "p90_inter_token_latency_ms": 10.82
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.68,
              "std_tokens_per_second": 0.78,
              "avg_first_token_latency_s": 0.0443,
              "avg_inter_token_latency_ms": 10.21,
              "avg_total_time_s": 2.6482,
              "peak_memory_gb": 1.45,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.735956430435181,
              "cpu": {
                "avg_percent": 52.1,
                "max_percent": 57.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.4,
                "peak_used_gb": 11.95
              },
              "gpu": {
                "avg_utilization_percent": 30.5,
                "max_utilization_percent": 38.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.65,
                "first_token_latency_s": 0.0596,
                "tokens_per_second": 96.6,
                "memory_before_gb": 1.45,
                "memory_after_gb": 1.451,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.149,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.16,
                "p90_inter_token_latency_ms": 10.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6304,
                "first_token_latency_s": 0.0275,
                "tokens_per_second": 97.32,
                "memory_before_gb": 1.451,
                "memory_after_gb": 1.458,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.157,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.21,
                "p90_inter_token_latency_ms": 10.83
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6231,
                "first_token_latency_s": 0.0275,
                "tokens_per_second": 97.59,
                "memory_before_gb": 1.458,
                "memory_after_gb": 1.459,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.157,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.18,
                "p90_inter_token_latency_ms": 10.69
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.17,
              "std_tokens_per_second": 0.42,
              "avg_first_token_latency_s": 0.0382,
              "avg_inter_token_latency_ms": 10.18,
              "avg_total_time_s": 2.6345,
              "peak_memory_gb": 1.459,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.756580829620361,
              "cpu": {
                "avg_percent": 52.1,
                "max_percent": 58.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.4,
                "peak_used_gb": 11.95
              },
              "gpu": {
                "avg_utilization_percent": 30.1,
                "max_utilization_percent": 34.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.7629,
                "first_token_latency_s": 0.1159,
                "tokens_per_second": 92.66,
                "memory_before_gb": 1.459,
                "memory_after_gb": 1.465,
                "memory_delta_gb": 0.006,
                "server_memory_gb": 1.163,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.38,
                "p90_inter_token_latency_ms": 10.89
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6743,
                "first_token_latency_s": 0.0385,
                "tokens_per_second": 95.73,
                "memory_before_gb": 1.465,
                "memory_after_gb": 1.474,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 1.171,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.34,
                "p90_inter_token_latency_ms": 10.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6739,
                "first_token_latency_s": 0.0344,
                "tokens_per_second": 95.74,
                "memory_before_gb": 1.474,
                "memory_after_gb": 1.482,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 1.179,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.35,
                "p90_inter_token_latency_ms": 10.75
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 94.71,
              "std_tokens_per_second": 1.45,
              "avg_first_token_latency_s": 0.0629,
              "avg_inter_token_latency_ms": 10.36,
              "avg_total_time_s": 2.7037,
              "peak_memory_gb": 1.482,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.681025266647339,
              "cpu": {
                "avg_percent": 52.0,
                "max_percent": 57.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.5,
                "peak_used_gb": 11.98
              },
              "gpu": {
                "avg_utilization_percent": 30.8,
                "max_utilization_percent": 40.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 44.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "tokens_per_second": 97.86,
            "first_token_latency_s": 0.0256,
            "inter_token_latency_ms": 10.16,
            "peak_memory_gb": 1.415,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "tokens_per_second": 96.05,
            "first_token_latency_s": 0.0484,
            "inter_token_latency_ms": 10.26,
            "peak_memory_gb": 1.423,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "tokens_per_second": 96.5,
            "first_token_latency_s": 0.0409,
            "inter_token_latency_ms": 10.24,
            "peak_memory_gb": 1.442,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "tokens_per_second": 96.68,
            "first_token_latency_s": 0.0443,
            "inter_token_latency_ms": 10.21,
            "peak_memory_gb": 1.45,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "tokens_per_second": 97.17,
            "first_token_latency_s": 0.0382,
            "inter_token_latency_ms": 10.18,
            "peak_memory_gb": 1.459,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "tokens_per_second": 94.71,
            "first_token_latency_s": 0.0629,
            "inter_token_latency_ms": 10.36,
            "peak_memory_gb": 1.482,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6284,
                "first_token_latency_s": 0.0259,
                "tokens_per_second": 97.4,
                "memory_before_gb": 1.41,
                "memory_after_gb": 1.411,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.108,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.21,
                "p90_inter_token_latency_ms": 10.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6149,
                "first_token_latency_s": 0.0336,
                "tokens_per_second": 97.9,
                "memory_before_gb": 1.411,
                "memory_after_gb": 1.417,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.12,
                "p90_inter_token_latency_ms": 10.66
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.609,
                "first_token_latency_s": 0.03,
                "tokens_per_second": 98.12,
                "memory_before_gb": 1.417,
                "memory_after_gb": 1.417,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.114,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.11,
                "p90_inter_token_latency_ms": 10.74
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.81,
              "std_tokens_per_second": 0.3,
              "avg_first_token_latency_s": 0.0298,
              "avg_inter_token_latency_ms": 10.15,
              "avg_total_time_s": 2.6174,
              "peak_memory_gb": 1.417,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.735030889511108,
              "cpu": {
                "avg_percent": 52.8,
                "max_percent": 58.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.3,
                "max_percent": 38.3,
                "peak_used_gb": 11.93
              },
              "gpu": {
                "avg_utilization_percent": 31.5,
                "max_utilization_percent": 41.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 44.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6964,
                "first_token_latency_s": 0.0832,
                "tokens_per_second": 94.94,
                "memory_before_gb": 1.417,
                "memory_after_gb": 1.42,
                "memory_delta_gb": 0.003,
                "server_memory_gb": 1.117,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.25,
                "p90_inter_token_latency_ms": 10.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.627,
                "first_token_latency_s": 0.0254,
                "tokens_per_second": 97.45,
                "memory_before_gb": 1.42,
                "memory_after_gb": 1.427,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.124,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.2,
                "p90_inter_token_latency_ms": 10.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.626,
                "first_token_latency_s": 0.0145,
                "tokens_per_second": 97.49,
                "memory_before_gb": 1.427,
                "memory_after_gb": 1.435,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.132,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.24,
                "p90_inter_token_latency_ms": 10.83
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.63,
              "std_tokens_per_second": 1.19,
              "avg_first_token_latency_s": 0.041,
              "avg_inter_token_latency_ms": 10.23,
              "avg_total_time_s": 2.6498,
              "peak_memory_gb": 1.435,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.832540273666382,
              "cpu": {
                "avg_percent": 52.7,
                "max_percent": 59.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.4,
                "peak_used_gb": 11.96
              },
              "gpu": {
                "avg_utilization_percent": 29.9,
                "max_utilization_percent": 38.0,
                "peak_memory_mb": 1157.0,
                "max_temperature_c": 43.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.7102,
                "first_token_latency_s": 0.0777,
                "tokens_per_second": 94.46,
                "memory_before_gb": 1.435,
                "memory_after_gb": 1.438,
                "memory_delta_gb": 0.003,
                "server_memory_gb": 1.135,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.32,
                "p90_inter_token_latency_ms": 10.85
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6347,
                "first_token_latency_s": 0.0318,
                "tokens_per_second": 97.17,
                "memory_before_gb": 1.438,
                "memory_after_gb": 1.446,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.143,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.21,
                "p90_inter_token_latency_ms": 10.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6482,
                "first_token_latency_s": 0.0319,
                "tokens_per_second": 96.67,
                "memory_before_gb": 1.446,
                "memory_after_gb": 1.453,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.15,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.26,
                "p90_inter_token_latency_ms": 10.81
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 96.1,
              "std_tokens_per_second": 1.18,
              "avg_first_token_latency_s": 0.0471,
              "avg_inter_token_latency_ms": 10.26,
              "avg_total_time_s": 2.6644,
              "peak_memory_gb": 1.453,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.707743167877197,
              "cpu": {
                "avg_percent": 52.0,
                "max_percent": 58.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.5,
                "peak_used_gb": 11.97
              },
              "gpu": {
                "avg_utilization_percent": 32.1,
                "max_utilization_percent": 43.0,
                "peak_memory_mb": 1163.0,
                "max_temperature_c": 43.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6506,
                "first_token_latency_s": 0.0516,
                "tokens_per_second": 96.58,
                "memory_before_gb": 1.453,
                "memory_after_gb": 1.454,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.151,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.19,
                "p90_inter_token_latency_ms": 10.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6185,
                "first_token_latency_s": 0.0359,
                "tokens_per_second": 97.77,
                "memory_before_gb": 1.454,
                "memory_after_gb": 1.461,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.158,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.13,
                "p90_inter_token_latency_ms": 10.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6099,
                "first_token_latency_s": 0.0263,
                "tokens_per_second": 98.09,
                "memory_before_gb": 1.461,
                "memory_after_gb": 1.461,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.158,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.13,
                "p90_inter_token_latency_ms": 10.72
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.48,
              "std_tokens_per_second": 0.65,
              "avg_first_token_latency_s": 0.0379,
              "avg_inter_token_latency_ms": 10.15,
              "avg_total_time_s": 2.6263,
              "peak_memory_gb": 1.461,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.757516622543335,
              "cpu": {
                "avg_percent": 52.8,
                "max_percent": 59.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.5,
                "peak_used_gb": 11.97
              },
              "gpu": {
                "avg_utilization_percent": 29.7,
                "max_utilization_percent": 40.0,
                "peak_memory_mb": 1172.0,
                "max_temperature_c": 43.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.7148,
                "first_token_latency_s": 0.0842,
                "tokens_per_second": 94.3,
                "memory_before_gb": 1.461,
                "memory_after_gb": 1.462,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.159,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.32,
                "p90_inter_token_latency_ms": 10.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.5891,
                "first_token_latency_s": 0.014,
                "tokens_per_second": 98.88,
                "memory_before_gb": 1.462,
                "memory_after_gb": 1.47,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.167,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.1,
                "p90_inter_token_latency_ms": 10.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.617,
                "first_token_latency_s": 0.0147,
                "tokens_per_second": 97.82,
                "memory_before_gb": 1.47,
                "memory_after_gb": 1.478,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.175,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.2,
                "p90_inter_token_latency_ms": 10.82
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.0,
              "std_tokens_per_second": 1.96,
              "avg_first_token_latency_s": 0.0376,
              "avg_inter_token_latency_ms": 10.21,
              "avg_total_time_s": 2.6403,
              "peak_memory_gb": 1.478,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.772464275360107,
              "cpu": {
                "avg_percent": 56.2,
                "max_percent": 58.7,
                "min_percent": 46.2
              },
              "ram": {
                "avg_percent": 38.5,
                "max_percent": 38.5,
                "peak_used_gb": 11.98
              },
              "gpu": {
                "avg_utilization_percent": 26.9,
                "max_utilization_percent": 44.0,
                "peak_memory_mb": 1203.0,
                "max_temperature_c": 43.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU d√©tect√©, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "tokens_per_second": 97.81,
            "first_token_latency_s": 0.0298,
            "inter_token_latency_ms": 10.15,
            "peak_memory_gb": 1.417,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "tokens_per_second": 96.63,
            "first_token_latency_s": 0.041,
            "inter_token_latency_ms": 10.23,
            "peak_memory_gb": 1.435,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "tokens_per_second": 96.1,
            "first_token_latency_s": 0.0471,
            "inter_token_latency_ms": 10.26,
            "peak_memory_gb": 1.453,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "tokens_per_second": 97.48,
            "first_token_latency_s": 0.0379,
            "inter_token_latency_ms": 10.15,
            "peak_memory_gb": 1.461,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "tokens_per_second": 97.0,
            "first_token_latency_s": 0.0376,
            "inter_token_latency_ms": 10.21,
            "peak_memory_gb": 1.478,
            "stability": "stable"
          }
        ]
      }
    }
  }
}