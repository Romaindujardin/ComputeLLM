{
  "id": "20260219_164734",
  "timestamp": "2026-02-19T16:47:34.985264",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26200-SP0",
      "python_version": "3.11.9"
    },
    "cpu": {
      "physical_cores": 12,
      "logical_cores": 24,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier spécifié est introuvable",
      "model": "AMD64 Family 26 Model 68 Stepping 0, AuthenticAMD",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 4400.0,
        "min": null,
        "max": 4400.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "NVIDIA",
          "name": "NVIDIA GeForce RTX 3070",
          "vram_total_mb": 8192.0,
          "vram_free_mb": 6663.0,
          "driver_version": "591.74",
          "compute_capability": "8.6",
          "backend": "cuda",
          "device_index": 0,
          "gpu_index": 0
        },
        {
          "type": "AMD",
          "name": "AMD Radeon(TM) Graphics",
          "backend": "directml",
          "detected_via": "wmi",
          "vram_total_mb": 512,
          "driver_version": "32.0.21041.1000",
          "gpu_index": 1
        }
      ],
      "backends": [
        "cuda",
        "directml",
        "cpu"
      ],
      "primary_backend": "cuda",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.5.1+cu121",
        "pytorch_cuda": true,
        "pytorch_cuda_version": "12.1",
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": false,
        "llama_server": false,
        "pytorch_rocm": false,
        "ipex": false,
        "directml": false
      }
    },
    "ram": {
      "total_gb": 31.11,
      "available_gb": 19.5,
      "used_gb": 11.61,
      "percent_used": 37.3,
      "swap_total_gb": 2.0,
      "swap_used_gb": 0.13,
      "unified_memory": false
    },
    "selected_gpu": {
      "gpu_index": 0,
      "name": "NVIDIA GeForce RTX 3070",
      "backend": "cuda"
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 8.09,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread, subprocess isolé)",
        "results": {
          "512x512": {
            "times_s": [
              0.0012,
              0.0011,
              0.0011
            ],
            "mean_s": 0.0011,
            "median_s": 0.0011,
            "std_s": 0.0,
            "gflops": 235.95
          },
          "1024x1024": {
            "times_s": [
              0.0073,
              0.0074,
              0.0072
            ],
            "mean_s": 0.0073,
            "median_s": 0.0073,
            "std_s": 0.0001,
            "gflops": 293.22
          },
          "2048x2048": {
            "times_s": [
              0.0538,
              0.0536,
              0.0539
            ],
            "mean_s": 0.0538,
            "median_s": 0.0538,
            "std_s": 0.0001,
            "gflops": 319.39
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 24 threads, subprocess isolé)",
        "n_threads": 24,
        "results": {
          "512x512": {
            "times_s": [
              0.0007,
              0.0007,
              0.0008
            ],
            "mean_s": 0.0008,
            "median_s": 0.0007,
            "std_s": 0.0,
            "gflops": 360.22
          },
          "1024x1024": {
            "times_s": [
              0.0024,
              0.0019,
              0.002
            ],
            "mean_s": 0.0021,
            "median_s": 0.002,
            "std_s": 0.0002,
            "gflops": 1092.37
          },
          "2048x2048": {
            "times_s": [
              0.0131,
              0.0127,
              0.012
            ],
            "mean_s": 0.0126,
            "median_s": 0.0127,
            "std_s": 0.0005,
            "gflops": 1350.58
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0408,
            "median_s": 0.0453,
            "bandwidth_gb_s": 5.51
          },
          "read": {
            "mean_s": 0.0194,
            "median_s": 0.0194,
            "bandwidth_gb_s": 12.87
          },
          "copy": {
            "mean_s": 0.0367,
            "median_s": 0.0396,
            "bandwidth_gb_s": 6.31
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute (Raw)",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 3070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "times_s": [
              0.0002,
              0.0003,
              0.0003
            ],
            "mean_s": 0.0003,
            "median_s": 0.0003,
            "gflops": 8243.7
          },
          "2048x2048": {
            "times_s": [
              0.0014,
              0.0014,
              0.0014
            ],
            "mean_s": 0.0014,
            "median_s": 0.0014,
            "gflops": 12127.54
          },
          "4096x4096": {
            "times_s": [
              0.011,
              0.0118,
              0.0116
            ],
            "mean_s": 0.0114,
            "median_s": 0.0116,
            "gflops": 11850.64
          }
        }
      },
      "gpu_system": {
        "test": "GPU System Score",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 3070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "pipeline_times_s": [
              0.0014,
              0.0015,
              0.0015
            ],
            "pipeline_median_s": 0.0015,
            "transfer_to_median_s": 0.0007,
            "compute_median_s": 0.0005,
            "transfer_back_median_s": 0.0004,
            "gflops_pipeline": 1402.67,
            "gflops_compute": 4475.79,
            "transfer_bandwidth_gb_s": 11.44,
            "data_transferred_gb": 0.0117,
            "pct_transfer_to": 43.8,
            "pct_compute": 31.3,
            "pct_transfer_back": 23.1
          },
          "2048x2048": {
            "pipeline_times_s": [
              0.0066,
              0.0072,
              0.0063
            ],
            "pipeline_median_s": 0.0066,
            "transfer_to_median_s": 0.0024,
            "compute_median_s": 0.0026,
            "transfer_back_median_s": 0.0013,
            "gflops_pipeline": 2594.13,
            "gflops_compute": 6540.73,
            "transfer_bandwidth_gb_s": 12.57,
            "data_transferred_gb": 0.0469,
            "pct_transfer_to": 36.6,
            "pct_compute": 39.7,
            "pct_transfer_back": 19.7
          },
          "4096x4096": {
            "pipeline_times_s": [
              0.0364,
              0.0395,
              0.034
            ],
            "pipeline_median_s": 0.0364,
            "transfer_to_median_s": 0.0094,
            "compute_median_s": 0.0213,
            "transfer_back_median_s": 0.0057,
            "gflops_pipeline": 3771.27,
            "gflops_compute": 6446.99,
            "transfer_bandwidth_gb_s": 12.4,
            "data_transferred_gb": 0.1875,
            "pct_transfer_to": 25.8,
            "pct_compute": 58.5,
            "pct_transfer_back": 15.7
          }
        }
      }
    },
    "resource_usage": {
      "n_samples": 15,
      "duration_s": 7.5571675300598145,
      "cpu": {
        "avg_percent": 5.0,
        "max_percent": 15.9,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 37.6,
        "max_percent": 38.2,
        "peak_used_gb": 11.88
      },
      "gpu": {
        "avg_utilization_percent": 8.5,
        "max_utilization_percent": 63.0,
        "peak_memory_mb": 1618.0,
        "max_temperature_c": 50.0
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 2,
      "n_benchmark_runs": 3
    },
    "total_time_s": 1603.84,
    "models_tested": 3,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 0.7614,
            "first_token_latency_s": 0.0058,
            "tokens_per_second": 336.22,
            "memory_before_gb": 1.718,
            "memory_after_gb": 1.719,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 0.928,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.96,
            "p90_inter_token_latency_ms": 3.42
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.7852,
            "first_token_latency_s": 0.0277,
            "tokens_per_second": 326.01,
            "memory_before_gb": 1.719,
            "memory_after_gb": 1.725,
            "memory_delta_gb": 0.007,
            "server_memory_gb": 0.935,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.97,
            "p90_inter_token_latency_ms": 3.4
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.8099,
            "first_token_latency_s": 0.0165,
            "tokens_per_second": 316.09,
            "memory_before_gb": 1.725,
            "memory_after_gb": 1.725,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 0.935,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 3.11,
            "p90_inter_token_latency_ms": 3.54
          }
        ],
        "model_load_time_s": 2.6,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 5,
          "duration_s": 2.1534793376922607,
          "cpu": {
            "avg_percent": 7.4,
            "max_percent": 11.0,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 47.3,
            "max_percent": 47.4,
            "peak_used_gb": 14.74
          },
          "gpu": {
            "avg_utilization_percent": 73.2,
            "max_utilization_percent": 91.0,
            "peak_memory_mb": 2706.0,
            "max_temperature_c": 62.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 326.11,
          "std_tokens_per_second": 8.22,
          "avg_first_token_latency_s": 0.0167,
          "avg_total_time_s": 0.7855,
          "peak_memory_gb": 1.725,
          "stability": "stable"
        }
      },
      "mistral-7b": {
        "model": "Mistral 7B",
        "params": "7B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 3.4309,
            "first_token_latency_s": 0.0406,
            "tokens_per_second": 74.62,
            "memory_before_gb": 5.143,
            "memory_after_gb": 5.144,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 4.353,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 13.3,
            "p90_inter_token_latency_ms": 13.57
          },
          {
            "tokens_generated": 256,
            "total_time_s": 3.4507,
            "first_token_latency_s": 0.048,
            "tokens_per_second": 74.19,
            "memory_before_gb": 5.144,
            "memory_after_gb": 5.181,
            "memory_delta_gb": 0.037,
            "server_memory_gb": 4.39,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 13.34,
            "p90_inter_token_latency_ms": 13.67
          },
          {
            "tokens_generated": 256,
            "total_time_s": 3.4361,
            "first_token_latency_s": 0.034,
            "tokens_per_second": 74.5,
            "memory_before_gb": 5.181,
            "memory_after_gb": 5.181,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 4.39,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 13.34,
            "p90_inter_token_latency_ms": 13.63
          }
        ],
        "model_load_time_s": 2.55,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 20,
          "duration_s": 10.177488803863525,
          "cpu": {
            "avg_percent": 7.3,
            "max_percent": 10.5,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 58.5,
            "max_percent": 58.6,
            "peak_used_gb": 18.22
          },
          "gpu": {
            "avg_utilization_percent": 96.4,
            "max_utilization_percent": 97.0,
            "peak_memory_mb": 6465.0,
            "max_temperature_c": 68.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 74.44,
          "std_tokens_per_second": 0.18,
          "avg_first_token_latency_s": 0.0409,
          "avg_total_time_s": 3.4392,
          "peak_memory_gb": 5.181,
          "stability": "stable"
        }
      },
      "llama2-13b": {
        "model": "Llama 2 13B",
        "params": "13B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 15.3002,
            "first_token_latency_s": 0.0767,
            "tokens_per_second": 16.73,
            "memory_before_gb": 9.022,
            "memory_after_gb": 9.023,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 8.299,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 59.7,
            "p90_inter_token_latency_ms": 62.73
          },
          {
            "tokens_generated": 256,
            "total_time_s": 15.3643,
            "first_token_latency_s": 0.135,
            "tokens_per_second": 16.66,
            "memory_before_gb": 9.023,
            "memory_after_gb": 9.278,
            "memory_delta_gb": 0.255,
            "server_memory_gb": 8.553,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 59.72,
            "p90_inter_token_latency_ms": 62.58
          },
          {
            "tokens_generated": 256,
            "total_time_s": 15.247,
            "first_token_latency_s": 0.0888,
            "tokens_per_second": 16.79,
            "memory_before_gb": 9.278,
            "memory_after_gb": 9.278,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 8.554,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 59.44,
            "p90_inter_token_latency_ms": 62.73
          }
        ],
        "model_load_time_s": 4.61,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 83,
          "duration_s": 45.43402695655823,
          "cpu": {
            "avg_percent": 56.1,
            "max_percent": 61.9,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 70.3,
            "max_percent": 70.7,
            "peak_used_gb": 21.99
          },
          "gpu": {
            "avg_utilization_percent": 39.3,
            "max_utilization_percent": 51.0,
            "peak_memory_mb": 7846.0,
            "max_temperature_c": 52.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 16.73,
          "std_tokens_per_second": 0.05,
          "avg_first_token_latency_s": 0.1002,
          "avg_total_time_s": 15.3038,
          "peak_memory_gb": 9.278,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.9012,
                "first_token_latency_s": 0.0212,
                "tokens_per_second": 284.07,
                "memory_before_gb": 1.495,
                "memory_after_gb": 1.495,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.771,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.45,
                "p90_inter_token_latency_ms": 3.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8589,
                "first_token_latency_s": 0.0075,
                "tokens_per_second": 298.04,
                "memory_before_gb": 1.495,
                "memory_after_gb": 1.502,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.777,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.34,
                "p90_inter_token_latency_ms": 3.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8784,
                "first_token_latency_s": 0.0222,
                "tokens_per_second": 291.45,
                "memory_before_gb": 1.502,
                "memory_after_gb": 1.502,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.777,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.36,
                "p90_inter_token_latency_ms": 3.74
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 1.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.469,
            "server_memory_after_load_gb": 0.745,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1770403385162354,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 11.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 45.5,
                "max_percent": 45.5,
                "peak_used_gb": 14.17
              },
              "gpu": {
                "avg_utilization_percent": 86.0,
                "max_utilization_percent": 91.0,
                "peak_memory_mb": 2488.0,
                "max_temperature_c": 57.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 291.19,
              "std_tokens_per_second": 5.71,
              "min_tokens_per_second": 284.07,
              "max_tokens_per_second": 298.04,
              "avg_first_token_latency_s": 0.017,
              "avg_inter_token_latency_ms": 3.38,
              "avg_total_time_s": 0.8795,
              "peak_memory_gb": 1.502,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8515,
                "first_token_latency_s": 0.0304,
                "tokens_per_second": 300.63,
                "memory_before_gb": 1.558,
                "memory_after_gb": 1.558,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.834,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.22,
                "p90_inter_token_latency_ms": 3.6
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.894,
                "first_token_latency_s": 0.0223,
                "tokens_per_second": 286.35,
                "memory_before_gb": 1.558,
                "memory_after_gb": 1.565,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.84,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.42,
                "p90_inter_token_latency_ms": 3.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8977,
                "first_token_latency_s": 0.0301,
                "tokens_per_second": 285.16,
                "memory_before_gb": 1.565,
                "memory_after_gb": 1.565,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.84,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.4,
                "p90_inter_token_latency_ms": 3.81
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 1.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.526,
            "server_memory_after_load_gb": 0.802,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1567342281341553,
              "cpu": {
                "avg_percent": 6.1,
                "max_percent": 8.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 45.7,
                "max_percent": 45.7,
                "peak_used_gb": 14.23
              },
              "gpu": {
                "avg_utilization_percent": 85.2,
                "max_utilization_percent": 91.0,
                "peak_memory_mb": 2549.0,
                "max_temperature_c": 56.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 290.71,
              "std_tokens_per_second": 7.03,
              "min_tokens_per_second": 285.16,
              "max_tokens_per_second": 300.63,
              "avg_first_token_latency_s": 0.0276,
              "avg_inter_token_latency_ms": 3.35,
              "avg_total_time_s": 0.8811,
              "peak_memory_gb": 1.565,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7964,
                "first_token_latency_s": 0.0267,
                "tokens_per_second": 321.44,
                "memory_before_gb": 1.652,
                "memory_after_gb": 1.653,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.928,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.02,
                "p90_inter_token_latency_ms": 3.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7783,
                "first_token_latency_s": 0.0291,
                "tokens_per_second": 328.92,
                "memory_before_gb": 1.653,
                "memory_after_gb": 1.659,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.94,
                "p90_inter_token_latency_ms": 3.37
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7797,
                "first_token_latency_s": 0.0247,
                "tokens_per_second": 328.32,
                "memory_before_gb": 1.659,
                "memory_after_gb": 1.659,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.96,
                "p90_inter_token_latency_ms": 3.41
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 0.5,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.628,
            "server_memory_after_load_gb": 0.903,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.155604362487793,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 9.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 46.1,
                "max_percent": 46.1,
                "peak_used_gb": 14.35
              },
              "gpu": {
                "avg_utilization_percent": 72.6,
                "max_utilization_percent": 91.0,
                "peak_memory_mb": 2636.0,
                "max_temperature_c": 55.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 326.23,
              "std_tokens_per_second": 3.39,
              "min_tokens_per_second": 321.44,
              "max_tokens_per_second": 328.92,
              "avg_first_token_latency_s": 0.0268,
              "avg_inter_token_latency_ms": 2.97,
              "avg_total_time_s": 0.7848,
              "peak_memory_gb": 1.659,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8544,
                "first_token_latency_s": 0.0197,
                "tokens_per_second": 299.63,
                "memory_before_gb": 1.751,
                "memory_after_gb": 1.752,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.027,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.27,
                "p90_inter_token_latency_ms": 3.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8504,
                "first_token_latency_s": 0.0082,
                "tokens_per_second": 301.03,
                "memory_before_gb": 1.752,
                "memory_after_gb": 1.759,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.034,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.3,
                "p90_inter_token_latency_ms": 3.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.867,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 295.28,
                "memory_before_gb": 1.759,
                "memory_after_gb": 1.759,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.034,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.31,
                "p90_inter_token_latency_ms": 3.71
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 1.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.727,
            "server_memory_after_load_gb": 1.002,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.140639066696167,
              "cpu": {
                "avg_percent": 6.2,
                "max_percent": 8.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 46.4,
                "max_percent": 46.5,
                "peak_used_gb": 14.45
              },
              "gpu": {
                "avg_utilization_percent": 83.8,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 2746.0,
                "max_temperature_c": 55.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 298.65,
              "std_tokens_per_second": 2.45,
              "min_tokens_per_second": 295.28,
              "max_tokens_per_second": 301.03,
              "avg_first_token_latency_s": 0.0168,
              "avg_inter_token_latency_ms": 3.29,
              "avg_total_time_s": 0.8573,
              "peak_memory_gb": 1.759,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.9086,
                "first_token_latency_s": 0.0058,
                "tokens_per_second": 281.75,
                "memory_before_gb": 1.849,
                "memory_after_gb": 1.849,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.124,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.54,
                "p90_inter_token_latency_ms": 3.95
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9295,
                "first_token_latency_s": 0.0207,
                "tokens_per_second": 275.42,
                "memory_before_gb": 1.849,
                "memory_after_gb": 1.856,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.131,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.56,
                "p90_inter_token_latency_ms": 3.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9472,
                "first_token_latency_s": 0.0281,
                "tokens_per_second": 270.26,
                "memory_before_gb": 1.856,
                "memory_after_gb": 1.856,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.131,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.6,
                "p90_inter_token_latency_ms": 4.04
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 1.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.832,
            "server_memory_after_load_gb": 1.107,
            "resource_usage": {
              "n_samples": 6,
              "duration_s": 2.68373441696167,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 10.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 46.8,
                "max_percent": 46.8,
                "peak_used_gb": 14.55
              },
              "gpu": {
                "avg_utilization_percent": 82.0,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 2852.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 275.81,
              "std_tokens_per_second": 4.7,
              "min_tokens_per_second": 270.26,
              "max_tokens_per_second": 281.75,
              "avg_first_token_latency_s": 0.0182,
              "avg_inter_token_latency_ms": 3.57,
              "avg_total_time_s": 0.9284,
              "peak_memory_gb": 1.856,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.0834,
                "first_token_latency_s": 0.007,
                "tokens_per_second": 236.3,
                "memory_before_gb": 2.081,
                "memory_after_gb": 2.082,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.357,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 4.22,
                "p90_inter_token_latency_ms": 4.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.1175,
                "first_token_latency_s": 0.0269,
                "tokens_per_second": 229.08,
                "memory_before_gb": 2.082,
                "memory_after_gb": 2.089,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.363,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 4.28,
                "p90_inter_token_latency_ms": 4.66
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.0949,
                "first_token_latency_s": 0.0173,
                "tokens_per_second": 233.81,
                "memory_before_gb": 2.089,
                "memory_after_gb": 2.089,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.363,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 4.23,
                "p90_inter_token_latency_ms": 4.61
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 1.52,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 2.066,
            "server_memory_after_load_gb": 1.34,
            "resource_usage": {
              "n_samples": 7,
              "duration_s": 3.2323591709136963,
              "cpu": {
                "avg_percent": 6.7,
                "max_percent": 9.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 47.5,
                "max_percent": 47.6,
                "peak_used_gb": 14.8
              },
              "gpu": {
                "avg_utilization_percent": 92.3,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 3092.0,
                "max_temperature_c": 54.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 233.06,
              "std_tokens_per_second": 2.99,
              "min_tokens_per_second": 229.08,
              "max_tokens_per_second": 236.3,
              "avg_first_token_latency_s": 0.0171,
              "avg_inter_token_latency_ms": 4.24,
              "avg_total_time_s": 1.0986,
              "peak_memory_gb": 2.089,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 291.19,
            "first_token_latency_s": 0.017,
            "inter_token_latency_ms": 3.38,
            "peak_memory_gb": 1.502,
            "model_load_time_s": 1.54,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 290.71,
            "first_token_latency_s": 0.0276,
            "inter_token_latency_ms": 3.35,
            "peak_memory_gb": 1.565,
            "model_load_time_s": 1.54,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 326.23,
            "first_token_latency_s": 0.0268,
            "inter_token_latency_ms": 2.97,
            "peak_memory_gb": 1.659,
            "model_load_time_s": 0.5,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 298.65,
            "first_token_latency_s": 0.0168,
            "inter_token_latency_ms": 3.29,
            "peak_memory_gb": 1.759,
            "model_load_time_s": 1.54,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 275.81,
            "first_token_latency_s": 0.0182,
            "inter_token_latency_ms": 3.57,
            "peak_memory_gb": 1.856,
            "model_load_time_s": 1.54,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 233.06,
            "first_token_latency_s": 0.0171,
            "inter_token_latency_ms": 4.24,
            "peak_memory_gb": 2.089,
            "model_load_time_s": 1.52,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.87,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.5034,
                "first_token_latency_s": 0.0277,
                "tokens_per_second": 73.07,
                "memory_before_gb": 3.911,
                "memory_after_gb": 3.911,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 3.186,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.63,
                "p90_inter_token_latency_ms": 14.19
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.4636,
                "first_token_latency_s": 0.0403,
                "tokens_per_second": 73.91,
                "memory_before_gb": 3.911,
                "memory_after_gb": 3.948,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 3.223,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.42,
                "p90_inter_token_latency_ms": 14.01
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.4309,
                "first_token_latency_s": 0.0165,
                "tokens_per_second": 74.62,
                "memory_before_gb": 3.948,
                "memory_after_gb": 3.948,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 3.223,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.39,
                "p90_inter_token_latency_ms": 14.1
              }
            ],
            "actual_file_size_gb": 2.871,
            "model_load_time_s": 2.54,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 3.886,
            "server_memory_after_load_gb": 3.161,
            "resource_usage": {
              "n_samples": 20,
              "duration_s": 10.17135500907898,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 13.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 53.1,
                "max_percent": 53.2,
                "peak_used_gb": 16.54
              },
              "gpu": {
                "avg_utilization_percent": 96.2,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 5201.0,
                "max_temperature_c": 67.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 73.87,
              "std_tokens_per_second": 0.63,
              "min_tokens_per_second": 73.07,
              "max_tokens_per_second": 74.62,
              "avg_first_token_latency_s": 0.0282,
              "avg_inter_token_latency_ms": 13.48,
              "avg_total_time_s": 3.466,
              "peak_memory_gb": 3.948,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.28,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1991,
                "first_token_latency_s": 0.0148,
                "tokens_per_second": 80.02,
                "memory_before_gb": 4.31,
                "memory_after_gb": 4.311,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 3.586,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.49,
                "p90_inter_token_latency_ms": 13.1
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.2634,
                "first_token_latency_s": 0.0401,
                "tokens_per_second": 78.45,
                "memory_before_gb": 4.311,
                "memory_after_gb": 4.348,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 3.622,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.64,
                "p90_inter_token_latency_ms": 13.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.2501,
                "first_token_latency_s": 0.0369,
                "tokens_per_second": 78.77,
                "memory_before_gb": 4.348,
                "memory_after_gb": 4.348,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 3.623,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.6,
                "p90_inter_token_latency_ms": 13.36
              }
            ],
            "actual_file_size_gb": 3.277,
            "model_load_time_s": 2.53,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 4.28,
            "server_memory_after_load_gb": 3.555,
            "resource_usage": {
              "n_samples": 19,
              "duration_s": 9.619113206863403,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 9.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 54.4,
                "max_percent": 54.4,
                "peak_used_gb": 16.93
              },
              "gpu": {
                "avg_utilization_percent": 96.3,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 5573.0,
                "max_temperature_c": 68.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 79.08,
              "std_tokens_per_second": 0.68,
              "min_tokens_per_second": 78.45,
              "max_tokens_per_second": 80.02,
              "avg_first_token_latency_s": 0.0306,
              "avg_inter_token_latency_ms": 12.58,
              "avg_total_time_s": 3.2375,
              "peak_memory_gb": 4.348,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.07,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.313,
                "first_token_latency_s": 0.0377,
                "tokens_per_second": 77.27,
                "memory_before_gb": 5.078,
                "memory_after_gb": 5.079,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.354,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.84,
                "p90_inter_token_latency_ms": 13.61
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.465,
                "first_token_latency_s": 0.0421,
                "tokens_per_second": 73.88,
                "memory_before_gb": 5.079,
                "memory_after_gb": 5.116,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.42,
                "p90_inter_token_latency_ms": 13.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.4495,
                "first_token_latency_s": 0.0167,
                "tokens_per_second": 74.21,
                "memory_before_gb": 5.116,
                "memory_after_gb": 5.116,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.46,
                "p90_inter_token_latency_ms": 13.77
              }
            ],
            "actual_file_size_gb": 4.068,
            "model_load_time_s": 2.55,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 5.055,
            "server_memory_after_load_gb": 4.33,
            "resource_usage": {
              "n_samples": 20,
              "duration_s": 10.129419803619385,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 10.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 56.8,
                "max_percent": 56.9,
                "peak_used_gb": 17.71
              },
              "gpu": {
                "avg_utilization_percent": 94.8,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6387.0,
                "max_temperature_c": 66.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 75.12,
              "std_tokens_per_second": 1.53,
              "min_tokens_per_second": 73.88,
              "max_tokens_per_second": 77.27,
              "avg_first_token_latency_s": 0.0322,
              "avg_inter_token_latency_ms": 13.24,
              "avg_total_time_s": 3.4092,
              "peak_memory_gb": 5.116,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.78,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.9337,
                "first_token_latency_s": 0.0363,
                "tokens_per_second": 65.08,
                "memory_before_gb": 5.74,
                "memory_after_gb": 5.741,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 5.049,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 15.28,
                "p90_inter_token_latency_ms": 15.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.9518,
                "first_token_latency_s": 0.0503,
                "tokens_per_second": 64.78,
                "memory_before_gb": 5.741,
                "memory_after_gb": 5.778,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 5.085,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 15.3,
                "p90_inter_token_latency_ms": 15.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.9309,
                "first_token_latency_s": 0.0333,
                "tokens_per_second": 65.12,
                "memory_before_gb": 5.778,
                "memory_after_gb": 5.778,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.085,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 15.28,
                "p90_inter_token_latency_ms": 15.79
              }
            ],
            "actual_file_size_gb": 4.779,
            "model_load_time_s": 3.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 5.717,
            "server_memory_after_load_gb": 5.025,
            "resource_usage": {
              "n_samples": 23,
              "duration_s": 11.748446941375732,
              "cpu": {
                "avg_percent": 6.7,
                "max_percent": 8.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 57.2,
                "max_percent": 57.2,
                "peak_used_gb": 17.81
              },
              "gpu": {
                "avg_utilization_percent": 95.8,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 7090.0,
                "max_temperature_c": 66.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 64.99,
              "std_tokens_per_second": 0.15,
              "min_tokens_per_second": 64.78,
              "max_tokens_per_second": 65.12,
              "avg_first_token_latency_s": 0.04,
              "avg_inter_token_latency_ms": 15.29,
              "avg_total_time_s": 3.9388,
              "peak_memory_gb": 5.778,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.53,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1944,
                "first_token_latency_s": 0.0363,
                "tokens_per_second": 49.28,
                "memory_before_gb": 6.515,
                "memory_after_gb": 6.516,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 5.839,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 20.23,
                "p90_inter_token_latency_ms": 21.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.265,
                "first_token_latency_s": 0.0516,
                "tokens_per_second": 48.62,
                "memory_before_gb": 6.516,
                "memory_after_gb": 6.553,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 5.875,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 20.44,
                "p90_inter_token_latency_ms": 21.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.2196,
                "first_token_latency_s": 0.0342,
                "tokens_per_second": 49.05,
                "memory_before_gb": 6.553,
                "memory_after_gb": 6.553,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.875,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 20.33,
                "p90_inter_token_latency_ms": 21.58
              }
            ],
            "actual_file_size_gb": 5.534,
            "model_load_time_s": 3.57,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 6.5,
            "server_memory_after_load_gb": 5.822,
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.538397312164307,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 10.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 58.8,
                "max_percent": 58.9,
                "peak_used_gb": 18.32
              },
              "gpu": {
                "avg_utilization_percent": 97.9,
                "max_utilization_percent": 98.0,
                "peak_memory_mb": 7783.0,
                "max_temperature_c": 68.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.98,
              "std_tokens_per_second": 0.27,
              "min_tokens_per_second": 48.62,
              "max_tokens_per_second": 49.28,
              "avg_first_token_latency_s": 0.0407,
              "avg_inter_token_latency_ms": 20.33,
              "avg_total_time_s": 5.2263,
              "peak_memory_gb": 6.553,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.17,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 11.7095,
                "first_token_latency_s": 0.0511,
                "tokens_per_second": 21.86,
                "memory_before_gb": 8.236,
                "memory_after_gb": 8.236,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 7.609,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 45.72,
                "p90_inter_token_latency_ms": 49.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 10.9415,
                "first_token_latency_s": 0.0595,
                "tokens_per_second": 23.4,
                "memory_before_gb": 8.236,
                "memory_after_gb": 8.273,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 7.646,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 42.67,
                "p90_inter_token_latency_ms": 43.95
              },
              {
                "tokens_generated": 256,
                "total_time_s": 10.9112,
                "first_token_latency_s": 0.07,
                "tokens_per_second": 23.46,
                "memory_before_gb": 8.273,
                "memory_after_gb": 8.273,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.646,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 42.51,
                "p90_inter_token_latency_ms": 44.02
              }
            ],
            "actual_file_size_gb": 7.167,
            "model_load_time_s": 4.57,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 8.237,
            "server_memory_after_load_gb": 7.61,
            "resource_usage": {
              "n_samples": 61,
              "duration_s": 33.0678973197937,
              "cpu": {
                "avg_percent": 55.3,
                "max_percent": 60.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 63.5,
                "max_percent": 63.7,
                "peak_used_gb": 19.82
              },
              "gpu": {
                "avg_utilization_percent": 50.7,
                "max_utilization_percent": 58.0,
                "peak_memory_mb": 7846.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 22.91,
              "std_tokens_per_second": 0.74,
              "min_tokens_per_second": 21.86,
              "max_tokens_per_second": 23.46,
              "avg_first_token_latency_s": 0.0602,
              "avg_inter_token_latency_ms": 43.63,
              "avg_total_time_s": 11.1874,
              "peak_memory_gb": 8.273,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.871,
            "tokens_per_second": 73.87,
            "first_token_latency_s": 0.0282,
            "inter_token_latency_ms": 13.48,
            "peak_memory_gb": 3.948,
            "model_load_time_s": 2.54,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.277,
            "tokens_per_second": 79.08,
            "first_token_latency_s": 0.0306,
            "inter_token_latency_ms": 12.58,
            "peak_memory_gb": 4.348,
            "model_load_time_s": 2.53,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.068,
            "tokens_per_second": 75.12,
            "first_token_latency_s": 0.0322,
            "inter_token_latency_ms": 13.24,
            "peak_memory_gb": 5.116,
            "model_load_time_s": 2.55,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.779,
            "tokens_per_second": 64.99,
            "first_token_latency_s": 0.04,
            "inter_token_latency_ms": 15.29,
            "peak_memory_gb": 5.778,
            "model_load_time_s": 3.56,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.534,
            "tokens_per_second": 48.98,
            "first_token_latency_s": 0.0407,
            "inter_token_latency_ms": 20.33,
            "peak_memory_gb": 6.553,
            "model_load_time_s": 3.57,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.167,
            "tokens_per_second": 22.91,
            "first_token_latency_s": 0.0602,
            "inter_token_latency_ms": 43.63,
            "peak_memory_gb": 8.273,
            "model_load_time_s": 4.57,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.13,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 8.8017,
                "first_token_latency_s": 0.0595,
                "tokens_per_second": 29.09,
                "memory_before_gb": 6.257,
                "memory_after_gb": 6.256,
                "memory_delta_gb": -0.001,
                "server_memory_gb": 5.71,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 34.28,
                "p90_inter_token_latency_ms": 35.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.8759,
                "first_token_latency_s": 0.1081,
                "tokens_per_second": 28.84,
                "memory_before_gb": 6.256,
                "memory_after_gb": 6.511,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 5.965,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 34.38,
                "p90_inter_token_latency_ms": 36.11
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.7829,
                "first_token_latency_s": 0.0604,
                "tokens_per_second": 29.15,
                "memory_before_gb": 6.511,
                "memory_after_gb": 6.511,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.965,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 34.21,
                "p90_inter_token_latency_ms": 35.91
              }
            ],
            "actual_file_size_gb": 5.056,
            "model_load_time_s": 3.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 6.217,
            "server_memory_after_load_gb": 5.671,
            "resource_usage": {
              "n_samples": 49,
              "duration_s": 26.24419069290161,
              "cpu": {
                "avg_percent": 52.9,
                "max_percent": 59.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 57.5,
                "max_percent": 57.9,
                "peak_used_gb": 18.02
              },
              "gpu": {
                "avg_utilization_percent": 72.5,
                "max_utilization_percent": 78.0,
                "peak_memory_mb": 7790.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 29.03,
              "std_tokens_per_second": 0.13,
              "min_tokens_per_second": 28.84,
              "max_tokens_per_second": 29.15,
              "avg_first_token_latency_s": 0.076,
              "avg_inter_token_latency_ms": 34.29,
              "avg_total_time_s": 8.8202,
              "peak_memory_gb": 6.511,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 6.34,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 11.2037,
                "first_token_latency_s": 0.061,
                "tokens_per_second": 22.85,
                "memory_before_gb": 7.25,
                "memory_after_gb": 7.25,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 6.704,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 43.7,
                "p90_inter_token_latency_ms": 46.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 11.2091,
                "first_token_latency_s": 0.1018,
                "tokens_per_second": 22.84,
                "memory_before_gb": 7.25,
                "memory_after_gb": 7.505,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 6.959,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 43.56,
                "p90_inter_token_latency_ms": 46.06
              },
              {
                "tokens_generated": 256,
                "total_time_s": 11.1808,
                "first_token_latency_s": 0.0736,
                "tokens_per_second": 22.9,
                "memory_before_gb": 7.505,
                "memory_after_gb": 7.505,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 6.959,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 43.56,
                "p90_inter_token_latency_ms": 46.43
              }
            ],
            "actual_file_size_gb": 5.903,
            "model_load_time_s": 3.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 7.203,
            "server_memory_after_load_gb": 6.657,
            "resource_usage": {
              "n_samples": 62,
              "duration_s": 33.442249059677124,
              "cpu": {
                "avg_percent": 54.6,
                "max_percent": 58.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 60.4,
                "max_percent": 60.8,
                "peak_used_gb": 18.9
              },
              "gpu": {
                "avg_utilization_percent": 54.6,
                "max_utilization_percent": 62.0,
                "peak_memory_mb": 7798.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 22.86,
              "std_tokens_per_second": 0.03,
              "min_tokens_per_second": 22.84,
              "max_tokens_per_second": 22.9,
              "avg_first_token_latency_s": 0.0788,
              "avg_inter_token_latency_ms": 43.61,
              "avg_total_time_s": 11.1979,
              "peak_memory_gb": 7.505,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.87,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.32,
                "first_token_latency_s": 0.0811,
                "tokens_per_second": 17.88,
                "memory_before_gb": 8.71,
                "memory_after_gb": 8.711,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.292,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.84,
                "p90_inter_token_latency_ms": 60.95
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.2662,
                "first_token_latency_s": 0.1476,
                "tokens_per_second": 17.94,
                "memory_before_gb": 8.711,
                "memory_after_gb": 8.966,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.547,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.37,
                "p90_inter_token_latency_ms": 59.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.4168,
                "first_token_latency_s": 0.0818,
                "tokens_per_second": 17.76,
                "memory_before_gb": 8.966,
                "memory_after_gb": 8.966,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.547,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.22,
                "p90_inter_token_latency_ms": 57.97
              }
            ],
            "actual_file_size_gb": 7.326,
            "model_load_time_s": 4.59,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 8.67,
            "server_memory_after_load_gb": 8.251,
            "resource_usage": {
              "n_samples": 78,
              "duration_s": 42.74139904975891,
              "cpu": {
                "avg_percent": 56.3,
                "max_percent": 100.0,
                "min_percent": 52.2
              },
              "ram": {
                "avg_percent": 64.2,
                "max_percent": 64.6,
                "peak_used_gb": 20.09
              },
              "gpu": {
                "avg_utilization_percent": 35.1,
                "max_utilization_percent": 50.0,
                "peak_memory_mb": 7858.0,
                "max_temperature_c": 51.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.86,
              "std_tokens_per_second": 0.07,
              "min_tokens_per_second": 17.76,
              "max_tokens_per_second": 17.94,
              "avg_first_token_latency_s": 0.1035,
              "avg_inter_token_latency_ms": 55.81,
              "avg_total_time_s": 14.3343,
              "peak_memory_gb": 8.966,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.6,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 20.212,
                "first_token_latency_s": 0.0833,
                "tokens_per_second": 12.67,
                "memory_before_gb": 9.918,
                "memory_after_gb": 9.919,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.578,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 78.94,
                "p90_inter_token_latency_ms": 82.26
              },
              {
                "tokens_generated": 256,
                "total_time_s": 20.4135,
                "first_token_latency_s": 0.144,
                "tokens_per_second": 12.54,
                "memory_before_gb": 9.919,
                "memory_after_gb": 10.174,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 9.833,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 79.49,
                "p90_inter_token_latency_ms": 81.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 20.3521,
                "first_token_latency_s": 0.0927,
                "tokens_per_second": 12.58,
                "memory_before_gb": 10.174,
                "memory_after_gb": 10.174,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 9.833,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 79.45,
                "p90_inter_token_latency_ms": 81.16
              }
            ],
            "actual_file_size_gb": 8.596,
            "model_load_time_s": 4.6,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 9.878,
            "server_memory_after_load_gb": 9.536,
            "resource_usage": {
              "n_samples": 110,
              "duration_s": 60.47269153594971,
              "cpu": {
                "avg_percent": 57.4,
                "max_percent": 62.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 67.3,
                "max_percent": 67.5,
                "peak_used_gb": 21.01
              },
              "gpu": {
                "avg_utilization_percent": 35.2,
                "max_utilization_percent": 50.0,
                "peak_memory_mb": 7759.0,
                "max_temperature_c": 47.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 12.6,
              "std_tokens_per_second": 0.05,
              "min_tokens_per_second": 12.54,
              "max_tokens_per_second": 12.67,
              "avg_first_token_latency_s": 0.1067,
              "avg_inter_token_latency_ms": 79.29,
              "avg_total_time_s": 20.3259,
              "peak_memory_gb": 10.174,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.95,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 26.2631,
                "first_token_latency_s": 0.1172,
                "tokens_per_second": 9.75,
                "memory_before_gb": 11.381,
                "memory_after_gb": 11.382,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 11.101,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 102.53,
                "p90_inter_token_latency_ms": 109.59
              },
              {
                "tokens_generated": 256,
                "total_time_s": 26.4674,
                "first_token_latency_s": 0.1859,
                "tokens_per_second": 9.67,
                "memory_before_gb": 11.382,
                "memory_after_gb": 11.583,
                "memory_delta_gb": 0.201,
                "server_memory_gb": 11.356,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 103.06,
                "p90_inter_token_latency_ms": 111.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 26.2904,
                "first_token_latency_s": 0.1252,
                "tokens_per_second": 9.74,
                "memory_before_gb": 11.583,
                "memory_after_gb": 11.583,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 11.356,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 102.61,
                "p90_inter_token_latency_ms": 110.75
              }
            ],
            "actual_file_size_gb": 9.946,
            "model_load_time_s": 5.57,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 11.35,
            "server_memory_after_load_gb": 11.069,
            "resource_usage": {
              "n_samples": 143,
              "duration_s": 78.85572361946106,
              "cpu": {
                "avg_percent": 57.7,
                "max_percent": 68.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 68.2,
                "max_percent": 71.0,
                "peak_used_gb": 22.1
              },
              "gpu": {
                "avg_utilization_percent": 34.7,
                "max_utilization_percent": 48.0,
                "peak_memory_mb": 7778.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 9.72,
              "std_tokens_per_second": 0.04,
              "min_tokens_per_second": 9.67,
              "max_tokens_per_second": 9.75,
              "avg_first_token_latency_s": 0.1428,
              "avg_inter_token_latency_ms": 102.73,
              "avg_total_time_s": 26.3403,
              "peak_memory_gb": 11.583,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 13.83,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 37.2596,
                "first_token_latency_s": 0.1577,
                "tokens_per_second": 6.87,
                "memory_before_gb": 14.278,
                "memory_after_gb": 14.279,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 14.072,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 145.5,
                "p90_inter_token_latency_ms": 148.45
              },
              {
                "tokens_generated": 256,
                "total_time_s": 37.2803,
                "first_token_latency_s": 0.2224,
                "tokens_per_second": 6.87,
                "memory_before_gb": 14.279,
                "memory_after_gb": 14.534,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 14.327,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 145.32,
                "p90_inter_token_latency_ms": 152.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 38.3597,
                "first_token_latency_s": 0.1689,
                "tokens_per_second": 6.67,
                "memory_before_gb": 14.534,
                "memory_after_gb": 14.534,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 14.327,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 149.77,
                "p90_inter_token_latency_ms": 155.88
              }
            ],
            "actual_file_size_gb": 12.881,
            "model_load_time_s": 5.59,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 14.244,
            "server_memory_after_load_gb": 14.037,
            "resource_usage": {
              "n_samples": 201,
              "duration_s": 112.50038862228394,
              "cpu": {
                "avg_percent": 55.6,
                "max_percent": 63.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 75.3,
                "max_percent": 75.6,
                "peak_used_gb": 23.52
              },
              "gpu": {
                "avg_utilization_percent": 30.1,
                "max_utilization_percent": 62.0,
                "peak_memory_mb": 7629.0,
                "max_temperature_c": 52.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 6.8,
              "std_tokens_per_second": 0.09,
              "min_tokens_per_second": 6.67,
              "max_tokens_per_second": 6.87,
              "avg_first_token_latency_s": 0.183,
              "avg_inter_token_latency_ms": 146.86,
              "avg_total_time_s": 37.6332,
              "peak_memory_gb": 14.534,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.056,
            "tokens_per_second": 29.03,
            "first_token_latency_s": 0.076,
            "inter_token_latency_ms": 34.29,
            "peak_memory_gb": 6.511,
            "model_load_time_s": 3.56,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 5.903,
            "tokens_per_second": 22.86,
            "first_token_latency_s": 0.0788,
            "inter_token_latency_ms": 43.61,
            "peak_memory_gb": 7.505,
            "model_load_time_s": 3.56,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.326,
            "tokens_per_second": 17.86,
            "first_token_latency_s": 0.1035,
            "inter_token_latency_ms": 55.81,
            "peak_memory_gb": 8.966,
            "model_load_time_s": 4.59,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.596,
            "tokens_per_second": 12.6,
            "first_token_latency_s": 0.1067,
            "inter_token_latency_ms": 79.29,
            "peak_memory_gb": 10.174,
            "model_load_time_s": 4.6,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.946,
            "tokens_per_second": 9.72,
            "first_token_latency_s": 0.1428,
            "inter_token_latency_ms": 102.73,
            "peak_memory_gb": 11.583,
            "model_load_time_s": 5.57,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 12.881,
            "tokens_per_second": 6.8,
            "first_token_latency_s": 0.183,
            "inter_token_latency_ms": 146.86,
            "peak_memory_gb": 14.534,
            "model_load_time_s": 5.59,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.726,
                "first_token_latency_s": 0.0278,
                "tokens_per_second": 352.61,
                "memory_before_gb": 1.135,
                "memory_after_gb": 1.135,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.928,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.74,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7413,
                "first_token_latency_s": 0.0306,
                "tokens_per_second": 345.34,
                "memory_before_gb": 1.135,
                "memory_after_gb": 1.142,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.79,
                "p90_inter_token_latency_ms": 2.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.765,
                "first_token_latency_s": 0.0171,
                "tokens_per_second": 334.66,
                "memory_before_gb": 1.142,
                "memory_after_gb": 1.142,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.93,
                "p90_inter_token_latency_ms": 3.36
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 344.2,
              "std_tokens_per_second": 7.37,
              "avg_first_token_latency_s": 0.0252,
              "avg_inter_token_latency_ms": 2.82,
              "avg_total_time_s": 0.7441,
              "peak_memory_gb": 1.142,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1816935539245605,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 9.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 32.5,
                "max_percent": 32.6,
                "peak_used_gb": 10.13
              },
              "gpu": {
                "avg_utilization_percent": 79.2,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2554.0,
                "max_temperature_c": 66.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7188,
                "first_token_latency_s": 0.0059,
                "tokens_per_second": 356.15,
                "memory_before_gb": 1.142,
                "memory_after_gb": 1.142,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.8,
                "p90_inter_token_latency_ms": 2.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.73,
                "first_token_latency_s": 0.0184,
                "tokens_per_second": 350.7,
                "memory_before_gb": 1.142,
                "memory_after_gb": 1.149,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.942,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.79,
                "p90_inter_token_latency_ms": 2.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7714,
                "first_token_latency_s": 0.0273,
                "tokens_per_second": 331.88,
                "memory_before_gb": 1.149,
                "memory_after_gb": 1.149,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.942,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.92,
                "p90_inter_token_latency_ms": 3.42
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 346.24,
              "std_tokens_per_second": 10.4,
              "avg_first_token_latency_s": 0.0172,
              "avg_inter_token_latency_ms": 2.84,
              "avg_total_time_s": 0.7401,
              "peak_memory_gb": 1.149,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.141765594482422,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 12.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 32.6,
                "max_percent": 32.6,
                "peak_used_gb": 10.15
              },
              "gpu": {
                "avg_utilization_percent": 72.4,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2545.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7163,
                "first_token_latency_s": 0.0062,
                "tokens_per_second": 357.41,
                "memory_before_gb": 1.149,
                "memory_after_gb": 1.149,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.942,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.83
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.731,
                "first_token_latency_s": 0.0218,
                "tokens_per_second": 350.21,
                "memory_before_gb": 1.149,
                "memory_after_gb": 1.156,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.949,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7261,
                "first_token_latency_s": 0.0163,
                "tokens_per_second": 352.55,
                "memory_before_gb": 1.156,
                "memory_after_gb": 1.156,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.949,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.81
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 353.39,
              "std_tokens_per_second": 3.0,
              "avg_first_token_latency_s": 0.0148,
              "avg_inter_token_latency_ms": 2.78,
              "avg_total_time_s": 0.7245,
              "peak_memory_gb": 1.156,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.129169464111328,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 12.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 32.6,
                "max_percent": 32.7,
                "peak_used_gb": 10.16
              },
              "gpu": {
                "avg_utilization_percent": 88.0,
                "max_utilization_percent": 88.0,
                "peak_memory_mb": 2545.0,
                "max_temperature_c": 68.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 344.2,
            "first_token_latency_s": 0.0252,
            "inter_token_latency_ms": 2.82,
            "peak_memory_gb": 1.142,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 346.24,
            "first_token_latency_s": 0.0172,
            "inter_token_latency_ms": 2.84,
            "peak_memory_gb": 1.149,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 353.39,
            "first_token_latency_s": 0.0148,
            "inter_token_latency_ms": 2.78,
            "peak_memory_gb": 1.156,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "temperature",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1802,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 80.5,
                "memory_before_gb": 4.56,
                "memory_after_gb": 4.561,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.354,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.37,
                "p90_inter_token_latency_ms": 13.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1521,
                "first_token_latency_s": 0.0413,
                "tokens_per_second": 81.22,
                "memory_before_gb": 4.561,
                "memory_after_gb": 4.598,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.2,
                "p90_inter_token_latency_ms": 12.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1434,
                "first_token_latency_s": 0.0312,
                "tokens_per_second": 81.44,
                "memory_before_gb": 4.598,
                "memory_after_gb": 4.598,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.2,
                "p90_inter_token_latency_ms": 12.84
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 81.05,
              "std_tokens_per_second": 0.4,
              "avg_first_token_latency_s": 0.0324,
              "avg_inter_token_latency_ms": 12.26,
              "avg_total_time_s": 3.1586,
              "peak_memory_gb": 4.598,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.109580278396606,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 9.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.8,
                "max_percent": 43.8,
                "peak_used_gb": 13.63
              },
              "gpu": {
                "avg_utilization_percent": 95.8,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6301.0,
                "max_temperature_c": 72.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1488,
                "first_token_latency_s": 0.0331,
                "tokens_per_second": 81.3,
                "memory_before_gb": 4.598,
                "memory_after_gb": 4.598,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.391,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.22,
                "p90_inter_token_latency_ms": 12.94
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1941,
                "first_token_latency_s": 0.037,
                "tokens_per_second": 80.15,
                "memory_before_gb": 4.598,
                "memory_after_gb": 4.635,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.427,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.38,
                "p90_inter_token_latency_ms": 13.34
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1513,
                "first_token_latency_s": 0.036,
                "tokens_per_second": 81.24,
                "memory_before_gb": 4.635,
                "memory_after_gb": 4.635,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.427,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.22,
                "p90_inter_token_latency_ms": 12.88
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.9,
              "std_tokens_per_second": 0.53,
              "avg_first_token_latency_s": 0.0354,
              "avg_inter_token_latency_ms": 12.27,
              "avg_total_time_s": 3.1647,
              "peak_memory_gb": 4.635,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.143095254898071,
              "cpu": {
                "avg_percent": 7.7,
                "max_percent": 11.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.9,
                "max_percent": 43.9,
                "peak_used_gb": 13.67
              },
              "gpu": {
                "avg_utilization_percent": 93.2,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6301.0,
                "max_temperature_c": 74.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1295,
                "first_token_latency_s": 0.0154,
                "tokens_per_second": 81.8,
                "memory_before_gb": 4.635,
                "memory_after_gb": 4.635,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.428,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.21,
                "p90_inter_token_latency_ms": 12.85
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1487,
                "first_token_latency_s": 0.0363,
                "tokens_per_second": 81.3,
                "memory_before_gb": 4.635,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.464,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.2,
                "p90_inter_token_latency_ms": 12.83
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1926,
                "first_token_latency_s": 0.0306,
                "tokens_per_second": 80.18,
                "memory_before_gb": 4.672,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.464,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.4,
                "p90_inter_token_latency_ms": 13.34
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 81.09,
              "std_tokens_per_second": 0.68,
              "avg_first_token_latency_s": 0.0274,
              "avg_inter_token_latency_ms": 12.27,
              "avg_total_time_s": 3.1569,
              "peak_memory_gb": 4.672,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.097635507583618,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 44.0,
                "max_percent": 44.1,
                "peak_used_gb": 13.71
              },
              "gpu": {
                "avg_utilization_percent": 96.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6301.0,
                "max_temperature_c": 77.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 81.05,
            "first_token_latency_s": 0.0324,
            "inter_token_latency_ms": 12.26,
            "peak_memory_gb": 4.598,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 80.9,
            "first_token_latency_s": 0.0354,
            "inter_token_latency_ms": 12.27,
            "peak_memory_gb": 4.635,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 81.09,
            "first_token_latency_s": 0.0274,
            "inter_token_latency_ms": 12.27,
            "peak_memory_gb": 4.672,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "temperature",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.6983,
                "first_token_latency_s": 0.0594,
                "tokens_per_second": 17.42,
                "memory_before_gb": 8.458,
                "memory_after_gb": 8.437,
                "memory_delta_gb": -0.021,
                "server_memory_gb": 8.23,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.41,
                "p90_inter_token_latency_ms": 60.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8319,
                "first_token_latency_s": 0.141,
                "tokens_per_second": 17.26,
                "memory_before_gb": 8.437,
                "memory_after_gb": 8.692,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.485,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.61,
                "p90_inter_token_latency_ms": 60.61
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.7872,
                "first_token_latency_s": 0.0815,
                "tokens_per_second": 17.31,
                "memory_before_gb": 8.692,
                "memory_after_gb": 8.692,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.485,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.67,
                "p90_inter_token_latency_ms": 60.67
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.33,
              "std_tokens_per_second": 0.07,
              "avg_first_token_latency_s": 0.094,
              "avg_inter_token_latency_ms": 57.56,
              "avg_total_time_s": 14.7725,
              "peak_memory_gb": 8.692,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.79835271835327,
              "cpu": {
                "avg_percent": 54.1,
                "max_percent": 61.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 56.9,
                "max_percent": 57.2,
                "peak_used_gb": 17.78
              },
              "gpu": {
                "avg_utilization_percent": 35.5,
                "max_utilization_percent": 45.0,
                "peak_memory_mb": 7798.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.7987,
                "first_token_latency_s": 0.0821,
                "tokens_per_second": 17.3,
                "memory_before_gb": 8.692,
                "memory_after_gb": 8.644,
                "memory_delta_gb": -0.048,
                "server_memory_gb": 8.485,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.71,
                "p90_inter_token_latency_ms": 62.15
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6135,
                "first_token_latency_s": 0.1319,
                "tokens_per_second": 17.52,
                "memory_before_gb": 8.644,
                "memory_after_gb": 8.898,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.74,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.79,
                "p90_inter_token_latency_ms": 60.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.4583,
                "first_token_latency_s": 0.0689,
                "tokens_per_second": 17.71,
                "memory_before_gb": 8.898,
                "memory_after_gb": 8.899,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.74,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.43,
                "p90_inter_token_latency_ms": 59.9
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.51,
              "std_tokens_per_second": 0.17,
              "avg_first_token_latency_s": 0.0943,
              "avg_inter_token_latency_ms": 56.98,
              "avg_total_time_s": 14.6235,
              "peak_memory_gb": 8.899,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.74028944969177,
              "cpu": {
                "avg_percent": 54.8,
                "max_percent": 65.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 54.6,
                "max_percent": 57.2,
                "peak_used_gb": 17.78
              },
              "gpu": {
                "avg_utilization_percent": 35.0,
                "max_utilization_percent": 50.0,
                "peak_memory_mb": 7807.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.5782,
                "first_token_latency_s": 0.0802,
                "tokens_per_second": 17.56,
                "memory_before_gb": 8.899,
                "memory_after_gb": 8.899,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.74,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.85,
                "p90_inter_token_latency_ms": 60.16
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6153,
                "first_token_latency_s": 0.132,
                "tokens_per_second": 17.52,
                "memory_before_gb": 8.899,
                "memory_after_gb": 9.154,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.995,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.8,
                "p90_inter_token_latency_ms": 60.19
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8177,
                "first_token_latency_s": 0.0815,
                "tokens_per_second": 17.28,
                "memory_before_gb": 9.154,
                "memory_after_gb": 9.154,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.995,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.79,
                "p90_inter_token_latency_ms": 60.84
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.45,
              "std_tokens_per_second": 0.12,
              "avg_first_token_latency_s": 0.0979,
              "avg_inter_token_latency_ms": 57.15,
              "avg_total_time_s": 14.6704,
              "peak_memory_gb": 9.154,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.62294936180115,
              "cpu": {
                "avg_percent": 54.3,
                "max_percent": 63.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 54.4,
                "max_percent": 54.8,
                "peak_used_gb": 17.05
              },
              "gpu": {
                "avg_utilization_percent": 34.8,
                "max_utilization_percent": 45.0,
                "peak_memory_mb": 7811.0,
                "max_temperature_c": 52.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 17.33,
            "first_token_latency_s": 0.094,
            "inter_token_latency_ms": 57.56,
            "peak_memory_gb": 8.692,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 17.51,
            "first_token_latency_s": 0.0943,
            "inter_token_latency_ms": 56.98,
            "peak_memory_gb": 8.899,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 17.45,
            "first_token_latency_s": 0.0979,
            "inter_token_latency_ms": 57.15,
            "peak_memory_gb": 9.154,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7176,
                "first_token_latency_s": 0.02,
                "tokens_per_second": 356.75,
                "memory_before_gb": 1.086,
                "memory_after_gb": 1.087,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.928,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.74,
                "p90_inter_token_latency_ms": 2.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7411,
                "first_token_latency_s": 0.0223,
                "tokens_per_second": 345.42,
                "memory_before_gb": 1.087,
                "memory_after_gb": 1.094,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.82,
                "p90_inter_token_latency_ms": 2.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7279,
                "first_token_latency_s": 0.0292,
                "tokens_per_second": 351.69,
                "memory_before_gb": 1.094,
                "memory_after_gb": 1.094,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.74,
                "p90_inter_token_latency_ms": 2.8
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 351.29,
              "std_tokens_per_second": 4.63,
              "avg_first_token_latency_s": 0.0238,
              "avg_inter_token_latency_ms": 2.77,
              "avg_total_time_s": 0.7289,
              "peak_memory_gb": 1.094,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1484878063201904,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 10.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.8,
                "max_percent": 28.8,
                "peak_used_gb": 8.96
              },
              "gpu": {
                "avg_utilization_percent": 72.8,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2537.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8009,
                "first_token_latency_s": 0.0303,
                "tokens_per_second": 319.65,
                "memory_before_gb": 1.094,
                "memory_after_gb": 1.095,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.936,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.02,
                "p90_inter_token_latency_ms": 3.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7302,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 350.58,
                "memory_before_gb": 1.095,
                "memory_after_gb": 1.103,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.944,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.77,
                "p90_inter_token_latency_ms": 2.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7343,
                "first_token_latency_s": 0.0208,
                "tokens_per_second": 348.64,
                "memory_before_gb": 1.103,
                "memory_after_gb": 1.11,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.951,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.8,
                "p90_inter_token_latency_ms": 2.82
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 339.62,
              "std_tokens_per_second": 14.15,
              "avg_first_token_latency_s": 0.0246,
              "avg_inter_token_latency_ms": 2.86,
              "avg_total_time_s": 0.7551,
              "peak_memory_gb": 1.11,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.132631778717041,
              "cpu": {
                "avg_percent": 16.5,
                "max_percent": 39.7,
                "min_percent": 8.1
              },
              "ram": {
                "avg_percent": 28.9,
                "max_percent": 28.9,
                "peak_used_gb": 8.99
              },
              "gpu": {
                "avg_utilization_percent": 70.4,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2537.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.72,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 355.56,
                "memory_before_gb": 1.11,
                "memory_after_gb": 1.111,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.952,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.77,
                "p90_inter_token_latency_ms": 2.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7174,
                "first_token_latency_s": 0.0069,
                "tokens_per_second": 356.82,
                "memory_before_gb": 1.111,
                "memory_after_gb": 1.118,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.959,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.79,
                "p90_inter_token_latency_ms": 2.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7274,
                "first_token_latency_s": 0.0187,
                "tokens_per_second": 351.95,
                "memory_before_gb": 1.118,
                "memory_after_gb": 1.126,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.967,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.81
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 354.78,
              "std_tokens_per_second": 2.06,
              "avg_first_token_latency_s": 0.0131,
              "avg_inter_token_latency_ms": 2.78,
              "avg_total_time_s": 0.7216,
              "peak_memory_gb": 1.126,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.175853729248047,
              "cpu": {
                "avg_percent": 7.7,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.0,
                "max_percent": 29.0,
                "peak_used_gb": 9.03
              },
              "gpu": {
                "avg_utilization_percent": 69.6,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2537.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7195,
                "first_token_latency_s": 0.0112,
                "tokens_per_second": 355.82,
                "memory_before_gb": 1.126,
                "memory_after_gb": 1.127,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.967,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7874,
                "first_token_latency_s": 0.0219,
                "tokens_per_second": 325.14,
                "memory_before_gb": 1.127,
                "memory_after_gb": 1.134,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.975,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.0,
                "p90_inter_token_latency_ms": 3.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7516,
                "first_token_latency_s": 0.0266,
                "tokens_per_second": 340.62,
                "memory_before_gb": 1.134,
                "memory_after_gb": 1.141,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.982,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.84,
                "p90_inter_token_latency_ms": 2.95
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 340.53,
              "std_tokens_per_second": 12.53,
              "avg_first_token_latency_s": 0.0199,
              "avg_inter_token_latency_ms": 2.87,
              "avg_total_time_s": 0.7528,
              "peak_memory_gb": 1.141,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1444194316864014,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.0,
                "max_percent": 29.1,
                "peak_used_gb": 9.05
              },
              "gpu": {
                "avg_utilization_percent": 58.8,
                "max_utilization_percent": 88.0,
                "peak_memory_mb": 2537.0,
                "max_temperature_c": 66.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7651,
                "first_token_latency_s": 0.0332,
                "tokens_per_second": 334.58,
                "memory_before_gb": 1.141,
                "memory_after_gb": 1.142,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.983,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.87,
                "p90_inter_token_latency_ms": 2.94
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7683,
                "first_token_latency_s": 0.0255,
                "tokens_per_second": 333.19,
                "memory_before_gb": 1.142,
                "memory_after_gb": 1.149,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.99,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.91,
                "p90_inter_token_latency_ms": 2.98
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7398,
                "first_token_latency_s": 0.0242,
                "tokens_per_second": 346.06,
                "memory_before_gb": 1.149,
                "memory_after_gb": 1.157,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.997,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.81,
                "p90_inter_token_latency_ms": 2.9
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 337.94,
              "std_tokens_per_second": 5.77,
              "avg_first_token_latency_s": 0.0276,
              "avg_inter_token_latency_ms": 2.86,
              "avg_total_time_s": 0.7577,
              "peak_memory_gb": 1.157,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1351335048675537,
              "cpu": {
                "avg_percent": 6.4,
                "max_percent": 8.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.1,
                "max_percent": 29.1,
                "peak_used_gb": 9.06
              },
              "gpu": {
                "avg_utilization_percent": 66.2,
                "max_utilization_percent": 88.0,
                "peak_memory_mb": 2537.0,
                "max_temperature_c": 66.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7831,
                "first_token_latency_s": 0.0412,
                "tokens_per_second": 326.9,
                "memory_before_gb": 1.157,
                "memory_after_gb": 1.157,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.998,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.91,
                "p90_inter_token_latency_ms": 2.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7363,
                "first_token_latency_s": 0.0274,
                "tokens_per_second": 347.66,
                "memory_before_gb": 1.157,
                "memory_after_gb": 1.166,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 1.007,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7687,
                "first_token_latency_s": 0.0197,
                "tokens_per_second": 333.04,
                "memory_before_gb": 1.166,
                "memory_after_gb": 1.174,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.015,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.94,
                "p90_inter_token_latency_ms": 3.41
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 335.87,
              "std_tokens_per_second": 8.71,
              "avg_first_token_latency_s": 0.0294,
              "avg_inter_token_latency_ms": 2.88,
              "avg_total_time_s": 0.7627,
              "peak_memory_gb": 1.174,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.131286382675171,
              "cpu": {
                "avg_percent": 6.8,
                "max_percent": 9.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.2,
                "max_percent": 29.3,
                "peak_used_gb": 9.11
              },
              "gpu": {
                "avg_utilization_percent": 71.0,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2539.0,
                "max_temperature_c": 66.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 351.29,
            "first_token_latency_s": 0.0238,
            "inter_token_latency_ms": 2.77,
            "peak_memory_gb": 1.094,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 339.62,
            "first_token_latency_s": 0.0246,
            "inter_token_latency_ms": 2.86,
            "peak_memory_gb": 1.11,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 354.78,
            "first_token_latency_s": 0.0131,
            "inter_token_latency_ms": 2.78,
            "peak_memory_gb": 1.126,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 340.53,
            "first_token_latency_s": 0.0199,
            "inter_token_latency_ms": 2.87,
            "peak_memory_gb": 1.141,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 337.94,
            "first_token_latency_s": 0.0276,
            "inter_token_latency_ms": 2.86,
            "peak_memory_gb": 1.157,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 335.87,
            "first_token_latency_s": 0.0294,
            "inter_token_latency_ms": 2.88,
            "peak_memory_gb": 1.174,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "language",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.2005,
                "first_token_latency_s": 0.0355,
                "tokens_per_second": 79.99,
                "memory_before_gb": 4.512,
                "memory_after_gb": 4.513,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.354,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.41,
                "p90_inter_token_latency_ms": 13.35
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1477,
                "first_token_latency_s": 0.0351,
                "tokens_per_second": 81.33,
                "memory_before_gb": 4.513,
                "memory_after_gb": 4.55,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.21,
                "p90_inter_token_latency_ms": 12.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1395,
                "first_token_latency_s": 0.015,
                "tokens_per_second": 81.54,
                "memory_before_gb": 4.55,
                "memory_after_gb": 4.55,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.25,
                "p90_inter_token_latency_ms": 12.89
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.95,
              "std_tokens_per_second": 0.69,
              "avg_first_token_latency_s": 0.0285,
              "avg_inter_token_latency_ms": 12.29,
              "avg_total_time_s": 3.1626,
              "peak_memory_gb": 4.55,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.089001417160034,
              "cpu": {
                "avg_percent": 7.0,
                "max_percent": 9.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.1,
                "max_percent": 40.1,
                "peak_used_gb": 12.48
              },
              "gpu": {
                "avg_utilization_percent": 96.2,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6293.0,
                "max_temperature_c": 70.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1739,
                "first_token_latency_s": 0.0526,
                "tokens_per_second": 80.66,
                "memory_before_gb": 4.55,
                "memory_after_gb": 4.551,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 4.392,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.24,
                "p90_inter_token_latency_ms": 12.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1747,
                "first_token_latency_s": 0.0413,
                "tokens_per_second": 80.64,
                "memory_before_gb": 4.551,
                "memory_after_gb": 4.591,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.431,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.29,
                "p90_inter_token_latency_ms": 13.04
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1783,
                "first_token_latency_s": 0.0436,
                "tokens_per_second": 80.55,
                "memory_before_gb": 4.591,
                "memory_after_gb": 4.63,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.47,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.29,
                "p90_inter_token_latency_ms": 12.98
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.62,
              "std_tokens_per_second": 0.05,
              "avg_first_token_latency_s": 0.0458,
              "avg_inter_token_latency_ms": 12.27,
              "avg_total_time_s": 3.1756,
              "peak_memory_gb": 4.63,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.112215518951416,
              "cpu": {
                "avg_percent": 7.1,
                "max_percent": 10.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.3,
                "max_percent": 40.4,
                "peak_used_gb": 12.56
              },
              "gpu": {
                "avg_utilization_percent": 96.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6293.0,
                "max_temperature_c": 73.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 238,
                "total_time_s": 3.1691,
                "first_token_latency_s": 0.0503,
                "tokens_per_second": 75.1,
                "memory_before_gb": 4.63,
                "memory_after_gb": 4.631,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.471,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.16,
                "p90_inter_token_latency_ms": 13.11
              },
              {
                "tokens_generated": 253,
                "total_time_s": 3.1752,
                "first_token_latency_s": 0.0356,
                "tokens_per_second": 79.68,
                "memory_before_gb": 4.631,
                "memory_after_gb": 4.67,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.51,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.46,
                "p90_inter_token_latency_ms": 13.02
              },
              {
                "tokens_generated": 253,
                "total_time_s": 3.1976,
                "first_token_latency_s": 0.0335,
                "tokens_per_second": 79.12,
                "memory_before_gb": 4.67,
                "memory_after_gb": 4.709,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.549,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.56,
                "p90_inter_token_latency_ms": 13.4
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 77.97,
              "std_tokens_per_second": 2.04,
              "avg_first_token_latency_s": 0.0398,
              "avg_inter_token_latency_ms": 12.73,
              "avg_total_time_s": 3.1806,
              "peak_memory_gb": 4.709,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.060442447662354,
              "cpu": {
                "avg_percent": 6.6,
                "max_percent": 10.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.5,
                "max_percent": 40.6,
                "peak_used_gb": 12.65
              },
              "gpu": {
                "avg_utilization_percent": 92.9,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6293.0,
                "max_temperature_c": 76.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1842,
                "first_token_latency_s": 0.0459,
                "tokens_per_second": 80.4,
                "memory_before_gb": 4.709,
                "memory_after_gb": 4.71,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.55,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.31,
                "p90_inter_token_latency_ms": 12.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1858,
                "first_token_latency_s": 0.0448,
                "tokens_per_second": 80.36,
                "memory_before_gb": 4.71,
                "memory_after_gb": 4.75,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.59,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.32,
                "p90_inter_token_latency_ms": 12.99
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1526,
                "first_token_latency_s": 0.0329,
                "tokens_per_second": 81.2,
                "memory_before_gb": 4.75,
                "memory_after_gb": 4.79,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.63,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.23,
                "p90_inter_token_latency_ms": 12.91
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.65,
              "std_tokens_per_second": 0.39,
              "avg_first_token_latency_s": 0.0412,
              "avg_inter_token_latency_ms": 12.29,
              "avg_total_time_s": 3.1742,
              "peak_memory_gb": 4.79,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.08984375,
              "cpu": {
                "avg_percent": 6.5,
                "max_percent": 9.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.7,
                "max_percent": 40.9,
                "peak_used_gb": 12.72
              },
              "gpu": {
                "avg_utilization_percent": 95.2,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6293.0,
                "max_temperature_c": 78.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1749,
                "first_token_latency_s": 0.0328,
                "tokens_per_second": 80.63,
                "memory_before_gb": 4.79,
                "memory_after_gb": 4.79,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.63,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.32,
                "p90_inter_token_latency_ms": 12.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1691,
                "first_token_latency_s": 0.0429,
                "tokens_per_second": 80.78,
                "memory_before_gb": 4.79,
                "memory_after_gb": 4.83,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.671,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.26,
                "p90_inter_token_latency_ms": 12.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1724,
                "first_token_latency_s": 0.045,
                "tokens_per_second": 80.7,
                "memory_before_gb": 4.83,
                "memory_after_gb": 4.87,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.711,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.26,
                "p90_inter_token_latency_ms": 12.98
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.7,
              "std_tokens_per_second": 0.06,
              "avg_first_token_latency_s": 0.0402,
              "avg_inter_token_latency_ms": 12.28,
              "avg_total_time_s": 3.1721,
              "peak_memory_gb": 4.87,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.148591756820679,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 10.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.9,
                "max_percent": 41.1,
                "peak_used_gb": 12.78
              },
              "gpu": {
                "avg_utilization_percent": 96.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6293.0,
                "max_temperature_c": 79.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 242,
                "total_time_s": 3.3025,
                "first_token_latency_s": 0.0554,
                "tokens_per_second": 73.28,
                "memory_before_gb": 4.87,
                "memory_after_gb": 4.871,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.711,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 13.47,
                "p90_inter_token_latency_ms": 13.77
              },
              {
                "tokens_generated": 248,
                "total_time_s": 3.2153,
                "first_token_latency_s": 0.0417,
                "tokens_per_second": 77.13,
                "memory_before_gb": 4.871,
                "memory_after_gb": 4.917,
                "memory_delta_gb": 0.045,
                "server_memory_gb": 4.757,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.85,
                "p90_inter_token_latency_ms": 13.32
              },
              {
                "tokens_generated": 248,
                "total_time_s": 3.2415,
                "first_token_latency_s": 0.0461,
                "tokens_per_second": 76.51,
                "memory_before_gb": 4.917,
                "memory_after_gb": 4.962,
                "memory_delta_gb": 0.045,
                "server_memory_gb": 4.802,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.94,
                "p90_inter_token_latency_ms": 13.55
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 75.64,
              "std_tokens_per_second": 1.69,
              "avg_first_token_latency_s": 0.0477,
              "avg_inter_token_latency_ms": 13.09,
              "avg_total_time_s": 3.2531,
              "peak_memory_gb": 4.962,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 19,
              "duration_s": 9.60235857963562,
              "cpu": {
                "avg_percent": 6.5,
                "max_percent": 9.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 41.3,
                "max_percent": 41.5,
                "peak_used_gb": 12.9
              },
              "gpu": {
                "avg_utilization_percent": 94.6,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6297.0,
                "max_temperature_c": 81.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 80.95,
            "first_token_latency_s": 0.0285,
            "inter_token_latency_ms": 12.29,
            "peak_memory_gb": 4.55,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 80.62,
            "first_token_latency_s": 0.0458,
            "inter_token_latency_ms": 12.27,
            "peak_memory_gb": 4.63,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 77.97,
            "first_token_latency_s": 0.0398,
            "inter_token_latency_ms": 12.73,
            "peak_memory_gb": 4.709,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 80.65,
            "first_token_latency_s": 0.0412,
            "inter_token_latency_ms": 12.29,
            "peak_memory_gb": 4.79,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 80.7,
            "first_token_latency_s": 0.0402,
            "inter_token_latency_ms": 12.28,
            "peak_memory_gb": 4.87,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 75.64,
            "first_token_latency_s": 0.0477,
            "inter_token_latency_ms": 13.09,
            "peak_memory_gb": 4.962,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "language",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.5403,
                "first_token_latency_s": 0.0589,
                "tokens_per_second": 17.61,
                "memory_before_gb": 8.389,
                "memory_after_gb": 8.39,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.23,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.79,
                "p90_inter_token_latency_ms": 60.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.3322,
                "first_token_latency_s": 0.1015,
                "tokens_per_second": 17.86,
                "memory_before_gb": 8.39,
                "memory_after_gb": 8.645,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.485,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.81,
                "p90_inter_token_latency_ms": 59.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6741,
                "first_token_latency_s": 0.0748,
                "tokens_per_second": 17.45,
                "memory_before_gb": 8.645,
                "memory_after_gb": 8.645,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.485,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.25,
                "p90_inter_token_latency_ms": 60.38
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.64,
              "std_tokens_per_second": 0.17,
              "avg_first_token_latency_s": 0.0784,
              "avg_inter_token_latency_ms": 56.62,
              "avg_total_time_s": 14.5155,
              "peak_memory_gb": 8.645,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.503735303878784,
              "cpu": {
                "avg_percent": 53.5,
                "max_percent": 63.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 53.1,
                "max_percent": 53.4,
                "peak_used_gb": 16.63
              },
              "gpu": {
                "avg_utilization_percent": 34.2,
                "max_utilization_percent": 46.0,
                "peak_memory_mb": 7803.0,
                "max_temperature_c": 51.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.5217,
                "first_token_latency_s": 0.2497,
                "tokens_per_second": 17.63,
                "memory_before_gb": 8.645,
                "memory_after_gb": 8.646,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.486,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.97,
                "p90_inter_token_latency_ms": 60.35
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.7902,
                "first_token_latency_s": 0.116,
                "tokens_per_second": 17.31,
                "memory_before_gb": 8.646,
                "memory_after_gb": 8.913,
                "memory_delta_gb": 0.267,
                "server_memory_gb": 8.753,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.55,
                "p90_inter_token_latency_ms": 60.51
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6986,
                "first_token_latency_s": 0.1319,
                "tokens_per_second": 17.42,
                "memory_before_gb": 8.913,
                "memory_after_gb": 9.179,
                "memory_delta_gb": 0.266,
                "server_memory_gb": 9.019,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.12,
                "p90_inter_token_latency_ms": 60.85
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.45,
              "std_tokens_per_second": 0.13,
              "avg_first_token_latency_s": 0.1659,
              "avg_inter_token_latency_ms": 56.88,
              "avg_total_time_s": 14.6702,
              "peak_memory_gb": 9.179,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.616026401519775,
              "cpu": {
                "avg_percent": 53.0,
                "max_percent": 59.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 54.2,
                "max_percent": 55.1,
                "peak_used_gb": 17.14
              },
              "gpu": {
                "avg_utilization_percent": 35.3,
                "max_utilization_percent": 56.0,
                "peak_memory_mb": 7831.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 204,
                "total_time_s": 14.6067,
                "first_token_latency_s": 0.3563,
                "tokens_per_second": 13.97,
                "memory_before_gb": 9.179,
                "memory_after_gb": 9.181,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.02,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 70.2,
                "p90_inter_token_latency_ms": 155.69
              },
              {
                "tokens_generated": 203,
                "total_time_s": 14.8575,
                "first_token_latency_s": 0.2544,
                "tokens_per_second": 13.66,
                "memory_before_gb": 9.181,
                "memory_after_gb": 9.465,
                "memory_delta_gb": 0.285,
                "server_memory_gb": 9.305,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 71.43,
                "p90_inter_token_latency_ms": 169.78
              },
              {
                "tokens_generated": 203,
                "total_time_s": 14.9089,
                "first_token_latency_s": 0.2477,
                "tokens_per_second": 13.62,
                "memory_before_gb": 9.465,
                "memory_after_gb": 9.739,
                "memory_delta_gb": 0.274,
                "server_memory_gb": 9.59,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 71.7,
                "p90_inter_token_latency_ms": 169.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 13.75,
              "std_tokens_per_second": 0.16,
              "avg_first_token_latency_s": 0.2861,
              "avg_inter_token_latency_ms": 71.11,
              "avg_total_time_s": 14.791,
              "peak_memory_gb": 9.739,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 81,
              "duration_s": 44.25045943260193,
              "cpu": {
                "avg_percent": 53.0,
                "max_percent": 61.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 56.0,
                "max_percent": 57.7,
                "peak_used_gb": 17.94
              },
              "gpu": {
                "avg_utilization_percent": 36.1,
                "max_utilization_percent": 80.0,
                "peak_memory_mb": 7828.0,
                "max_temperature_c": 54.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.7129,
                "first_token_latency_s": 0.3038,
                "tokens_per_second": 17.4,
                "memory_before_gb": 9.739,
                "memory_after_gb": 9.74,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.591,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.51,
                "p90_inter_token_latency_ms": 60.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.9137,
                "first_token_latency_s": 0.1314,
                "tokens_per_second": 17.17,
                "memory_before_gb": 9.74,
                "memory_after_gb": 10.011,
                "memory_delta_gb": 0.271,
                "server_memory_gb": 9.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.97,
                "p90_inter_token_latency_ms": 60.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6754,
                "first_token_latency_s": 0.1347,
                "tokens_per_second": 17.44,
                "memory_before_gb": 10.011,
                "memory_after_gb": 10.282,
                "memory_delta_gb": 0.271,
                "server_memory_gb": 10.133,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.02,
                "p90_inter_token_latency_ms": 60.17
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.34,
              "std_tokens_per_second": 0.12,
              "avg_first_token_latency_s": 0.19,
              "avg_inter_token_latency_ms": 57.17,
              "avg_total_time_s": 14.7673,
              "peak_memory_gb": 10.282,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.92902183532715,
              "cpu": {
                "avg_percent": 54.0,
                "max_percent": 60.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 58.1,
                "max_percent": 59.0,
                "peak_used_gb": 18.35
              },
              "gpu": {
                "avg_utilization_percent": 34.6,
                "max_utilization_percent": 74.0,
                "peak_memory_mb": 7820.0,
                "max_temperature_c": 57.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.6783,
                "first_token_latency_s": 0.3008,
                "tokens_per_second": 17.44,
                "memory_before_gb": 10.282,
                "memory_after_gb": 10.283,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 10.134,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.38,
                "p90_inter_token_latency_ms": 60.53
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6249,
                "first_token_latency_s": 0.134,
                "tokens_per_second": 17.5,
                "memory_before_gb": 10.283,
                "memory_after_gb": 10.557,
                "memory_delta_gb": 0.274,
                "server_memory_gb": 10.407,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.83,
                "p90_inter_token_latency_ms": 59.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8637,
                "first_token_latency_s": 0.1416,
                "tokens_per_second": 17.22,
                "memory_before_gb": 10.557,
                "memory_after_gb": 10.83,
                "memory_delta_gb": 0.273,
                "server_memory_gb": 10.68,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.73,
                "p90_inter_token_latency_ms": 60.65
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.39,
              "std_tokens_per_second": 0.12,
              "avg_first_token_latency_s": 0.1921,
              "avg_inter_token_latency_ms": 56.98,
              "avg_total_time_s": 14.7223,
              "peak_memory_gb": 10.83,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.82889533042908,
              "cpu": {
                "avg_percent": 53.7,
                "max_percent": 60.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.9,
                "max_percent": 60.8,
                "peak_used_gb": 18.91
              },
              "gpu": {
                "avg_utilization_percent": 34.8,
                "max_utilization_percent": 88.0,
                "peak_memory_mb": 7833.0,
                "max_temperature_c": 49.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 240,
                "total_time_s": 14.5013,
                "first_token_latency_s": 0.2606,
                "tokens_per_second": 16.55,
                "memory_before_gb": 10.83,
                "memory_after_gb": 10.831,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 10.681,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 59.58,
                "p90_inter_token_latency_ms": 61.55
              },
              {
                "tokens_generated": 234,
                "total_time_s": 14.91,
                "first_token_latency_s": 0.1457,
                "tokens_per_second": 15.69,
                "memory_before_gb": 10.831,
                "memory_after_gb": 11.145,
                "memory_delta_gb": 0.314,
                "server_memory_gb": 10.995,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 63.37,
                "p90_inter_token_latency_ms": 64.13
              },
              {
                "tokens_generated": 234,
                "total_time_s": 14.9959,
                "first_token_latency_s": 0.1357,
                "tokens_per_second": 15.6,
                "memory_before_gb": 11.145,
                "memory_after_gb": 11.458,
                "memory_delta_gb": 0.314,
                "server_memory_gb": 11.308,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 63.78,
                "p90_inter_token_latency_ms": 63.92
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 15.95,
              "std_tokens_per_second": 0.43,
              "avg_first_token_latency_s": 0.1807,
              "avg_inter_token_latency_ms": 62.24,
              "avg_total_time_s": 14.8024,
              "peak_memory_gb": 11.458,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 81,
              "duration_s": 44.24351501464844,
              "cpu": {
                "avg_percent": 53.3,
                "max_percent": 59.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 61.7,
                "max_percent": 62.9,
                "peak_used_gb": 19.56
              },
              "gpu": {
                "avg_utilization_percent": 34.0,
                "max_utilization_percent": 47.0,
                "peak_memory_mb": 7825.0,
                "max_temperature_c": 51.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 17.64,
            "first_token_latency_s": 0.0784,
            "inter_token_latency_ms": 56.62,
            "peak_memory_gb": 8.645,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 17.45,
            "first_token_latency_s": 0.1659,
            "inter_token_latency_ms": 56.88,
            "peak_memory_gb": 9.179,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 13.75,
            "first_token_latency_s": 0.2861,
            "inter_token_latency_ms": 71.11,
            "peak_memory_gb": 9.739,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 17.34,
            "first_token_latency_s": 0.19,
            "inter_token_latency_ms": 57.17,
            "peak_memory_gb": 10.282,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 17.39,
            "first_token_latency_s": 0.1921,
            "inter_token_latency_ms": 56.98,
            "peak_memory_gb": 10.83,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 15.95,
            "first_token_latency_s": 0.1807,
            "inter_token_latency_ms": 62.24,
            "peak_memory_gb": 11.458,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7219,
                "first_token_latency_s": 0.0047,
                "tokens_per_second": 354.64,
                "memory_before_gb": 1.077,
                "memory_after_gb": 1.078,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.928,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.81,
                "p90_inter_token_latency_ms": 2.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.745,
                "first_token_latency_s": 0.0173,
                "tokens_per_second": 343.61,
                "memory_before_gb": 1.078,
                "memory_after_gb": 1.085,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.85,
                "p90_inter_token_latency_ms": 2.89
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7857,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 325.82,
                "memory_before_gb": 1.085,
                "memory_after_gb": 1.085,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.935,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.99,
                "p90_inter_token_latency_ms": 3.47
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 341.36,
              "std_tokens_per_second": 11.87,
              "avg_first_token_latency_s": 0.0149,
              "avg_inter_token_latency_ms": 2.88,
              "avg_total_time_s": 0.7509,
              "peak_memory_gb": 1.085,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1499428749084473,
              "cpu": {
                "avg_percent": 5.8,
                "max_percent": 7.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.9,
                "max_percent": 28.9,
                "peak_used_gb": 9.0
              },
              "gpu": {
                "avg_utilization_percent": 70.4,
                "max_utilization_percent": 87.0,
                "peak_memory_mb": 2569.0,
                "max_temperature_c": 63.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7281,
                "first_token_latency_s": 0.0245,
                "tokens_per_second": 351.59,
                "memory_before_gb": 1.085,
                "memory_after_gb": 1.086,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.936,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.76,
                "p90_inter_token_latency_ms": 2.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7613,
                "first_token_latency_s": 0.0236,
                "tokens_per_second": 336.26,
                "memory_before_gb": 1.086,
                "memory_after_gb": 1.093,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.944,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.89,
                "p90_inter_token_latency_ms": 2.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7214,
                "first_token_latency_s": 0.0165,
                "tokens_per_second": 354.84,
                "memory_before_gb": 1.093,
                "memory_after_gb": 1.101,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.951,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.76,
                "p90_inter_token_latency_ms": 2.8
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 347.56,
              "std_tokens_per_second": 8.1,
              "avg_first_token_latency_s": 0.0215,
              "avg_inter_token_latency_ms": 2.8,
              "avg_total_time_s": 0.7369,
              "peak_memory_gb": 1.101,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.135392904281616,
              "cpu": {
                "avg_percent": 6.4,
                "max_percent": 9.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.9,
                "max_percent": 29.0,
                "peak_used_gb": 9.01
              },
              "gpu": {
                "avg_utilization_percent": 76.0,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2564.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 209,
                "total_time_s": 0.5948,
                "first_token_latency_s": 0.0153,
                "tokens_per_second": 351.36,
                "memory_before_gb": 1.101,
                "memory_after_gb": 1.102,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.952,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.77,
                "p90_inter_token_latency_ms": 2.8
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7266,
                "first_token_latency_s": 0.0179,
                "tokens_per_second": 352.33,
                "memory_before_gb": 1.102,
                "memory_after_gb": 1.108,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.959,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.78,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7811,
                "first_token_latency_s": 0.0289,
                "tokens_per_second": 327.76,
                "memory_before_gb": 1.108,
                "memory_after_gb": 1.116,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.966,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.95,
                "p90_inter_token_latency_ms": 3.41
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 343.82,
              "std_tokens_per_second": 11.36,
              "avg_first_token_latency_s": 0.0207,
              "avg_inter_token_latency_ms": 2.83,
              "avg_total_time_s": 0.7008,
              "peak_memory_gb": 1.116,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.601060152053833,
              "cpu": {
                "avg_percent": 6.3,
                "max_percent": 10.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.0,
                "max_percent": 29.0,
                "peak_used_gb": 9.03
              },
              "gpu": {
                "avg_utilization_percent": 60.8,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2571.0,
                "max_temperature_c": 64.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7332,
                "first_token_latency_s": 0.0284,
                "tokens_per_second": 349.14,
                "memory_before_gb": 1.116,
                "memory_after_gb": 1.117,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.967,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.76,
                "p90_inter_token_latency_ms": 2.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7344,
                "first_token_latency_s": 0.03,
                "tokens_per_second": 348.57,
                "memory_before_gb": 1.117,
                "memory_after_gb": 1.124,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.974,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.76,
                "p90_inter_token_latency_ms": 2.78
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.75,
                "first_token_latency_s": 0.0195,
                "tokens_per_second": 341.34,
                "memory_before_gb": 1.124,
                "memory_after_gb": 1.131,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.981,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.86,
                "p90_inter_token_latency_ms": 2.93
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 346.35,
              "std_tokens_per_second": 3.55,
              "avg_first_token_latency_s": 0.026,
              "avg_inter_token_latency_ms": 2.79,
              "avg_total_time_s": 0.7392,
              "peak_memory_gb": 1.131,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1445822715759277,
              "cpu": {
                "avg_percent": 5.8,
                "max_percent": 8.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.1,
                "max_percent": 29.1,
                "peak_used_gb": 9.05
              },
              "gpu": {
                "avg_utilization_percent": 85.2,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2562.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7427,
                "first_token_latency_s": 0.0157,
                "tokens_per_second": 344.67,
                "memory_before_gb": 1.131,
                "memory_after_gb": 1.132,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.982,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.85,
                "p90_inter_token_latency_ms": 2.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7302,
                "first_token_latency_s": 0.0256,
                "tokens_per_second": 350.59,
                "memory_before_gb": 1.132,
                "memory_after_gb": 1.139,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.989,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.76,
                "p90_inter_token_latency_ms": 2.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7817,
                "first_token_latency_s": 0.0331,
                "tokens_per_second": 327.48,
                "memory_before_gb": 1.139,
                "memory_after_gb": 1.147,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.997,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.94,
                "p90_inter_token_latency_ms": 3.41
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 340.91,
              "std_tokens_per_second": 9.8,
              "avg_first_token_latency_s": 0.0248,
              "avg_inter_token_latency_ms": 2.85,
              "avg_total_time_s": 0.7515,
              "peak_memory_gb": 1.147,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.13436222076416,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 9.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.1,
                "max_percent": 29.2,
                "peak_used_gb": 9.07
              },
              "gpu": {
                "avg_utilization_percent": 70.6,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2571.0,
                "max_temperature_c": 65.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 341.36,
            "first_token_latency_s": 0.0149,
            "inter_token_latency_ms": 2.88,
            "peak_memory_gb": 1.085,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 347.56,
            "first_token_latency_s": 0.0215,
            "inter_token_latency_ms": 2.8,
            "peak_memory_gb": 1.101,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 343.82,
            "first_token_latency_s": 0.0207,
            "inter_token_latency_ms": 2.83,
            "peak_memory_gb": 1.116,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 346.35,
            "first_token_latency_s": 0.026,
            "inter_token_latency_ms": 2.79,
            "peak_memory_gb": 1.131,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 340.91,
            "first_token_latency_s": 0.0248,
            "inter_token_latency_ms": 2.85,
            "peak_memory_gb": 1.147,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "prompt_type",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.2028,
                "first_token_latency_s": 0.037,
                "tokens_per_second": 79.93,
                "memory_before_gb": 4.503,
                "memory_after_gb": 4.504,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.354,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.41,
                "p90_inter_token_latency_ms": 13.44
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1598,
                "first_token_latency_s": 0.0416,
                "tokens_per_second": 81.02,
                "memory_before_gb": 4.504,
                "memory_after_gb": 4.54,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.23,
                "p90_inter_token_latency_ms": 12.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.143,
                "first_token_latency_s": 0.0158,
                "tokens_per_second": 81.45,
                "memory_before_gb": 4.54,
                "memory_after_gb": 4.54,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.26,
                "p90_inter_token_latency_ms": 12.97
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.8,
              "std_tokens_per_second": 0.64,
              "avg_first_token_latency_s": 0.0315,
              "avg_inter_token_latency_ms": 12.3,
              "avg_total_time_s": 3.1685,
              "peak_memory_gb": 4.54,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.06397271156311,
              "cpu": {
                "avg_percent": 6.6,
                "max_percent": 9.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.1,
                "max_percent": 40.2,
                "peak_used_gb": 12.5
              },
              "gpu": {
                "avg_utilization_percent": 95.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6325.0,
                "max_temperature_c": 71.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1563,
                "first_token_latency_s": 0.0347,
                "tokens_per_second": 81.11,
                "memory_before_gb": 4.54,
                "memory_after_gb": 4.542,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.392,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.24,
                "p90_inter_token_latency_ms": 12.98
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1595,
                "first_token_latency_s": 0.0354,
                "tokens_per_second": 81.03,
                "memory_before_gb": 4.542,
                "memory_after_gb": 4.581,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.431,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.25,
                "p90_inter_token_latency_ms": 12.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1537,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 81.17,
                "memory_before_gb": 4.581,
                "memory_after_gb": 4.62,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.471,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.28,
                "p90_inter_token_latency_ms": 13.03
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 81.1,
              "std_tokens_per_second": 0.06,
              "avg_first_token_latency_s": 0.0309,
              "avg_inter_token_latency_ms": 12.26,
              "avg_total_time_s": 3.1565,
              "peak_memory_gb": 4.62,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.091772317886353,
              "cpu": {
                "avg_percent": 7.2,
                "max_percent": 11.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.3,
                "max_percent": 40.5,
                "peak_used_gb": 12.61
              },
              "gpu": {
                "avg_utilization_percent": 96.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6320.0,
                "max_temperature_c": 73.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 183,
                "total_time_s": 2.3141,
                "first_token_latency_s": 0.0392,
                "tokens_per_second": 79.08,
                "memory_before_gb": 4.62,
                "memory_after_gb": 4.622,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.472,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.43,
                "p90_inter_token_latency_ms": 13.47
              },
              {
                "tokens_generated": 190,
                "total_time_s": 2.3747,
                "first_token_latency_s": 0.0465,
                "tokens_per_second": 80.01,
                "memory_before_gb": 4.622,
                "memory_after_gb": 4.655,
                "memory_delta_gb": 0.033,
                "server_memory_gb": 4.505,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.25,
                "p90_inter_token_latency_ms": 12.96
              },
              {
                "tokens_generated": 190,
                "total_time_s": 2.3505,
                "first_token_latency_s": 0.0215,
                "tokens_per_second": 80.83,
                "memory_before_gb": 4.655,
                "memory_after_gb": 4.689,
                "memory_delta_gb": 0.034,
                "server_memory_gb": 4.539,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.26,
                "p90_inter_token_latency_ms": 12.9
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 79.97,
              "std_tokens_per_second": 0.71,
              "avg_first_token_latency_s": 0.0357,
              "avg_inter_token_latency_ms": 12.31,
              "avg_total_time_s": 2.3464,
              "peak_memory_gb": 4.689,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 14,
              "duration_s": 6.911913633346558,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 11.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.6,
                "max_percent": 40.7,
                "peak_used_gb": 12.68
              },
              "gpu": {
                "avg_utilization_percent": 90.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6325.0,
                "max_temperature_c": 75.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1614,
                "first_token_latency_s": 0.0432,
                "tokens_per_second": 80.98,
                "memory_before_gb": 4.689,
                "memory_after_gb": 4.69,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.539,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.23,
                "p90_inter_token_latency_ms": 12.89
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1447,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 81.41,
                "memory_before_gb": 4.69,
                "memory_after_gb": 4.728,
                "memory_delta_gb": 0.038,
                "server_memory_gb": 4.577,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.24,
                "p90_inter_token_latency_ms": 13.0
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1563,
                "first_token_latency_s": 0.0382,
                "tokens_per_second": 81.11,
                "memory_before_gb": 4.728,
                "memory_after_gb": 4.765,
                "memory_delta_gb": 0.038,
                "server_memory_gb": 4.615,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.23,
                "p90_inter_token_latency_ms": 12.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 81.17,
              "std_tokens_per_second": 0.18,
              "avg_first_token_latency_s": 0.0346,
              "avg_inter_token_latency_ms": 12.23,
              "avg_total_time_s": 3.1541,
              "peak_memory_gb": 4.765,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.018529891967773,
              "cpu": {
                "avg_percent": 7.2,
                "max_percent": 9.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 40.9,
                "max_percent": 41.0,
                "peak_used_gb": 12.76
              },
              "gpu": {
                "avg_utilization_percent": 91.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6320.0,
                "max_temperature_c": 78.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.2127,
                "first_token_latency_s": 0.0412,
                "tokens_per_second": 79.68,
                "memory_before_gb": 4.765,
                "memory_after_gb": 4.766,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.616,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.44,
                "p90_inter_token_latency_ms": 13.45
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1843,
                "first_token_latency_s": 0.0453,
                "tokens_per_second": 80.39,
                "memory_before_gb": 4.766,
                "memory_after_gb": 4.809,
                "memory_delta_gb": 0.043,
                "server_memory_gb": 4.659,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.31,
                "p90_inter_token_latency_ms": 13.0
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1642,
                "first_token_latency_s": 0.0414,
                "tokens_per_second": 80.91,
                "memory_before_gb": 4.809,
                "memory_after_gb": 4.852,
                "memory_delta_gb": 0.043,
                "server_memory_gb": 4.702,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.25,
                "p90_inter_token_latency_ms": 12.89
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 80.33,
              "std_tokens_per_second": 0.5,
              "avg_first_token_latency_s": 0.0426,
              "avg_inter_token_latency_ms": 12.33,
              "avg_total_time_s": 3.1871,
              "peak_memory_gb": 4.852,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.098528861999512,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 9.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 41.1,
                "max_percent": 41.3,
                "peak_used_gb": 12.85
              },
              "gpu": {
                "avg_utilization_percent": 96.6,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 6327.0,
                "max_temperature_c": 80.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 80.8,
            "first_token_latency_s": 0.0315,
            "inter_token_latency_ms": 12.3,
            "peak_memory_gb": 4.54,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 81.1,
            "first_token_latency_s": 0.0309,
            "inter_token_latency_ms": 12.26,
            "peak_memory_gb": 4.62,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 79.97,
            "first_token_latency_s": 0.0357,
            "inter_token_latency_ms": 12.31,
            "peak_memory_gb": 4.689,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 81.17,
            "first_token_latency_s": 0.0346,
            "inter_token_latency_ms": 12.23,
            "peak_memory_gb": 4.765,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 80.33,
            "first_token_latency_s": 0.0426,
            "inter_token_latency_ms": 12.33,
            "peak_memory_gb": 4.852,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "prompt_type",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.587,
                "first_token_latency_s": 0.0806,
                "tokens_per_second": 17.55,
                "memory_before_gb": 8.383,
                "memory_after_gb": 8.323,
                "memory_delta_gb": -0.06,
                "server_memory_gb": 8.173,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.89,
                "p90_inter_token_latency_ms": 59.13
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.7633,
                "first_token_latency_s": 0.1177,
                "tokens_per_second": 17.34,
                "memory_before_gb": 8.323,
                "memory_after_gb": 8.578,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.428,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.43,
                "p90_inter_token_latency_ms": 59.08
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.6861,
                "first_token_latency_s": 0.0765,
                "tokens_per_second": 17.43,
                "memory_before_gb": 8.578,
                "memory_after_gb": 8.578,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.428,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.29,
                "p90_inter_token_latency_ms": 58.82
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.44,
              "std_tokens_per_second": 0.09,
              "avg_first_token_latency_s": 0.0916,
              "avg_inter_token_latency_ms": 57.2,
              "avg_total_time_s": 14.6788,
              "peak_memory_gb": 8.578,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.576305866241455,
              "cpu": {
                "avg_percent": 54.2,
                "max_percent": 59.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 53.5,
                "max_percent": 53.8,
                "peak_used_gb": 16.75
              },
              "gpu": {
                "avg_utilization_percent": 34.7,
                "max_utilization_percent": 44.0,
                "peak_memory_mb": 7829.0,
                "max_temperature_c": 52.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.4972,
                "first_token_latency_s": 0.2671,
                "tokens_per_second": 17.66,
                "memory_before_gb": 8.578,
                "memory_after_gb": 8.579,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.429,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.8,
                "p90_inter_token_latency_ms": 58.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 15.0717,
                "first_token_latency_s": 0.124,
                "tokens_per_second": 16.99,
                "memory_before_gb": 8.579,
                "memory_after_gb": 8.85,
                "memory_delta_gb": 0.271,
                "server_memory_gb": 8.701,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 58.62,
                "p90_inter_token_latency_ms": 61.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8188,
                "first_token_latency_s": 0.1091,
                "tokens_per_second": 17.28,
                "memory_before_gb": 8.85,
                "memory_after_gb": 9.122,
                "memory_delta_gb": 0.272,
                "server_memory_gb": 8.974,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.68,
                "p90_inter_token_latency_ms": 59.15
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.31,
              "std_tokens_per_second": 0.27,
              "avg_first_token_latency_s": 0.1667,
              "avg_inter_token_latency_ms": 57.37,
              "avg_total_time_s": 14.7959,
              "peak_memory_gb": 9.122,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 81,
              "duration_s": 44.08334946632385,
              "cpu": {
                "avg_percent": 53.8,
                "max_percent": 61.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 54.7,
                "max_percent": 55.5,
                "peak_used_gb": 17.27
              },
              "gpu": {
                "avg_utilization_percent": 35.1,
                "max_utilization_percent": 42.0,
                "peak_memory_mb": 7829.0,
                "max_temperature_c": 49.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.5399,
                "first_token_latency_s": 0.2578,
                "tokens_per_second": 17.61,
                "memory_before_gb": 9.122,
                "memory_after_gb": 9.123,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.974,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.01,
                "p90_inter_token_latency_ms": 59.16
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.7926,
                "first_token_latency_s": 0.1169,
                "tokens_per_second": 17.31,
                "memory_before_gb": 9.123,
                "memory_after_gb": 9.415,
                "memory_delta_gb": 0.292,
                "server_memory_gb": 9.266,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.55,
                "p90_inter_token_latency_ms": 59.17
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.819,
                "first_token_latency_s": 0.1225,
                "tokens_per_second": 17.28,
                "memory_before_gb": 9.415,
                "memory_after_gb": 9.706,
                "memory_delta_gb": 0.292,
                "server_memory_gb": 9.558,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.63,
                "p90_inter_token_latency_ms": 59.21
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.4,
              "std_tokens_per_second": 0.15,
              "avg_first_token_latency_s": 0.1657,
              "avg_inter_token_latency_ms": 57.06,
              "avg_total_time_s": 14.7172,
              "peak_memory_gb": 9.706,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 81,
              "duration_s": 44.018396854400635,
              "cpu": {
                "avg_percent": 53.2,
                "max_percent": 59.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 56.4,
                "max_percent": 57.4,
                "peak_used_gb": 17.86
              },
              "gpu": {
                "avg_utilization_percent": 34.3,
                "max_utilization_percent": 58.0,
                "peak_memory_mb": 7821.0,
                "max_temperature_c": 55.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.4917,
                "first_token_latency_s": 0.2618,
                "tokens_per_second": 17.67,
                "memory_before_gb": 9.706,
                "memory_after_gb": 9.707,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.559,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 55.8,
                "p90_inter_token_latency_ms": 58.85
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8147,
                "first_token_latency_s": 0.1134,
                "tokens_per_second": 17.28,
                "memory_before_gb": 9.707,
                "memory_after_gb": 9.972,
                "memory_delta_gb": 0.265,
                "server_memory_gb": 9.824,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.65,
                "p90_inter_token_latency_ms": 59.51
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8151,
                "first_token_latency_s": 0.1065,
                "tokens_per_second": 17.28,
                "memory_before_gb": 9.972,
                "memory_after_gb": 10.237,
                "memory_delta_gb": 0.265,
                "server_memory_gb": 10.089,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.68,
                "p90_inter_token_latency_ms": 59.5
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.41,
              "std_tokens_per_second": 0.18,
              "avg_first_token_latency_s": 0.1606,
              "avg_inter_token_latency_ms": 57.04,
              "avg_total_time_s": 14.7072,
              "peak_memory_gb": 10.237,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 80,
              "duration_s": 43.609094858169556,
              "cpu": {
                "avg_percent": 53.8,
                "max_percent": 58.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 58.3,
                "max_percent": 59.2,
                "peak_used_gb": 18.41
              },
              "gpu": {
                "avg_utilization_percent": 34.5,
                "max_utilization_percent": 51.0,
                "peak_memory_mb": 7828.0,
                "max_temperature_c": 54.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 14.6103,
                "first_token_latency_s": 0.296,
                "tokens_per_second": 17.52,
                "memory_before_gb": 10.237,
                "memory_after_gb": 10.238,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 10.09,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 56.13,
                "p90_inter_token_latency_ms": 59.26
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8327,
                "first_token_latency_s": 0.1122,
                "tokens_per_second": 17.26,
                "memory_before_gb": 10.238,
                "memory_after_gb": 10.534,
                "memory_delta_gb": 0.296,
                "server_memory_gb": 10.386,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.73,
                "p90_inter_token_latency_ms": 59.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 14.8426,
                "first_token_latency_s": 0.0997,
                "tokens_per_second": 17.25,
                "memory_before_gb": 10.534,
                "memory_after_gb": 10.83,
                "memory_delta_gb": 0.296,
                "server_memory_gb": 10.682,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 57.81,
                "p90_inter_token_latency_ms": 59.37
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 17.34,
              "std_tokens_per_second": 0.12,
              "avg_first_token_latency_s": 0.1693,
              "avg_inter_token_latency_ms": 57.22,
              "avg_total_time_s": 14.7619,
              "peak_memory_gb": 10.83,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 81,
              "duration_s": 44.10980534553528,
              "cpu": {
                "avg_percent": 54.1,
                "max_percent": 62.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 60.1,
                "max_percent": 61.1,
                "peak_used_gb": 19.0
              },
              "gpu": {
                "avg_utilization_percent": 34.9,
                "max_utilization_percent": 86.0,
                "peak_memory_mb": 7825.0,
                "max_temperature_c": 58.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 17.44,
            "first_token_latency_s": 0.0916,
            "inter_token_latency_ms": 57.2,
            "peak_memory_gb": 8.578,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 17.31,
            "first_token_latency_s": 0.1667,
            "inter_token_latency_ms": 57.37,
            "peak_memory_gb": 9.122,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 17.4,
            "first_token_latency_s": 0.1657,
            "inter_token_latency_ms": 57.06,
            "peak_memory_gb": 9.706,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 17.41,
            "first_token_latency_s": 0.1606,
            "inter_token_latency_ms": 57.04,
            "peak_memory_gb": 10.237,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 17.34,
            "first_token_latency_s": 0.1693,
            "inter_token_latency_ms": 57.22,
            "peak_memory_gb": 10.83,
            "stability": "stable"
          }
        ]
      }
    }
  }
}