{
  "id": "20260218_111551",
  "timestamp": "2026-02-18T11:15:51.943914",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26200-SP0",
      "python_version": "3.9.13"
    },
    "cpu": {
      "physical_cores": 8,
      "logical_cores": 16,
      "architecture": "AMD64",
      "model": "AMD Ryzen 7 4800H with Radeon Graphics",
      "max_clock_speed_mhz": "2900",
      "architecture_type": "x86_64",
      "is_apple_silicon": false,
      "frequency_mhz": {
        "current": 2900.0,
        "min": null,
        "max": 2900.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "AMD",
          "name": "AMD Radeon(TM) Graphics",
          "backend": "rocm",
          "detected_via": "wmi",
          "vram_total_mb": 512,
          "driver_version": "31.0.21921.1000",
          "gpu_index": 0
        },
        {
          "type": "AMD",
          "name": "Radeon RX 5500M",
          "backend": "rocm",
          "detected_via": "wmi",
          "vram_total_mb": 4080,
          "driver_version": "32.0.12019.1028",
          "gpu_index": 1
        }
      ],
      "backends": [
        "rocm",
        "cpu"
      ],
      "primary_backend": "rocm",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.4.1+cpu",
        "pytorch_cuda": false,
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": false,
        "llama_server": false,
        "pytorch_rocm": false,
        "ipex": false
      }
    },
    "ram": {
      "total_gb": 15.4,
      "available_gb": 5.05,
      "used_gb": 10.35,
      "percent_used": 67.2,
      "swap_total_gb": 10.0,
      "swap_used_gb": 0.08,
      "unified_memory": false
    },
    "selected_gpu": {
      "gpu_index": 1,
      "name": "Radeon RX 5500M",
      "backend": "rocm"
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 8.83,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread)",
        "results": {
          "512x512": {
            "times_s": [
              0.0014,
              0.0021,
              0.0018
            ],
            "mean_s": 0.0018,
            "std_s": 0.0003,
            "gflops": 151.48
          },
          "1024x1024": {
            "times_s": [
              0.0074,
              0.0092,
              0.007
            ],
            "mean_s": 0.0078,
            "std_s": 0.001,
            "gflops": 273.95
          },
          "2048x2048": {
            "times_s": [
              0.0384,
              0.0399,
              0.0296
            ],
            "mean_s": 0.0359,
            "std_s": 0.0046,
            "gflops": 478.13
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 16 threads)",
        "n_threads": 16,
        "results": {
          "512x512": {
            "times_s": [
              0.0016,
              0.0014,
              0.0016
            ],
            "mean_s": 0.0015,
            "std_s": 0.0001,
            "gflops": 175.17
          },
          "1024x1024": {
            "times_s": [
              0.0075,
              0.0074,
              0.007
            ],
            "mean_s": 0.0073,
            "std_s": 0.0002,
            "gflops": 295.09
          },
          "2048x2048": {
            "times_s": [
              0.0346,
              0.0342,
              0.0345
            ],
            "mean_s": 0.0344,
            "std_s": 0.0002,
            "gflops": 499.0
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0546,
            "bandwidth_gb_s": 4.58
          },
          "read": {
            "mean_s": 0.0434,
            "bandwidth_gb_s": 5.76
          },
          "copy": {
            "mean_s": 0.0627,
            "bandwidth_gb_s": 3.98
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute",
        "status": "skipped",
        "reason": "GPU AMD (AMD Radeon(TM) Graphics) d√©tect√©, mais PyTorch n'a pas le support ROCm activ√©.",
        "advice": "Installez PyTorch avec le support ROCm pour activer le support GPU AMD :\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2"
      }
    },
    "resource_usage": {
      "n_samples": 16,
      "duration_s": 8.288018465042114,
      "cpu": {
        "avg_percent": 14.0,
        "max_percent": 32.0,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 68.1,
        "max_percent": 69.4,
        "peak_used_gb": 10.69
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 1,
      "n_benchmark_runs": 3
    },
    "total_time_s": 168.02,
    "models_tested": 1,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 1.6137,
            "first_token_latency_s": 0.0335,
            "tokens_per_second": 158.64,
            "memory_before_gb": 0.973,
            "memory_after_gb": 0.974,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 0.749,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 6.2,
            "p90_inter_token_latency_ms": 6.6
          },
          {
            "tokens_generated": 256,
            "total_time_s": 1.6189,
            "first_token_latency_s": 0.0393,
            "tokens_per_second": 158.14,
            "memory_before_gb": 0.974,
            "memory_after_gb": 0.98,
            "memory_delta_gb": 0.007,
            "server_memory_gb": 0.756,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 6.19,
            "p90_inter_token_latency_ms": 6.61
          },
          {
            "tokens_generated": 256,
            "total_time_s": 1.5949,
            "first_token_latency_s": 0.0123,
            "tokens_per_second": 160.51,
            "memory_before_gb": 0.98,
            "memory_after_gb": 0.98,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 0.756,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 6.21,
            "p90_inter_token_latency_ms": 6.61
          }
        ],
        "model_load_time_s": 1.55,
        "backend": {
          "backend": "rocm",
          "n_gpu_layers": -1,
          "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
          "amd_device": "AMD Radeon(TM) Graphics",
          "amd_vram_mb": 512,
          "driver_version": "31.0.21921.1000",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 9,
          "duration_s": 4.363446235656738,
          "cpu": {
            "avg_percent": 7.3,
            "max_percent": 12.3,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 72.6,
            "max_percent": 72.6,
            "peak_used_gb": 11.18
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 159.1,
          "std_tokens_per_second": 1.02,
          "avg_first_token_latency_s": 0.0284,
          "avg_total_time_s": 1.6092,
          "peak_memory_gb": 0.98,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.8146,
                "first_token_latency_s": 0.0277,
                "tokens_per_second": 141.08,
                "memory_before_gb": 0.815,
                "memory_after_gb": 0.815,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.591,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.01,
                "p90_inter_token_latency_ms": 7.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.8217,
                "first_token_latency_s": 0.0422,
                "tokens_per_second": 140.53,
                "memory_before_gb": 0.815,
                "memory_after_gb": 0.822,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.597,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.98,
                "p90_inter_token_latency_ms": 7.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.8177,
                "first_token_latency_s": 0.0376,
                "tokens_per_second": 140.84,
                "memory_before_gb": 0.822,
                "memory_after_gb": 0.822,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 0.597,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.98,
                "p90_inter_token_latency_ms": 7.3
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 1.53,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.812,
            "server_memory_after_load_gb": 0.588,
            "resource_usage": {
              "n_samples": 11,
              "duration_s": 5.471832036972046,
              "cpu": {
                "avg_percent": 7.1,
                "max_percent": 13.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 71.1,
                "max_percent": 71.1,
                "peak_used_gb": 10.95
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 140.82,
              "std_tokens_per_second": 0.23,
              "min_tokens_per_second": 140.53,
              "max_tokens_per_second": 141.08,
              "avg_first_token_latency_s": 0.0358,
              "avg_inter_token_latency_ms": 6.99,
              "avg_total_time_s": 1.818,
              "peak_memory_gb": 0.822,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.786,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 143.34,
                "memory_before_gb": 0.872,
                "memory_after_gb": 0.873,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.648,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.91,
                "p90_inter_token_latency_ms": 7.23
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.8139,
                "first_token_latency_s": 0.0428,
                "tokens_per_second": 141.13,
                "memory_before_gb": 0.873,
                "memory_after_gb": 0.88,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.655,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.94,
                "p90_inter_token_latency_ms": 7.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.7896,
                "first_token_latency_s": 0.0135,
                "tokens_per_second": 143.05,
                "memory_before_gb": 0.88,
                "memory_after_gb": 0.88,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 0.655,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.96,
                "p90_inter_token_latency_ms": 7.3
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.87,
            "server_memory_after_load_gb": 0.645,
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.931663990020752,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 16.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 71.5,
                "max_percent": 71.5,
                "peak_used_gb": 11.01
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 142.51,
              "std_tokens_per_second": 0.98,
              "min_tokens_per_second": 141.13,
              "max_tokens_per_second": 143.34,
              "avg_first_token_latency_s": 0.027,
              "avg_inter_token_latency_ms": 6.94,
              "avg_total_time_s": 1.7965,
              "peak_memory_gb": 0.88,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.5975,
                "first_token_latency_s": 0.0284,
                "tokens_per_second": 160.25,
                "memory_before_gb": 0.973,
                "memory_after_gb": 0.974,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.749,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.15,
                "p90_inter_token_latency_ms": 6.59
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6168,
                "first_token_latency_s": 0.0441,
                "tokens_per_second": 158.34,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.17,
                "p90_inter_token_latency_ms": 6.49
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.5829,
                "first_token_latency_s": 0.0133,
                "tokens_per_second": 161.73,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.981,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.15,
                "p90_inter_token_latency_ms": 6.51
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 0.971,
            "server_memory_after_load_gb": 0.747,
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.372732877731323,
              "cpu": {
                "avg_percent": 9.4,
                "max_percent": 13.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.2,
                "max_percent": 72.2,
                "peak_used_gb": 11.12
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 160.11,
              "std_tokens_per_second": 1.39,
              "min_tokens_per_second": 158.34,
              "max_tokens_per_second": 161.73,
              "avg_first_token_latency_s": 0.0286,
              "avg_inter_token_latency_ms": 6.16,
              "avg_total_time_s": 1.5991,
              "peak_memory_gb": 0.981,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.7378,
                "first_token_latency_s": 0.0353,
                "tokens_per_second": 147.31,
                "memory_before_gb": 1.072,
                "memory_after_gb": 1.072,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.848,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.68,
                "p90_inter_token_latency_ms": 7.01
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.7282,
                "first_token_latency_s": 0.0209,
                "tokens_per_second": 148.13,
                "memory_before_gb": 1.072,
                "memory_after_gb": 1.08,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.855,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.69,
                "p90_inter_token_latency_ms": 7.08
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.7286,
                "first_token_latency_s": 0.0345,
                "tokens_per_second": 148.09,
                "memory_before_gb": 1.08,
                "memory_after_gb": 1.08,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.855,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.64,
                "p90_inter_token_latency_ms": 6.99
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.07,
            "server_memory_after_load_gb": 0.846,
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.9229207038879395,
              "cpu": {
                "avg_percent": 9.7,
                "max_percent": 14.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.9,
                "max_percent": 72.9,
                "peak_used_gb": 11.23
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 147.84,
              "std_tokens_per_second": 0.38,
              "min_tokens_per_second": 147.31,
              "max_tokens_per_second": 148.13,
              "avg_first_token_latency_s": 0.0302,
              "avg_inter_token_latency_ms": 6.67,
              "avg_total_time_s": 1.7315,
              "peak_memory_gb": 1.08,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.7663,
                "first_token_latency_s": 0.0121,
                "tokens_per_second": 144.94,
                "memory_before_gb": 1.177,
                "memory_after_gb": 1.178,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.953,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.88,
                "p90_inter_token_latency_ms": 7.23
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.7775,
                "first_token_latency_s": 0.0204,
                "tokens_per_second": 144.03,
                "memory_before_gb": 1.178,
                "memory_after_gb": 1.185,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.96,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.89,
                "p90_inter_token_latency_ms": 7.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.765,
                "first_token_latency_s": 0.014,
                "tokens_per_second": 145.04,
                "memory_before_gb": 1.185,
                "memory_after_gb": 1.185,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 0.96,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.87,
                "p90_inter_token_latency_ms": 7.28
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 1.55,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.175,
            "server_memory_after_load_gb": 0.951,
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.919201850891113,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 11.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 73.5,
                "max_percent": 73.5,
                "peak_used_gb": 11.32
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 144.67,
              "std_tokens_per_second": 0.45,
              "min_tokens_per_second": 144.03,
              "max_tokens_per_second": 145.04,
              "avg_first_token_latency_s": 0.0155,
              "avg_inter_token_latency_ms": 6.88,
              "avg_total_time_s": 1.7696,
              "peak_memory_gb": 1.185,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 14,
                "total_time_s": 0.1428,
                "first_token_latency_s": 0.0328,
                "tokens_per_second": 98.01,
                "memory_before_gb": 1.425,
                "memory_after_gb": 1.425,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.2,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.84,
                "p90_inter_token_latency_ms": 8.16
              },
              {
                "tokens_generated": 14,
                "total_time_s": 0.1374,
                "first_token_latency_s": 0.0295,
                "tokens_per_second": 101.88,
                "memory_before_gb": 1.425,
                "memory_after_gb": 1.425,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.2,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.7,
                "p90_inter_token_latency_ms": 7.97
              },
              {
                "tokens_generated": 14,
                "total_time_s": 0.1461,
                "first_token_latency_s": 0.0344,
                "tokens_per_second": 95.81,
                "memory_before_gb": 1.425,
                "memory_after_gb": 1.425,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 1.2,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 7.95,
                "p90_inter_token_latency_ms": 8.19
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 1.56,
            "backend": {
              "backend": "rocm",
              "n_gpu_layers": -1,
              "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
              "amd_device": "AMD Radeon(TM) Graphics",
              "amd_vram_mb": 512,
              "driver_version": "31.0.21921.1000",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.423,
            "server_memory_after_load_gb": 1.198,
            "resource_usage": {
              "n_samples": 1,
              "duration_s": 0,
              "cpu": {
                "avg_percent": 0.0,
                "max_percent": 0.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 75.1,
                "max_percent": 75.1,
                "peak_used_gb": 11.57
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 98.57,
              "std_tokens_per_second": 2.51,
              "min_tokens_per_second": 95.81,
              "max_tokens_per_second": 101.88,
              "avg_first_token_latency_s": 0.0322,
              "avg_inter_token_latency_ms": 7.83,
              "avg_total_time_s": 0.1421,
              "peak_memory_gb": 1.425,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 140.82,
            "first_token_latency_s": 0.0358,
            "inter_token_latency_ms": 6.99,
            "peak_memory_gb": 0.822,
            "model_load_time_s": 1.53,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 142.51,
            "first_token_latency_s": 0.027,
            "inter_token_latency_ms": 6.94,
            "peak_memory_gb": 0.88,
            "model_load_time_s": 1.56,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 160.11,
            "first_token_latency_s": 0.0286,
            "inter_token_latency_ms": 6.16,
            "peak_memory_gb": 0.981,
            "model_load_time_s": 1.56,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 147.84,
            "first_token_latency_s": 0.0302,
            "inter_token_latency_ms": 6.67,
            "peak_memory_gb": 1.08,
            "model_load_time_s": 1.56,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 144.67,
            "first_token_latency_s": 0.0155,
            "inter_token_latency_ms": 6.88,
            "peak_memory_gb": 1.185,
            "model_load_time_s": 1.55,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 98.57,
            "first_token_latency_s": 0.0322,
            "inter_token_latency_ms": 7.83,
            "peak_memory_gb": 1.425,
            "model_load_time_s": 1.56,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6036,
                "first_token_latency_s": 0.0123,
                "tokens_per_second": 159.64,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.974,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.749,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.24,
                "p90_inter_token_latency_ms": 6.66
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6223,
                "first_token_latency_s": 0.0405,
                "tokens_per_second": 157.8,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.2,
                "p90_inter_token_latency_ms": 6.59
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6233,
                "first_token_latency_s": 0.0347,
                "tokens_per_second": 157.71,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.23,
                "p90_inter_token_latency_ms": 6.66
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 158.38,
              "std_tokens_per_second": 0.89,
              "avg_first_token_latency_s": 0.0292,
              "avg_inter_token_latency_ms": 6.22,
              "avg_total_time_s": 1.6164,
              "peak_memory_gb": 0.981,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.392160177230835,
              "cpu": {
                "avg_percent": 6.6,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.4,
                "max_percent": 72.4,
                "peak_used_gb": 11.15
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.5992,
                "first_token_latency_s": 0.0247,
                "tokens_per_second": 160.08,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.982,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.757,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.17,
                "p90_inter_token_latency_ms": 6.56
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6082,
                "first_token_latency_s": 0.0378,
                "tokens_per_second": 159.18,
                "memory_before_gb": 0.982,
                "memory_after_gb": 0.988,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.763,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.16,
                "p90_inter_token_latency_ms": 6.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6205,
                "first_token_latency_s": 0.0334,
                "tokens_per_second": 157.98,
                "memory_before_gb": 0.988,
                "memory_after_gb": 0.988,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.763,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.22,
                "p90_inter_token_latency_ms": 6.61
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 159.08,
              "std_tokens_per_second": 0.86,
              "avg_first_token_latency_s": 0.032,
              "avg_inter_token_latency_ms": 6.18,
              "avg_total_time_s": 1.6093,
              "peak_memory_gb": 0.988,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.383978843688965,
              "cpu": {
                "avg_percent": 7.1,
                "max_percent": 9.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.4,
                "max_percent": 72.4,
                "peak_used_gb": 11.15
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6105,
                "first_token_latency_s": 0.0244,
                "tokens_per_second": 158.96,
                "memory_before_gb": 0.988,
                "memory_after_gb": 0.989,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.764,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.22,
                "p90_inter_token_latency_ms": 6.61
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6102,
                "first_token_latency_s": 0.0316,
                "tokens_per_second": 158.99,
                "memory_before_gb": 0.989,
                "memory_after_gb": 0.995,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.771,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.19,
                "p90_inter_token_latency_ms": 6.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6143,
                "first_token_latency_s": 0.0301,
                "tokens_per_second": 158.58,
                "memory_before_gb": 0.995,
                "memory_after_gb": 0.995,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.771,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.21,
                "p90_inter_token_latency_ms": 6.6
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 158.84,
              "std_tokens_per_second": 0.19,
              "avg_first_token_latency_s": 0.0287,
              "avg_inter_token_latency_ms": 6.21,
              "avg_total_time_s": 1.6117,
              "peak_memory_gb": 0.995,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.362928152084351,
              "cpu": {
                "avg_percent": 7.6,
                "max_percent": 11.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.5,
                "max_percent": 72.5,
                "peak_used_gb": 11.16
              }
            }
          }
        },
        "backend": {
          "backend": "rocm",
          "n_gpu_layers": -1,
          "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
          "amd_device": "AMD Radeon(TM) Graphics",
          "amd_vram_mb": 512,
          "driver_version": "31.0.21921.1000",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 158.38,
            "first_token_latency_s": 0.0292,
            "inter_token_latency_ms": 6.22,
            "peak_memory_gb": 0.981,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 159.08,
            "first_token_latency_s": 0.032,
            "inter_token_latency_ms": 6.18,
            "peak_memory_gb": 0.988,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 158.84,
            "first_token_latency_s": 0.0287,
            "inter_token_latency_ms": 6.21,
            "peak_memory_gb": 0.995,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6236,
                "first_token_latency_s": 0.0326,
                "tokens_per_second": 157.67,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.974,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.749,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.24,
                "p90_inter_token_latency_ms": 6.66
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6128,
                "first_token_latency_s": 0.0208,
                "tokens_per_second": 158.73,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.24,
                "p90_inter_token_latency_ms": 6.64
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6088,
                "first_token_latency_s": 0.0244,
                "tokens_per_second": 159.13,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.981,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.21,
                "p90_inter_token_latency_ms": 6.67
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 158.51,
              "std_tokens_per_second": 0.62,
              "avg_first_token_latency_s": 0.0259,
              "avg_inter_token_latency_ms": 6.23,
              "avg_total_time_s": 1.6151,
              "peak_memory_gb": 0.981,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.393590927124023,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 12.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.4,
                "max_percent": 72.4,
                "peak_used_gb": 11.15
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6742,
                "first_token_latency_s": 0.0766,
                "tokens_per_second": 152.91,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.982,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.757,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.26,
                "p90_inter_token_latency_ms": 6.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.622,
                "first_token_latency_s": 0.0196,
                "tokens_per_second": 157.83,
                "memory_before_gb": 0.982,
                "memory_after_gb": 0.989,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.764,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.28,
                "p90_inter_token_latency_ms": 6.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6379,
                "first_token_latency_s": 0.0432,
                "tokens_per_second": 156.3,
                "memory_before_gb": 0.989,
                "memory_after_gb": 0.996,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.771,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.25,
                "p90_inter_token_latency_ms": 6.67
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 155.68,
              "std_tokens_per_second": 2.06,
              "avg_first_token_latency_s": 0.0465,
              "avg_inter_token_latency_ms": 6.26,
              "avg_total_time_s": 1.6447,
              "peak_memory_gb": 0.996,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.9231603145599365,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 9.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.5,
                "max_percent": 72.5,
                "peak_used_gb": 11.17
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6972,
                "first_token_latency_s": 0.0992,
                "tokens_per_second": 150.84,
                "memory_before_gb": 0.996,
                "memory_after_gb": 0.997,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.772,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.27,
                "p90_inter_token_latency_ms": 6.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6209,
                "first_token_latency_s": 0.0212,
                "tokens_per_second": 157.93,
                "memory_before_gb": 0.997,
                "memory_after_gb": 1.005,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.78,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.27,
                "p90_inter_token_latency_ms": 6.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6289,
                "first_token_latency_s": 0.0356,
                "tokens_per_second": 157.16,
                "memory_before_gb": 1.005,
                "memory_after_gb": 1.012,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.787,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.25,
                "p90_inter_token_latency_ms": 6.63
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 155.31,
              "std_tokens_per_second": 3.18,
              "avg_first_token_latency_s": 0.052,
              "avg_inter_token_latency_ms": 6.26,
              "avg_total_time_s": 1.649,
              "peak_memory_gb": 1.012,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.9366700649261475,
              "cpu": {
                "avg_percent": 7.2,
                "max_percent": 10.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.5,
                "max_percent": 72.6,
                "peak_used_gb": 11.18
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6897,
                "first_token_latency_s": 0.0794,
                "tokens_per_second": 151.5,
                "memory_before_gb": 1.012,
                "memory_after_gb": 1.013,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.788,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.31,
                "p90_inter_token_latency_ms": 6.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6162,
                "first_token_latency_s": 0.0203,
                "tokens_per_second": 158.39,
                "memory_before_gb": 1.013,
                "memory_after_gb": 1.02,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.795,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.26,
                "p90_inter_token_latency_ms": 6.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6272,
                "first_token_latency_s": 0.0304,
                "tokens_per_second": 157.33,
                "memory_before_gb": 1.02,
                "memory_after_gb": 1.027,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.802,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.26,
                "p90_inter_token_latency_ms": 6.66
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 155.74,
              "std_tokens_per_second": 3.03,
              "avg_first_token_latency_s": 0.0434,
              "avg_inter_token_latency_ms": 6.28,
              "avg_total_time_s": 1.6444,
              "peak_memory_gb": 1.027,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.929988145828247,
              "cpu": {
                "avg_percent": 6.5,
                "max_percent": 10.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.6,
                "max_percent": 72.6,
                "peak_used_gb": 11.19
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6632,
                "first_token_latency_s": 0.0652,
                "tokens_per_second": 153.92,
                "memory_before_gb": 1.027,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.803,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.27,
                "p90_inter_token_latency_ms": 6.66
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6265,
                "first_token_latency_s": 0.0372,
                "tokens_per_second": 157.4,
                "memory_before_gb": 1.028,
                "memory_after_gb": 1.035,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.81,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.23,
                "p90_inter_token_latency_ms": 6.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6277,
                "first_token_latency_s": 0.0361,
                "tokens_per_second": 157.28,
                "memory_before_gb": 1.035,
                "memory_after_gb": 1.042,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.817,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.24,
                "p90_inter_token_latency_ms": 6.69
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 156.2,
              "std_tokens_per_second": 1.61,
              "avg_first_token_latency_s": 0.0462,
              "avg_inter_token_latency_ms": 6.25,
              "avg_total_time_s": 1.6391,
              "peak_memory_gb": 1.042,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.928824424743652,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 10.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.7,
                "max_percent": 72.7,
                "peak_used_gb": 11.2
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "runs": [
              {
                "tokens_generated": 240,
                "total_time_s": 1.7062,
                "first_token_latency_s": 0.1091,
                "tokens_per_second": 140.66,
                "memory_before_gb": 1.042,
                "memory_after_gb": 1.042,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.818,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.68,
                "p90_inter_token_latency_ms": 6.84
              },
              {
                "tokens_generated": 245,
                "total_time_s": 1.6547,
                "first_token_latency_s": 0.0445,
                "tokens_per_second": 148.06,
                "memory_before_gb": 1.043,
                "memory_after_gb": 1.051,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.826,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.6,
                "p90_inter_token_latency_ms": 6.76
              },
              {
                "tokens_generated": 245,
                "total_time_s": 1.6314,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 150.18,
                "memory_before_gb": 1.051,
                "memory_after_gb": 1.059,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.834,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.58,
                "p90_inter_token_latency_ms": 6.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 146.3,
              "std_tokens_per_second": 4.08,
              "avg_first_token_latency_s": 0.0594,
              "avg_inter_token_latency_ms": 6.62,
              "avg_total_time_s": 1.6641,
              "peak_memory_gb": 1.059,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.9303882122039795,
              "cpu": {
                "avg_percent": 10.8,
                "max_percent": 16.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.5,
                "max_percent": 72.7,
                "peak_used_gb": 11.2
              }
            }
          }
        },
        "backend": {
          "backend": "rocm",
          "n_gpu_layers": -1,
          "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
          "amd_device": "AMD Radeon(TM) Graphics",
          "amd_vram_mb": 512,
          "driver_version": "31.0.21921.1000",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "üá¨üáß",
            "tokens_per_second": 158.51,
            "first_token_latency_s": 0.0259,
            "inter_token_latency_ms": 6.23,
            "peak_memory_gb": 0.981,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Fran√ßais",
            "flag": "üá´üá∑",
            "tokens_per_second": 155.68,
            "first_token_latency_s": 0.0465,
            "inter_token_latency_ms": 6.26,
            "peak_memory_gb": 0.996,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "üá®üá≥",
            "tokens_per_second": 155.31,
            "first_token_latency_s": 0.052,
            "inter_token_latency_ms": 6.26,
            "peak_memory_gb": 1.012,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "üá™üá∏",
            "tokens_per_second": 155.74,
            "first_token_latency_s": 0.0434,
            "inter_token_latency_ms": 6.28,
            "peak_memory_gb": 1.027,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "üá©üá™",
            "tokens_per_second": 156.2,
            "first_token_latency_s": 0.0462,
            "inter_token_latency_ms": 6.25,
            "peak_memory_gb": 1.042,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "üá∏üá¶",
            "tokens_per_second": 146.3,
            "first_token_latency_s": 0.0594,
            "inter_token_latency_ms": 6.62,
            "peak_memory_gb": 1.059,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6024,
                "first_token_latency_s": 0.0123,
                "tokens_per_second": 159.76,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.974,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.749,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.23,
                "p90_inter_token_latency_ms": 6.61
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6112,
                "first_token_latency_s": 0.0207,
                "tokens_per_second": 158.89,
                "memory_before_gb": 0.974,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.24,
                "p90_inter_token_latency_ms": 6.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6248,
                "first_token_latency_s": 0.0381,
                "tokens_per_second": 157.56,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.981,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.756,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.22,
                "p90_inter_token_latency_ms": 6.66
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 158.74,
              "std_tokens_per_second": 0.9,
              "avg_first_token_latency_s": 0.0237,
              "avg_inter_token_latency_ms": 6.23,
              "avg_total_time_s": 1.6128,
              "peak_memory_gb": 0.981,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 9,
              "duration_s": 4.393304824829102,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 71.8,
                "max_percent": 71.8,
                "peak_used_gb": 11.06
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6903,
                "first_token_latency_s": 0.0895,
                "tokens_per_second": 151.45,
                "memory_before_gb": 0.981,
                "memory_after_gb": 0.982,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.757,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.28,
                "p90_inter_token_latency_ms": 6.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6402,
                "first_token_latency_s": 0.0374,
                "tokens_per_second": 156.08,
                "memory_before_gb": 0.982,
                "memory_after_gb": 0.989,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.764,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.28,
                "p90_inter_token_latency_ms": 6.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.65,
                "first_token_latency_s": 0.0443,
                "tokens_per_second": 155.15,
                "memory_before_gb": 0.989,
                "memory_after_gb": 0.996,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.772,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.3,
                "p90_inter_token_latency_ms": 6.66
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 154.23,
              "std_tokens_per_second": 2.0,
              "avg_first_token_latency_s": 0.0571,
              "avg_inter_token_latency_ms": 6.29,
              "avg_total_time_s": 1.6602,
              "peak_memory_gb": 0.996,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.913275718688965,
              "cpu": {
                "avg_percent": 6.4,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 71.9,
                "max_percent": 72.0,
                "peak_used_gb": 11.08
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6861,
                "first_token_latency_s": 0.0767,
                "tokens_per_second": 151.83,
                "memory_before_gb": 0.997,
                "memory_after_gb": 0.997,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.772,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.31,
                "p90_inter_token_latency_ms": 6.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6261,
                "first_token_latency_s": 0.0214,
                "tokens_per_second": 157.43,
                "memory_before_gb": 0.997,
                "memory_after_gb": 1.005,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.78,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.29,
                "p90_inter_token_latency_ms": 6.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6373,
                "first_token_latency_s": 0.0337,
                "tokens_per_second": 156.35,
                "memory_before_gb": 1.005,
                "memory_after_gb": 1.013,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.788,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.29,
                "p90_inter_token_latency_ms": 6.64
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 155.2,
              "std_tokens_per_second": 2.43,
              "avg_first_token_latency_s": 0.0439,
              "avg_inter_token_latency_ms": 6.3,
              "avg_total_time_s": 1.6498,
              "peak_memory_gb": 1.013,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.917819976806641,
              "cpu": {
                "avg_percent": 6.4,
                "max_percent": 9.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.1,
                "max_percent": 72.1,
                "peak_used_gb": 11.11
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.6613,
                "first_token_latency_s": 0.0719,
                "tokens_per_second": 154.1,
                "memory_before_gb": 1.012,
                "memory_after_gb": 1.013,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.788,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.23,
                "p90_inter_token_latency_ms": 6.63
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6324,
                "first_token_latency_s": 0.0362,
                "tokens_per_second": 156.83,
                "memory_before_gb": 1.013,
                "memory_after_gb": 1.02,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.795,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.26,
                "p90_inter_token_latency_ms": 6.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6149,
                "first_token_latency_s": 0.0334,
                "tokens_per_second": 158.52,
                "memory_before_gb": 1.02,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.802,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.2,
                "p90_inter_token_latency_ms": 6.56
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 156.48,
              "std_tokens_per_second": 1.82,
              "avg_first_token_latency_s": 0.0472,
              "avg_inter_token_latency_ms": 6.23,
              "avg_total_time_s": 1.6362,
              "peak_memory_gb": 1.028,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.916372537612915,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 14.1,
                "min_percent": 5.3
              },
              "ram": {
                "avg_percent": 72.2,
                "max_percent": 72.3,
                "peak_used_gb": 11.14
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.685,
                "first_token_latency_s": 0.0772,
                "tokens_per_second": 151.93,
                "memory_before_gb": 1.027,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.803,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.3,
                "p90_inter_token_latency_ms": 6.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6364,
                "first_token_latency_s": 0.0309,
                "tokens_per_second": 156.44,
                "memory_before_gb": 1.028,
                "memory_after_gb": 1.036,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.811,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.29,
                "p90_inter_token_latency_ms": 6.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.6396,
                "first_token_latency_s": 0.0342,
                "tokens_per_second": 156.14,
                "memory_before_gb": 1.036,
                "memory_after_gb": 1.043,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.818,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 6.29,
                "p90_inter_token_latency_ms": 6.68
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 154.84,
              "std_tokens_per_second": 2.06,
              "avg_first_token_latency_s": 0.0474,
              "avg_inter_token_latency_ms": 6.29,
              "avg_total_time_s": 1.6537,
              "peak_memory_gb": 1.043,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 10,
              "duration_s": 4.899520635604858,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 13.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 72.3,
                "max_percent": 72.4,
                "peak_used_gb": 11.15
              }
            }
          }
        },
        "backend": {
          "backend": "rocm",
          "n_gpu_layers": -1,
          "details": "AMD GPU d√©tect√© (AMD Radeon(TM) Graphics via wmi), utilisation de ROCm/HIP",
          "amd_device": "AMD Radeon(TM) Graphics",
          "amd_vram_mb": 512,
          "driver_version": "31.0.21921.1000",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "G√©n√©ral / Connaissances",
            "icon": "üìö",
            "tokens_per_second": 158.74,
            "first_token_latency_s": 0.0237,
            "inter_token_latency_ms": 6.23,
            "peak_memory_gb": 0.981,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "üíª",
            "tokens_per_second": 154.23,
            "first_token_latency_s": 0.0571,
            "inter_token_latency_ms": 6.29,
            "peak_memory_gb": 0.996,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "üß†",
            "tokens_per_second": 155.2,
            "first_token_latency_s": 0.0439,
            "inter_token_latency_ms": 6.3,
            "peak_memory_gb": 1.013,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Cr√©atif / R√©daction",
            "icon": "‚úçÔ∏è",
            "tokens_per_second": 156.48,
            "first_token_latency_s": 0.0472,
            "inter_token_latency_ms": 6.23,
            "peak_memory_gb": 1.028,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Math√©matiques",
            "icon": "üî¢",
            "tokens_per_second": 154.84,
            "first_token_latency_s": 0.0474,
            "inter_token_latency_ms": 6.29,
            "peak_memory_gb": 1.043,
            "stability": "stable"
          }
        ]
      }
    }
  }
}