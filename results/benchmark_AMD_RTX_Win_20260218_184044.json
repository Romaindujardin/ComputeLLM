{
  "id": "20260218_184044",
  "timestamp": "2026-02-18T18:40:44.667022",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26200-SP0",
      "python_version": "3.11.9"
    },
    "cpu": {
      "physical_cores": 12,
      "logical_cores": 24,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier spécifié est introuvable",
      "model": "AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 3701.0,
        "min": null,
        "max": 3701.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "NVIDIA",
          "name": "NVIDIA GeForce RTX 4070",
          "vram_total_mb": 12282.0,
          "vram_free_mb": 10427.0,
          "driver_version": "591.74",
          "compute_capability": "8.9",
          "backend": "cuda"
        }
      ],
      "backends": [
        "cuda",
        "cpu"
      ],
      "primary_backend": "cuda",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.5.1+cu121",
        "pytorch_cuda": true,
        "pytorch_cuda_version": "12.1",
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": true,
        "llama_cpp_version": "0.3.4",
        "llama_server": false,
        "ipex": false
      }
    },
    "ram": {
      "total_gb": 63.93,
      "available_gb": 51.26,
      "used_gb": 12.67,
      "percent_used": 19.8,
      "swap_total_gb": 4.0,
      "swap_used_gb": 0.0,
      "unified_memory": false
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 6.21,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread)",
        "results": {
          "512x512": {
            "times_s": [
              0.0012,
              0.0012,
              0.001
            ],
            "mean_s": 0.0011,
            "std_s": 0.0001,
            "gflops": 239.35
          },
          "1024x1024": {
            "times_s": [
              0.0052,
              0.005,
              0.0051
            ],
            "mean_s": 0.0051,
            "std_s": 0.0001,
            "gflops": 420.1
          },
          "2048x2048": {
            "times_s": [
              0.0262,
              0.0224,
              0.0243
            ],
            "mean_s": 0.0243,
            "std_s": 0.0016,
            "gflops": 706.84
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 24 threads)",
        "n_threads": 24,
        "results": {
          "512x512": {
            "times_s": [
              0.0011,
              0.0012,
              0.0011
            ],
            "mean_s": 0.0011,
            "std_s": 0.0,
            "gflops": 239.77
          },
          "1024x1024": {
            "times_s": [
              0.0053,
              0.0053,
              0.0057
            ],
            "mean_s": 0.0055,
            "std_s": 0.0002,
            "gflops": 394.03
          },
          "2048x2048": {
            "times_s": [
              0.0253,
              0.0288,
              0.0249
            ],
            "mean_s": 0.0264,
            "std_s": 0.0018,
            "gflops": 651.89
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0385,
            "bandwidth_gb_s": 6.49
          },
          "read": {
            "mean_s": 0.0316,
            "bandwidth_gb_s": 7.91
          },
          "copy": {
            "mean_s": 0.0451,
            "bandwidth_gb_s": 5.55
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 4070",
        "backend": "CUDA",
        "results": {
          "1024x1024": {
            "times_s": [
              0.0016,
              0.0016,
              0.0025
            ],
            "mean_s": 0.0019,
            "gflops": 1121.17
          },
          "2048x2048": {
            "times_s": [
              0.0387,
              0.0263,
              0.016
            ],
            "mean_s": 0.027,
            "gflops": 636.33
          },
          "4096x4096": {
            "times_s": [
              0.0075,
              0.0066,
              0.0066
            ],
            "mean_s": 0.0069,
            "gflops": 19945.86
          }
        }
      }
    },
    "resource_usage": {
      "n_samples": 11,
      "duration_s": 5.662895441055298,
      "cpu": {
        "avg_percent": 11.4,
        "max_percent": 26.5,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 19.8,
        "max_percent": 20.5,
        "peak_used_gb": 13.12
      },
      "gpu": {
        "avg_utilization_percent": 11.7,
        "max_utilization_percent": 15.0,
        "peak_memory_mb": 1672.0,
        "max_temperature_c": 41.0
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 1,
      "n_benchmark_runs": 3
    },
    "total_time_s": 9281.44,
    "models_tested": 4,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 0.8483,
            "first_token_latency_s": 0.0075,
            "tokens_per_second": 301.78,
            "memory_before_gb": 1.34,
            "memory_after_gb": 1.34,
            "memory_delta_gb": 0.001,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 3.3,
            "p90_inter_token_latency_ms": 3.58
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.8207,
            "first_token_latency_s": 0.0044,
            "tokens_per_second": 311.94,
            "memory_before_gb": 1.34,
            "memory_after_gb": 1.341,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 3.2,
            "p90_inter_token_latency_ms": 3.54
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.8234,
            "first_token_latency_s": 0.0051,
            "tokens_per_second": 310.91,
            "memory_before_gb": 1.341,
            "memory_after_gb": 1.341,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 3.21,
            "p90_inter_token_latency_ms": 3.57
          }
        ],
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "model_load_time_s": 0.29,
        "resource_usage": {
          "n_samples": 5,
          "duration_s": 2.2084293365478516,
          "cpu": {
            "avg_percent": 8.4,
            "max_percent": 11.8,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 20.6,
            "max_percent": 20.6,
            "peak_used_gb": 13.17
          },
          "gpu": {
            "avg_utilization_percent": 62.0,
            "max_utilization_percent": 86.0,
            "peak_memory_mb": 2402.0,
            "max_temperature_c": 51.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 308.21,
          "std_tokens_per_second": 4.57,
          "avg_first_token_latency_s": 0.0057,
          "avg_total_time_s": 0.8308,
          "peak_memory_gb": 1.341,
          "stability": "stable"
        }
      },
      "mistral-7b": {
        "model": "Mistral 7B",
        "params": "7B",
        "status": "completed",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 3.132,
            "first_token_latency_s": 0.0151,
            "tokens_per_second": 81.74,
            "memory_before_gb": 4.758,
            "memory_after_gb": 4.759,
            "memory_delta_gb": 0.001,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 12.22,
            "p90_inter_token_latency_ms": 12.83
          },
          {
            "tokens_generated": 256,
            "total_time_s": 3.1079,
            "first_token_latency_s": 0.0144,
            "tokens_per_second": 82.37,
            "memory_before_gb": 4.759,
            "memory_after_gb": 4.76,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 12.13,
            "p90_inter_token_latency_ms": 12.59
          },
          {
            "tokens_generated": 256,
            "total_time_s": 3.0932,
            "first_token_latency_s": 0.0134,
            "tokens_per_second": 82.76,
            "memory_before_gb": 4.76,
            "memory_after_gb": 4.76,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 12.08,
            "p90_inter_token_latency_ms": 12.59
          }
        ],
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "model_load_time_s": 2.09,
        "resource_usage": {
          "n_samples": 17,
          "duration_s": 8.83910870552063,
          "cpu": {
            "avg_percent": 9.3,
            "max_percent": 12.7,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 25.6,
            "max_percent": 26.0,
            "peak_used_gb": 16.63
          },
          "gpu": {
            "avg_utilization_percent": 90.8,
            "max_utilization_percent": 93.0,
            "peak_memory_mb": 6093.0,
            "max_temperature_c": 60.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 82.29,
          "std_tokens_per_second": 0.42,
          "avg_first_token_latency_s": 0.0143,
          "avg_total_time_s": 3.111,
          "peak_memory_gb": 4.76,
          "stability": "stable"
        }
      },
      "llama2-13b": {
        "model": "Llama 2 13B",
        "params": "13B",
        "status": "completed",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 5.2849,
            "first_token_latency_s": 0.0242,
            "tokens_per_second": 48.44,
            "memory_before_gb": 8.004,
            "memory_after_gb": 8.005,
            "memory_delta_gb": 0.001,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 20.63,
            "p90_inter_token_latency_ms": 21.1
          },
          {
            "tokens_generated": 256,
            "total_time_s": 5.2843,
            "first_token_latency_s": 0.0223,
            "tokens_per_second": 48.45,
            "memory_before_gb": 8.005,
            "memory_after_gb": 8.005,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 20.63,
            "p90_inter_token_latency_ms": 21.27
          },
          {
            "tokens_generated": 256,
            "total_time_s": 5.2982,
            "first_token_latency_s": 0.0226,
            "tokens_per_second": 48.32,
            "memory_before_gb": 8.005,
            "memory_after_gb": 8.006,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 20.69,
            "p90_inter_token_latency_ms": 21.12
          }
        ],
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "model_load_time_s": 3.84,
        "resource_usage": {
          "n_samples": 29,
          "duration_s": 15.417006015777588,
          "cpu": {
            "avg_percent": 8.6,
            "max_percent": 12.1,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 30.6,
            "max_percent": 30.6,
            "peak_used_gb": 19.59
          },
          "gpu": {
            "avg_utilization_percent": 92.9,
            "max_utilization_percent": 94.0,
            "peak_memory_mb": 10757.0,
            "max_temperature_c": 61.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 48.4,
          "std_tokens_per_second": 0.06,
          "avg_first_token_latency_s": 0.023,
          "avg_total_time_s": 5.2891,
          "peak_memory_gb": 8.006,
          "stability": "stable"
        }
      },
      "codellama-34b": {
        "model": "CodeLlama 34B",
        "params": "34B",
        "status": "completed",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 160.5147,
            "first_token_latency_s": 0.6226,
            "tokens_per_second": 1.59,
            "memory_before_gb": 28.841,
            "memory_after_gb": 28.842,
            "memory_delta_gb": 0.001,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 627.03,
            "p90_inter_token_latency_ms": 638.93
          },
          {
            "tokens_generated": 256,
            "total_time_s": 160.9684,
            "first_token_latency_s": 0.6189,
            "tokens_per_second": 1.59,
            "memory_before_gb": 28.842,
            "memory_after_gb": 28.748,
            "memory_delta_gb": -0.094,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 628.82,
            "p90_inter_token_latency_ms": 641.74
          },
          {
            "tokens_generated": 256,
            "total_time_s": 159.7277,
            "first_token_latency_s": 0.6221,
            "tokens_per_second": 1.6,
            "memory_before_gb": 28.748,
            "memory_after_gb": 28.748,
            "memory_delta_gb": 0.0,
            "error": null,
            "success": true,
            "avg_inter_token_latency_ms": 623.94,
            "p90_inter_token_latency_ms": 639.61
          }
        ],
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "model_load_time_s": 13.52,
        "resource_usage": {
          "n_samples": 874,
          "duration_s": 480.6630001068115,
          "cpu": {
            "avg_percent": 8.8,
            "max_percent": 41.0,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 61.9,
            "max_percent": 63.2,
            "peak_used_gb": 40.4
          },
          "gpu": {
            "avg_utilization_percent": 99.7,
            "max_utilization_percent": 100.0,
            "peak_memory_mb": 11836.0,
            "max_temperature_c": 47.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 1.59,
          "std_tokens_per_second": 0.0,
          "avg_first_token_latency_s": 0.6212,
          "avg_total_time_s": 160.4036,
          "peak_memory_gb": 28.842,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8112,
                "first_token_latency_s": 0.0058,
                "tokens_per_second": 315.57,
                "memory_before_gb": 1.47,
                "memory_after_gb": 1.28,
                "memory_delta_gb": -0.19,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.16,
                "p90_inter_token_latency_ms": 3.45
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7989,
                "first_token_latency_s": 0.0048,
                "tokens_per_second": 320.45,
                "memory_before_gb": 1.28,
                "memory_after_gb": 1.276,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.11,
                "p90_inter_token_latency_ms": 3.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8186,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 312.72,
                "memory_before_gb": 1.276,
                "memory_after_gb": 1.273,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.19,
                "p90_inter_token_latency_ms": 3.56
              }
            ],
            "actual_file_size_gb": 0.45,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.33,
            "memory_after_load_gb": 1.469,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2131495475769043,
              "cpu": {
                "avg_percent": 8.9,
                "max_percent": 14.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.6,
                "max_percent": 17.8,
                "peak_used_gb": 11.37
              },
              "gpu": {
                "avg_utilization_percent": 73.8,
                "max_utilization_percent": 76.0,
                "peak_memory_mb": 2139.0,
                "max_temperature_c": 49.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 316.25,
              "std_tokens_per_second": 3.19,
              "min_tokens_per_second": 312.72,
              "max_tokens_per_second": 320.45,
              "avg_first_token_latency_s": 0.005,
              "avg_inter_token_latency_ms": 3.15,
              "avg_total_time_s": 0.8096,
              "peak_memory_gb": 1.28,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8373,
                "first_token_latency_s": 0.0102,
                "tokens_per_second": 305.73,
                "memory_before_gb": 1.201,
                "memory_after_gb": 1.198,
                "memory_delta_gb": -0.003,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.24,
                "p90_inter_token_latency_ms": 3.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8191,
                "first_token_latency_s": 0.0047,
                "tokens_per_second": 312.54,
                "memory_before_gb": 1.198,
                "memory_after_gb": 1.195,
                "memory_delta_gb": -0.003,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.19,
                "p90_inter_token_latency_ms": 3.49
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8377,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 305.61,
                "memory_before_gb": 1.195,
                "memory_after_gb": 1.195,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.26,
                "p90_inter_token_latency_ms": 3.53
              }
            ],
            "actual_file_size_gb": 0.513,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.25,
            "memory_after_load_gb": 1.201,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2295327186584473,
              "cpu": {
                "avg_percent": 7.4,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.4,
                "max_percent": 17.4,
                "peak_used_gb": 11.12
              },
              "gpu": {
                "avg_utilization_percent": 65.0,
                "max_utilization_percent": 80.0,
                "peak_memory_mb": 2197.0,
                "max_temperature_c": 50.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 307.96,
              "std_tokens_per_second": 3.24,
              "min_tokens_per_second": 305.61,
              "max_tokens_per_second": 312.54,
              "avg_first_token_latency_s": 0.0068,
              "avg_inter_token_latency_ms": 3.23,
              "avg_total_time_s": 0.8314,
              "peak_memory_gb": 1.198,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8274,
                "first_token_latency_s": 0.0057,
                "tokens_per_second": 309.4,
                "memory_before_gb": 1.254,
                "memory_after_gb": 1.254,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.22,
                "p90_inter_token_latency_ms": 3.52
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8187,
                "first_token_latency_s": 0.0046,
                "tokens_per_second": 312.67,
                "memory_before_gb": 1.254,
                "memory_after_gb": 1.255,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.19,
                "p90_inter_token_latency_ms": 3.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8173,
                "first_token_latency_s": 0.0049,
                "tokens_per_second": 313.21,
                "memory_before_gb": 1.255,
                "memory_after_gb": 1.255,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.18,
                "p90_inter_token_latency_ms": 3.47
              }
            ],
            "actual_file_size_gb": 0.623,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.3,
            "memory_after_load_gb": 1.253,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2504119873046875,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 12.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.5,
                "max_percent": 17.5,
                "peak_used_gb": 11.16
              },
              "gpu": {
                "avg_utilization_percent": 77.8,
                "max_utilization_percent": 90.0,
                "peak_memory_mb": 2300.0,
                "max_temperature_c": 49.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 311.76,
              "std_tokens_per_second": 1.68,
              "min_tokens_per_second": 309.4,
              "max_tokens_per_second": 313.21,
              "avg_first_token_latency_s": 0.0051,
              "avg_inter_token_latency_ms": 3.2,
              "avg_total_time_s": 0.8211,
              "peak_memory_gb": 1.255,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8929,
                "first_token_latency_s": 0.0052,
                "tokens_per_second": 286.72,
                "memory_before_gb": 1.352,
                "memory_after_gb": 1.353,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.48,
                "p90_inter_token_latency_ms": 3.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8789,
                "first_token_latency_s": 0.0055,
                "tokens_per_second": 291.26,
                "memory_before_gb": 1.353,
                "memory_after_gb": 1.353,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.42,
                "p90_inter_token_latency_ms": 3.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8953,
                "first_token_latency_s": 0.0049,
                "tokens_per_second": 285.95,
                "memory_before_gb": 1.353,
                "memory_after_gb": 1.354,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.49,
                "p90_inter_token_latency_ms": 3.87
              }
            ],
            "actual_file_size_gb": 0.729,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.33,
            "memory_after_load_gb": 1.352,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.235128402709961,
              "cpu": {
                "avg_percent": 9.0,
                "max_percent": 16.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.6,
                "max_percent": 17.6,
                "peak_used_gb": 11.25
              },
              "gpu": {
                "avg_utilization_percent": 64.6,
                "max_utilization_percent": 79.0,
                "peak_memory_mb": 2402.0,
                "max_temperature_c": 51.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 287.98,
              "std_tokens_per_second": 2.34,
              "min_tokens_per_second": 285.95,
              "max_tokens_per_second": 291.26,
              "avg_first_token_latency_s": 0.0052,
              "avg_inter_token_latency_ms": 3.46,
              "avg_total_time_s": 0.889,
              "peak_memory_gb": 1.354,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.9538,
                "first_token_latency_s": 0.0057,
                "tokens_per_second": 268.39,
                "memory_before_gb": 1.457,
                "memory_after_gb": 1.458,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.72,
                "p90_inter_token_latency_ms": 3.98
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9519,
                "first_token_latency_s": 0.0051,
                "tokens_per_second": 268.92,
                "memory_before_gb": 1.458,
                "memory_after_gb": 1.458,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.71,
                "p90_inter_token_latency_ms": 4.02
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9421,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 271.73,
                "memory_before_gb": 1.458,
                "memory_after_gb": 1.459,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.67,
                "p90_inter_token_latency_ms": 4.0
              }
            ],
            "actual_file_size_gb": 0.842,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.37,
            "memory_after_load_gb": 1.457,
            "resource_usage": {
              "n_samples": 6,
              "duration_s": 2.7911295890808105,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 11.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.8,
                "max_percent": 17.8,
                "peak_used_gb": 11.36
              },
              "gpu": {
                "avg_utilization_percent": 80.0,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 2508.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 269.68,
              "std_tokens_per_second": 1.47,
              "min_tokens_per_second": 268.39,
              "max_tokens_per_second": 271.73,
              "avg_first_token_latency_s": 0.0054,
              "avg_inter_token_latency_ms": 3.7,
              "avg_total_time_s": 0.9493,
              "peak_memory_gb": 1.459,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 1.0873,
                "first_token_latency_s": 0.0063,
                "tokens_per_second": 235.44,
                "memory_before_gb": 1.691,
                "memory_after_gb": 1.691,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 4.24,
                "p90_inter_token_latency_ms": 4.54
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.0825,
                "first_token_latency_s": 0.0055,
                "tokens_per_second": 236.49,
                "memory_before_gb": 1.691,
                "memory_after_gb": 1.692,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 4.22,
                "p90_inter_token_latency_ms": 4.54
              },
              {
                "tokens_generated": 256,
                "total_time_s": 1.0961,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 233.56,
                "memory_before_gb": 1.692,
                "memory_after_gb": 1.692,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 4.28,
                "p90_inter_token_latency_ms": 4.65
              }
            ],
            "actual_file_size_gb": 1.09,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 0.45,
            "memory_after_load_gb": 1.69,
            "resource_usage": {
              "n_samples": 6,
              "duration_s": 2.7758779525756836,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 18.1,
                "max_percent": 18.1,
                "peak_used_gb": 11.6
              },
              "gpu": {
                "avg_utilization_percent": 83.2,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 2748.0,
                "max_temperature_c": 51.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 235.16,
              "std_tokens_per_second": 1.21,
              "min_tokens_per_second": 233.56,
              "max_tokens_per_second": 236.49,
              "avg_first_token_latency_s": 0.0057,
              "avg_inter_token_latency_ms": 4.25,
              "avg_total_time_s": 1.0886,
              "peak_memory_gb": 1.692,
              "stability": "stable"
            }
          }
        },
        "total_time_s": 34.49,
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 316.25,
            "first_token_latency_s": 0.005,
            "inter_token_latency_ms": 3.15,
            "peak_memory_gb": 1.28,
            "model_load_time_s": 0.33,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 307.96,
            "first_token_latency_s": 0.0068,
            "inter_token_latency_ms": 3.23,
            "peak_memory_gb": 1.198,
            "model_load_time_s": 0.25,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 311.76,
            "first_token_latency_s": 0.0051,
            "inter_token_latency_ms": 3.2,
            "peak_memory_gb": 1.255,
            "model_load_time_s": 0.3,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 287.98,
            "first_token_latency_s": 0.0052,
            "inter_token_latency_ms": 3.46,
            "peak_memory_gb": 1.354,
            "model_load_time_s": 0.33,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 269.68,
            "first_token_latency_s": 0.0054,
            "inter_token_latency_ms": 3.7,
            "peak_memory_gb": 1.459,
            "model_load_time_s": 0.37,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 235.16,
            "first_token_latency_s": 0.0057,
            "inter_token_latency_ms": 4.25,
            "peak_memory_gb": 1.692,
            "model_load_time_s": 0.45,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.87,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6757,
                "first_token_latency_s": 0.0135,
                "tokens_per_second": 95.68,
                "memory_before_gb": 3.501,
                "memory_after_gb": 3.502,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 10.44,
                "p90_inter_token_latency_ms": 10.94
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.683,
                "first_token_latency_s": 0.0119,
                "tokens_per_second": 95.41,
                "memory_before_gb": 3.502,
                "memory_after_gb": 3.502,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 10.47,
                "p90_inter_token_latency_ms": 10.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6798,
                "first_token_latency_s": 0.012,
                "tokens_per_second": 95.53,
                "memory_before_gb": 3.502,
                "memory_after_gb": 3.502,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 10.46,
                "p90_inter_token_latency_ms": 10.92
              }
            ],
            "actual_file_size_gb": 2.871,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 1.59,
            "memory_after_load_gb": 3.501,
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.715896368026733,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.0,
                "max_percent": 21.0,
                "peak_used_gb": 13.43
              },
              "gpu": {
                "avg_utilization_percent": 89.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 4826.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 95.54,
              "std_tokens_per_second": 0.11,
              "min_tokens_per_second": 95.41,
              "max_tokens_per_second": 95.68,
              "avg_first_token_latency_s": 0.0125,
              "avg_inter_token_latency_ms": 10.46,
              "avg_total_time_s": 2.6795,
              "peak_memory_gb": 3.502,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.28,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8416,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 90.09,
                "memory_before_gb": 3.895,
                "memory_after_gb": 3.895,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.09,
                "p90_inter_token_latency_ms": 11.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.85,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 89.83,
                "memory_before_gb": 3.895,
                "memory_after_gb": 3.896,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.12,
                "p90_inter_token_latency_ms": 11.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8432,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 90.04,
                "memory_before_gb": 3.896,
                "memory_after_gb": 3.896,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.1,
                "p90_inter_token_latency_ms": 11.61
              }
            ],
            "actual_file_size_gb": 3.277,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 1.76,
            "memory_after_load_gb": 3.894,
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.30509877204895,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 10.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.6,
                "max_percent": 21.6,
                "peak_used_gb": 13.83
              },
              "gpu": {
                "avg_utilization_percent": 90.2,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5228.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.99,
              "std_tokens_per_second": 0.11,
              "min_tokens_per_second": 89.83,
              "max_tokens_per_second": 90.09,
              "avg_first_token_latency_s": 0.013,
              "avg_inter_token_latency_ms": 11.1,
              "avg_total_time_s": 2.8449,
              "peak_memory_gb": 3.896,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.07,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.0854,
                "first_token_latency_s": 0.0152,
                "tokens_per_second": 82.97,
                "memory_before_gb": 4.67,
                "memory_after_gb": 4.67,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.04,
                "p90_inter_token_latency_ms": 12.45
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0892,
                "first_token_latency_s": 0.0136,
                "tokens_per_second": 82.87,
                "memory_before_gb": 4.67,
                "memory_after_gb": 4.671,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.06,
                "p90_inter_token_latency_ms": 12.48
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0934,
                "first_token_latency_s": 0.0132,
                "tokens_per_second": 82.76,
                "memory_before_gb": 4.671,
                "memory_after_gb": 4.671,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.08,
                "p90_inter_token_latency_ms": 12.56
              }
            ],
            "actual_file_size_gb": 4.068,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 1.65,
            "memory_after_load_gb": 4.669,
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.815204620361328,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 12.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.8,
                "max_percent": 22.9,
                "peak_used_gb": 14.61
              },
              "gpu": {
                "avg_utilization_percent": 90.6,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 6023.0,
                "max_temperature_c": 61.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.87,
              "std_tokens_per_second": 0.09,
              "min_tokens_per_second": 82.76,
              "max_tokens_per_second": 82.97,
              "avg_first_token_latency_s": 0.014,
              "avg_inter_token_latency_ms": 12.06,
              "avg_total_time_s": 3.0893,
              "peak_memory_gb": 4.671,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.78,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.5397,
                "first_token_latency_s": 0.0169,
                "tokens_per_second": 72.32,
                "memory_before_gb": 5.365,
                "memory_after_gb": 5.366,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 13.81,
                "p90_inter_token_latency_ms": 14.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.5284,
                "first_token_latency_s": 0.0154,
                "tokens_per_second": 72.55,
                "memory_before_gb": 5.366,
                "memory_after_gb": 5.366,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 13.78,
                "p90_inter_token_latency_ms": 14.22
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.529,
                "first_token_latency_s": 0.0149,
                "tokens_per_second": 72.54,
                "memory_before_gb": 5.366,
                "memory_after_gb": 5.367,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 13.78,
                "p90_inter_token_latency_ms": 14.14
              }
            ],
            "actual_file_size_gb": 4.779,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 3.39,
            "memory_after_load_gb": 5.365,
            "resource_usage": {
              "n_samples": 20,
              "duration_s": 10.445744752883911,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 12.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.28
              },
              "gpu": {
                "avg_utilization_percent": 87.4,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 6738.0,
                "max_temperature_c": 61.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 72.47,
              "std_tokens_per_second": 0.11,
              "min_tokens_per_second": 72.32,
              "max_tokens_per_second": 72.55,
              "avg_first_token_latency_s": 0.0157,
              "avg_inter_token_latency_ms": 13.79,
              "avg_total_time_s": 3.5324,
              "peak_memory_gb": 5.367,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.53,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.0014,
                "first_token_latency_s": 0.0194,
                "tokens_per_second": 63.98,
                "memory_before_gb": 6.104,
                "memory_after_gb": 6.105,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 15.61,
                "p90_inter_token_latency_ms": 16.1
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.0012,
                "first_token_latency_s": 0.0179,
                "tokens_per_second": 63.98,
                "memory_before_gb": 6.105,
                "memory_after_gb": 6.105,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 15.62,
                "p90_inter_token_latency_ms": 16.01
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.0056,
                "first_token_latency_s": 0.0176,
                "tokens_per_second": 63.91,
                "memory_before_gb": 6.105,
                "memory_after_gb": 6.106,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 15.64,
                "p90_inter_token_latency_ms": 16.03
              }
            ],
            "actual_file_size_gb": 5.534,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 2.98,
            "memory_after_load_gb": 6.103,
            "resource_usage": {
              "n_samples": 22,
              "duration_s": 11.573629379272461,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 25.0,
                "max_percent": 25.0,
                "peak_used_gb": 16.01
              },
              "gpu": {
                "avg_utilization_percent": 91.5,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 7490.0,
                "max_temperature_c": 63.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 63.96,
              "std_tokens_per_second": 0.03,
              "min_tokens_per_second": 63.91,
              "max_tokens_per_second": 63.98,
              "avg_first_token_latency_s": 0.0183,
              "avg_inter_token_latency_ms": 15.62,
              "avg_total_time_s": 4.0027,
              "peak_memory_gb": 6.106,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.17,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.9384,
                "first_token_latency_s": 0.0218,
                "tokens_per_second": 51.84,
                "memory_before_gb": 7.708,
                "memory_after_gb": 7.709,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 19.28,
                "p90_inter_token_latency_ms": 19.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.9498,
                "first_token_latency_s": 0.0208,
                "tokens_per_second": 51.72,
                "memory_before_gb": 7.709,
                "memory_after_gb": 7.709,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 19.33,
                "p90_inter_token_latency_ms": 19.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.9521,
                "first_token_latency_s": 0.0207,
                "tokens_per_second": 51.7,
                "memory_before_gb": 7.709,
                "memory_after_gb": 7.71,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 19.34,
                "p90_inter_token_latency_ms": 19.68
              }
            ],
            "actual_file_size_gb": 7.167,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 3.91,
            "memory_after_load_gb": 7.707,
            "resource_usage": {
              "n_samples": 27,
              "duration_s": 14.3383047580719,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 11.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.5,
                "max_percent": 27.5,
                "peak_used_gb": 17.6
              },
              "gpu": {
                "avg_utilization_percent": 93.8,
                "max_utilization_percent": 98.0,
                "peak_memory_mb": 9132.0,
                "max_temperature_c": 57.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 51.75,
              "std_tokens_per_second": 0.06,
              "min_tokens_per_second": 51.7,
              "max_tokens_per_second": 51.84,
              "avg_first_token_latency_s": 0.0211,
              "avg_inter_token_latency_ms": 19.32,
              "avg_total_time_s": 4.9468,
              "peak_memory_gb": 7.71,
              "stability": "stable"
            }
          }
        },
        "total_time_s": 98.41,
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.871,
            "tokens_per_second": 95.54,
            "first_token_latency_s": 0.0125,
            "inter_token_latency_ms": 10.46,
            "peak_memory_gb": 3.502,
            "model_load_time_s": 1.59,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.277,
            "tokens_per_second": 89.99,
            "first_token_latency_s": 0.013,
            "inter_token_latency_ms": 11.1,
            "peak_memory_gb": 3.896,
            "model_load_time_s": 1.76,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.068,
            "tokens_per_second": 82.87,
            "first_token_latency_s": 0.014,
            "inter_token_latency_ms": 12.06,
            "peak_memory_gb": 4.671,
            "model_load_time_s": 1.65,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.779,
            "tokens_per_second": 72.47,
            "first_token_latency_s": 0.0157,
            "inter_token_latency_ms": 13.79,
            "peak_memory_gb": 5.367,
            "model_load_time_s": 3.39,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.534,
            "tokens_per_second": 63.96,
            "first_token_latency_s": 0.0183,
            "inter_token_latency_ms": 15.62,
            "peak_memory_gb": 6.106,
            "model_load_time_s": 2.98,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.167,
            "tokens_per_second": 51.75,
            "first_token_latency_s": 0.0211,
            "inter_token_latency_ms": 19.32,
            "peak_memory_gb": 7.71,
            "model_load_time_s": 3.91,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.13,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 244,
                "total_time_s": 4.422,
                "first_token_latency_s": 0.0209,
                "tokens_per_second": 55.18,
                "memory_before_gb": 5.678,
                "memory_after_gb": 5.679,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 18.11,
                "p90_inter_token_latency_ms": 17.83
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.4289,
                "first_token_latency_s": 0.02,
                "tokens_per_second": 57.8,
                "memory_before_gb": 5.679,
                "memory_after_gb": 5.68,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 17.29,
                "p90_inter_token_latency_ms": 17.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.4418,
                "first_token_latency_s": 0.0198,
                "tokens_per_second": 57.63,
                "memory_before_gb": 5.68,
                "memory_after_gb": 5.68,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 17.34,
                "p90_inter_token_latency_ms": 17.73
              }
            ],
            "actual_file_size_gb": 5.056,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 2.8,
            "memory_after_load_gb": 5.678,
            "resource_usage": {
              "n_samples": 25,
              "duration_s": 13.260942459106445,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 12.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 24.3,
                "max_percent": 24.3,
                "peak_used_gb": 15.56
              },
              "gpu": {
                "avg_utilization_percent": 91.8,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 8438.0,
                "max_temperature_c": 65.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 56.87,
              "std_tokens_per_second": 1.2,
              "min_tokens_per_second": 55.18,
              "max_tokens_per_second": 57.8,
              "avg_first_token_latency_s": 0.0202,
              "avg_inter_token_latency_ms": 17.58,
              "avg_total_time_s": 4.4309,
              "peak_memory_gb": 5.68,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 6.34,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.7961,
                "first_token_latency_s": 0.022,
                "tokens_per_second": 53.38,
                "memory_before_gb": 6.51,
                "memory_after_gb": 6.511,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 18.72,
                "p90_inter_token_latency_ms": 19.22
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.8112,
                "first_token_latency_s": 0.0205,
                "tokens_per_second": 53.21,
                "memory_before_gb": 6.511,
                "memory_after_gb": 6.511,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 18.79,
                "p90_inter_token_latency_ms": 19.4
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.8087,
                "first_token_latency_s": 0.0212,
                "tokens_per_second": 53.24,
                "memory_before_gb": 6.511,
                "memory_after_gb": 6.511,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 18.77,
                "p90_inter_token_latency_ms": 19.24
              }
            ],
            "actual_file_size_gb": 5.903,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 3.18,
            "memory_after_load_gb": 6.509,
            "resource_usage": {
              "n_samples": 27,
              "duration_s": 14.340167760848999,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 25.6,
                "max_percent": 25.6,
                "peak_used_gb": 16.39
              },
              "gpu": {
                "avg_utilization_percent": 92.5,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 9290.0,
                "max_temperature_c": 65.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 53.28,
              "std_tokens_per_second": 0.07,
              "min_tokens_per_second": 53.21,
              "max_tokens_per_second": 53.38,
              "avg_first_token_latency_s": 0.0212,
              "avg_inter_token_latency_ms": 18.76,
              "avg_total_time_s": 4.8053,
              "peak_memory_gb": 6.511,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.87,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3283,
                "first_token_latency_s": 0.0249,
                "tokens_per_second": 48.05,
                "memory_before_gb": 7.913,
                "memory_after_gb": 7.914,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.8,
                "p90_inter_token_latency_ms": 21.27
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3081,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 48.23,
                "memory_before_gb": 7.914,
                "memory_after_gb": 7.914,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.73,
                "p90_inter_token_latency_ms": 21.27
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3073,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 48.24,
                "memory_before_gb": 7.914,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.72,
                "p90_inter_token_latency_ms": 21.33
              }
            ],
            "actual_file_size_gb": 7.326,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 3.94,
            "memory_after_load_gb": 7.913,
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.421365022659302,
              "cpu": {
                "avg_percent": 8.7,
                "max_percent": 20.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.9,
                "max_percent": 27.9,
                "peak_used_gb": 17.85
              },
              "gpu": {
                "avg_utilization_percent": 93.1,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10727.0,
                "max_temperature_c": 64.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.17,
              "std_tokens_per_second": 0.09,
              "min_tokens_per_second": 48.05,
              "max_tokens_per_second": 48.24,
              "avg_first_token_latency_s": 0.0234,
              "avg_inter_token_latency_ms": 20.75,
              "avg_total_time_s": 5.3146,
              "peak_memory_gb": 7.915,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.6,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 8.0828,
                "first_token_latency_s": 0.0323,
                "tokens_per_second": 31.67,
                "memory_before_gb": 9.291,
                "memory_after_gb": 9.292,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 31.57,
                "p90_inter_token_latency_ms": 33.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.0841,
                "first_token_latency_s": 0.0331,
                "tokens_per_second": 31.67,
                "memory_before_gb": 9.292,
                "memory_after_gb": 9.287,
                "memory_delta_gb": -0.005,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 31.57,
                "p90_inter_token_latency_ms": 33.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.1479,
                "first_token_latency_s": 0.0355,
                "tokens_per_second": 31.42,
                "memory_before_gb": 9.287,
                "memory_after_gb": 9.287,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 31.81,
                "p90_inter_token_latency_ms": 33.76
              }
            ],
            "actual_file_size_gb": 8.596,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 4.6,
            "memory_after_load_gb": 9.231,
            "resource_usage": {
              "n_samples": 45,
              "duration_s": 24.21257781982422,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.0,
                "min_percent": 5.5
              },
              "ram": {
                "avg_percent": 30.2,
                "max_percent": 30.2,
                "peak_used_gb": 19.3
              },
              "gpu": {
                "avg_utilization_percent": 95.3,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 11786.0,
                "max_temperature_c": 63.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 31.59,
              "std_tokens_per_second": 0.12,
              "min_tokens_per_second": 31.42,
              "max_tokens_per_second": 31.67,
              "avg_first_token_latency_s": 0.0336,
              "avg_inter_token_latency_ms": 31.65,
              "avg_total_time_s": 8.1049,
              "peak_memory_gb": 9.292,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.95,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 11.8138,
                "first_token_latency_s": 0.0431,
                "tokens_per_second": 21.67,
                "memory_before_gb": 11.9,
                "memory_after_gb": 11.901,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 46.16,
                "p90_inter_token_latency_ms": 52.35
              },
              {
                "tokens_generated": 256,
                "total_time_s": 11.7525,
                "first_token_latency_s": 0.046,
                "tokens_per_second": 21.78,
                "memory_before_gb": 11.901,
                "memory_after_gb": 11.902,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 45.91,
                "p90_inter_token_latency_ms": 51.85
              },
              {
                "tokens_generated": 256,
                "total_time_s": 11.821,
                "first_token_latency_s": 0.0397,
                "tokens_per_second": 21.66,
                "memory_before_gb": 11.902,
                "memory_after_gb": 11.902,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 46.2,
                "p90_inter_token_latency_ms": 52.29
              }
            ],
            "actual_file_size_gb": 9.946,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 6.15,
            "memory_after_load_gb": 11.718,
            "resource_usage": {
              "n_samples": 64,
              "duration_s": 34.86067748069763,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 13.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 34.4,
                "max_percent": 34.4,
                "peak_used_gb": 22.0
              },
              "gpu": {
                "avg_utilization_percent": 96.5,
                "max_utilization_percent": 98.0,
                "peak_memory_mb": 11833.0,
                "max_temperature_c": 61.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 21.7,
              "std_tokens_per_second": 0.05,
              "min_tokens_per_second": 21.66,
              "max_tokens_per_second": 21.78,
              "avg_first_token_latency_s": 0.0429,
              "avg_inter_token_latency_ms": 46.09,
              "avg_total_time_s": 11.7958,
              "peak_memory_gb": 11.902,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 13.83,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 38.8242,
                "first_token_latency_s": 0.1498,
                "tokens_per_second": 6.59,
                "memory_before_gb": 17.643,
                "memory_after_gb": 17.581,
                "memory_delta_gb": -0.061,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 151.66,
                "p90_inter_token_latency_ms": 157.64
              },
              {
                "tokens_generated": 256,
                "total_time_s": 38.8785,
                "first_token_latency_s": 0.1468,
                "tokens_per_second": 6.58,
                "memory_before_gb": 17.581,
                "memory_after_gb": 17.582,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 151.89,
                "p90_inter_token_latency_ms": 158.37
              },
              {
                "tokens_generated": 256,
                "total_time_s": 39.1566,
                "first_token_latency_s": 0.1493,
                "tokens_per_second": 6.54,
                "memory_before_gb": 17.582,
                "memory_after_gb": 17.582,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 152.97,
                "p90_inter_token_latency_ms": 160.38
              }
            ],
            "actual_file_size_gb": 12.881,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 9.71,
            "memory_after_load_gb": 17.552,
            "resource_usage": {
              "n_samples": 212,
              "duration_s": 116.46434712409973,
              "cpu": {
                "avg_percent": 10.1,
                "max_percent": 22.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.3,
                "max_percent": 43.7,
                "peak_used_gb": 27.91
              },
              "gpu": {
                "avg_utilization_percent": 98.7,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11861.0,
                "max_temperature_c": 51.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 6.57,
              "std_tokens_per_second": 0.02,
              "min_tokens_per_second": 6.54,
              "max_tokens_per_second": 6.59,
              "avg_first_token_latency_s": 0.1486,
              "avg_inter_token_latency_ms": 152.17,
              "avg_total_time_s": 38.9531,
              "peak_memory_gb": 17.582,
              "stability": "stable"
            }
          }
        },
        "total_time_s": 279.78,
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.056,
            "tokens_per_second": 56.87,
            "first_token_latency_s": 0.0202,
            "inter_token_latency_ms": 17.58,
            "peak_memory_gb": 5.68,
            "model_load_time_s": 2.8,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 5.903,
            "tokens_per_second": 53.28,
            "first_token_latency_s": 0.0212,
            "inter_token_latency_ms": 18.76,
            "peak_memory_gb": 6.511,
            "model_load_time_s": 3.18,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.326,
            "tokens_per_second": 48.17,
            "first_token_latency_s": 0.0234,
            "inter_token_latency_ms": 20.75,
            "peak_memory_gb": 7.915,
            "model_load_time_s": 3.94,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.596,
            "tokens_per_second": 31.59,
            "first_token_latency_s": 0.0336,
            "inter_token_latency_ms": 31.65,
            "peak_memory_gb": 9.292,
            "model_load_time_s": 4.6,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.946,
            "tokens_per_second": 21.7,
            "first_token_latency_s": 0.0429,
            "inter_token_latency_ms": 46.09,
            "peak_memory_gb": 11.902,
            "model_load_time_s": 6.15,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 12.881,
            "tokens_per_second": 6.57,
            "first_token_latency_s": 0.1486,
            "inter_token_latency_ms": 152.17,
            "peak_memory_gb": 17.582,
            "model_load_time_s": 9.71,
            "stability": "stable"
          }
        ]
      },
      "codellama-34b": {
        "model_name": "CodeLlama 34B",
        "model_key": "codellama-34b",
        "params": "34B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 12.8,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 6,
                "total_time_s": 2.0223,
                "first_token_latency_s": 0.2915,
                "tokens_per_second": 2.97,
                "memory_before_gb": 17.396,
                "memory_after_gb": 17.397,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 288.67,
                "p90_inter_token_latency_ms": 290.1
              },
              {
                "tokens_generated": 255,
                "total_time_s": 77.3812,
                "first_token_latency_s": 0.2932,
                "tokens_per_second": 3.3,
                "memory_before_gb": 17.397,
                "memory_after_gb": 17.398,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 303.49,
                "p90_inter_token_latency_ms": 313.47
              },
              {
                "tokens_generated": 255,
                "total_time_s": 77.4824,
                "first_token_latency_s": 0.2927,
                "tokens_per_second": 3.29,
                "memory_before_gb": 17.398,
                "memory_after_gb": 17.398,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 303.89,
                "p90_inter_token_latency_ms": 314.53
              }
            ],
            "actual_file_size_gb": 13.235,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 9.47,
            "memory_after_load_gb": 17.09,
            "resource_usage": {
              "n_samples": 282,
              "duration_s": 156.40985202789307,
              "cpu": {
                "avg_percent": 12.4,
                "max_percent": 24.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.0,
                "max_percent": 43.7,
                "peak_used_gb": 27.95
              },
              "gpu": {
                "avg_utilization_percent": 99.3,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11851.0,
                "max_temperature_c": 52.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 3.19,
              "std_tokens_per_second": 0.15,
              "min_tokens_per_second": 2.97,
              "max_tokens_per_second": 3.3,
              "avg_first_token_latency_s": 0.2925,
              "avg_inter_token_latency_ms": 298.68,
              "avg_total_time_s": 52.2953,
              "peak_memory_gb": 17.398,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 15.8,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 110.7707,
                "first_token_latency_s": 0.4235,
                "tokens_per_second": 2.31,
                "memory_before_gb": 21.301,
                "memory_after_gb": 21.302,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 432.73,
                "p90_inter_token_latency_ms": 444.06
              },
              {
                "tokens_generated": 256,
                "total_time_s": 110.6923,
                "first_token_latency_s": 0.4248,
                "tokens_per_second": 2.31,
                "memory_before_gb": 21.302,
                "memory_after_gb": 21.302,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 432.42,
                "p90_inter_token_latency_ms": 443.95
              },
              {
                "tokens_generated": 256,
                "total_time_s": 107.2139,
                "first_token_latency_s": 0.4249,
                "tokens_per_second": 2.39,
                "memory_before_gb": 21.302,
                "memory_after_gb": 21.302,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 418.78,
                "p90_inter_token_latency_ms": 429.13
              }
            ],
            "actual_file_size_gb": 15.165,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 12.23,
            "memory_after_load_gb": 20.995,
            "resource_usage": {
              "n_samples": 593,
              "duration_s": 328.6545567512512,
              "cpu": {
                "avg_percent": 12.5,
                "max_percent": 29.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 48.8,
                "max_percent": 49.4,
                "peak_used_gb": 31.56
              },
              "gpu": {
                "avg_utilization_percent": 99.3,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11739.0,
                "max_temperature_c": 64.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 2.34,
              "std_tokens_per_second": 0.04,
              "min_tokens_per_second": 2.31,
              "max_tokens_per_second": 2.39,
              "avg_first_token_latency_s": 0.4244,
              "avg_inter_token_latency_ms": 427.98,
              "avg_total_time_s": 109.559,
              "peak_memory_gb": 21.302,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 20.2,
            "status": "completed",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 151.7659,
                "first_token_latency_s": 0.585,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.499,
                "memory_after_gb": 28.5,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 592.86,
                "p90_inter_token_latency_ms": 602.53
              },
              {
                "tokens_generated": 256,
                "total_time_s": 151.8392,
                "first_token_latency_s": 0.5832,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.5,
                "memory_after_gb": 28.501,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 593.16,
                "p90_inter_token_latency_ms": 603.19
              },
              {
                "tokens_generated": 256,
                "total_time_s": 151.7843,
                "first_token_latency_s": 0.5871,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.501,
                "memory_after_gb": 28.501,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 592.93,
                "p90_inter_token_latency_ms": 603.69
              }
            ],
            "actual_file_size_gb": 18.831,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA"
            },
            "model_load_time_s": 17.09,
            "memory_after_load_gb": 28.193,
            "resource_usage": {
              "n_samples": 828,
              "duration_s": 455.0732970237732,
              "cpu": {
                "avg_percent": 11.6,
                "max_percent": 21.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.9,
                "max_percent": 60.5,
                "peak_used_gb": 38.65
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11791.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.69,
              "std_tokens_per_second": 0.0,
              "min_tokens_per_second": 1.69,
              "max_tokens_per_second": 1.69,
              "avg_first_token_latency_s": 0.5851,
              "avg_inter_token_latency_ms": 592.98,
              "avg_total_time_s": 151.7965,
              "peak_memory_gb": 28.501,
              "stability": "stable"
            }
          }
        },
        "total_time_s": 1027.19,
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 13.235,
            "tokens_per_second": 3.19,
            "first_token_latency_s": 0.2925,
            "inter_token_latency_ms": 298.68,
            "peak_memory_gb": 17.398,
            "model_load_time_s": 9.47,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 15.165,
            "tokens_per_second": 2.34,
            "first_token_latency_s": 0.4244,
            "inter_token_latency_ms": 427.98,
            "peak_memory_gb": 21.302,
            "model_load_time_s": 12.23,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 18.831,
            "tokens_per_second": 1.69,
            "first_token_latency_s": 0.5851,
            "inter_token_latency_ms": 592.98,
            "peak_memory_gb": 28.501,
            "model_load_time_s": 17.09,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8027,
                "first_token_latency_s": 0.0052,
                "tokens_per_second": 318.94,
                "memory_before_gb": 1.443,
                "memory_after_gb": 1.444,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.13,
                "p90_inter_token_latency_ms": 3.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8133,
                "first_token_latency_s": 0.0052,
                "tokens_per_second": 314.77,
                "memory_before_gb": 1.444,
                "memory_after_gb": 1.436,
                "memory_delta_gb": -0.008,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.17,
                "p90_inter_token_latency_ms": 3.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8099,
                "first_token_latency_s": 0.0053,
                "tokens_per_second": 316.09,
                "memory_before_gb": 1.436,
                "memory_after_gb": 1.429,
                "memory_delta_gb": -0.007,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.15,
                "p90_inter_token_latency_ms": 3.32
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 316.6,
              "std_tokens_per_second": 1.74,
              "avg_first_token_latency_s": 0.0052,
              "avg_inter_token_latency_ms": 3.15,
              "avg_total_time_s": 0.8086,
              "peak_memory_gb": 1.444,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.191866636276245,
              "cpu": {
                "avg_percent": 11.6,
                "max_percent": 15.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.4,
                "max_percent": 17.5,
                "peak_used_gb": 11.18
              },
              "gpu": {
                "avg_utilization_percent": 71.8,
                "max_utilization_percent": 75.0,
                "peak_memory_mb": 2077.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8078,
                "first_token_latency_s": 0.0061,
                "tokens_per_second": 316.9,
                "memory_before_gb": 1.429,
                "memory_after_gb": 1.425,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.14,
                "p90_inter_token_latency_ms": 3.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7995,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 320.21,
                "memory_before_gb": 1.425,
                "memory_after_gb": 1.421,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.12,
                "p90_inter_token_latency_ms": 3.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8041,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 318.35,
                "memory_before_gb": 1.421,
                "memory_after_gb": 1.419,
                "memory_delta_gb": -0.003,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.14,
                "p90_inter_token_latency_ms": 3.27
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 318.49,
              "std_tokens_per_second": 1.35,
              "avg_first_token_latency_s": 0.0049,
              "avg_inter_token_latency_ms": 3.13,
              "avg_total_time_s": 0.8038,
              "peak_memory_gb": 1.425,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1858158111572266,
              "cpu": {
                "avg_percent": 11.0,
                "max_percent": 14.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.3,
                "max_percent": 17.3,
                "peak_used_gb": 11.08
              },
              "gpu": {
                "avg_utilization_percent": 61.8,
                "max_utilization_percent": 75.0,
                "peak_memory_mb": 2077.0,
                "max_temperature_c": 49.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8238,
                "first_token_latency_s": 0.006,
                "tokens_per_second": 310.76,
                "memory_before_gb": 1.419,
                "memory_after_gb": 1.332,
                "memory_delta_gb": -0.087,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.21,
                "p90_inter_token_latency_ms": 3.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8013,
                "first_token_latency_s": 0.0045,
                "tokens_per_second": 319.48,
                "memory_before_gb": 1.332,
                "memory_after_gb": 1.319,
                "memory_delta_gb": -0.013,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.12,
                "p90_inter_token_latency_ms": 3.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8321,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 307.67,
                "memory_before_gb": 1.319,
                "memory_after_gb": 1.319,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.24,
                "p90_inter_token_latency_ms": 3.56
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 312.64,
              "std_tokens_per_second": 5.0,
              "avg_first_token_latency_s": 0.0053,
              "avg_inter_token_latency_ms": 3.19,
              "avg_total_time_s": 0.8191,
              "peak_memory_gb": 1.332,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.197518825531006,
              "cpu": {
                "avg_percent": 10.8,
                "max_percent": 16.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.2,
                "max_percent": 17.3,
                "peak_used_gb": 11.07
              },
              "gpu": {
                "avg_utilization_percent": 58.4,
                "max_utilization_percent": 75.0,
                "peak_memory_mb": 2077.0,
                "max_temperature_c": 51.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 316.6,
            "first_token_latency_s": 0.0052,
            "inter_token_latency_ms": 3.15,
            "peak_memory_gb": 1.444,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 318.49,
            "first_token_latency_s": 0.0049,
            "inter_token_latency_ms": 3.13,
            "peak_memory_gb": 1.425,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 312.64,
            "first_token_latency_s": 0.0053,
            "inter_token_latency_ms": 3.19,
            "peak_memory_gb": 1.332,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "temperature",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9855,
                "first_token_latency_s": 0.0142,
                "tokens_per_second": 85.75,
                "memory_before_gb": 4.671,
                "memory_after_gb": 4.671,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.65,
                "p90_inter_token_latency_ms": 12.05
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.006,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 85.16,
                "memory_before_gb": 4.671,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.73,
                "p90_inter_token_latency_ms": 12.08
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0093,
                "first_token_latency_s": 0.0132,
                "tokens_per_second": 85.07,
                "memory_before_gb": 4.672,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.75,
                "p90_inter_token_latency_ms": 12.13
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 85.33,
              "std_tokens_per_second": 0.3,
              "avg_first_token_latency_s": 0.0137,
              "avg_inter_token_latency_ms": 11.71,
              "avg_total_time_s": 3.0003,
              "peak_memory_gb": 4.672,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.776590824127197,
              "cpu": {
                "avg_percent": 12.6,
                "max_percent": 16.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.4,
                "max_percent": 22.5,
                "peak_used_gb": 14.36
              },
              "gpu": {
                "avg_utilization_percent": 90.1,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 5799.0,
                "max_temperature_c": 59.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9914,
                "first_token_latency_s": 0.0149,
                "tokens_per_second": 85.58,
                "memory_before_gb": 4.672,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.67,
                "p90_inter_token_latency_ms": 12.01
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0039,
                "first_token_latency_s": 0.0131,
                "tokens_per_second": 85.22,
                "memory_before_gb": 4.672,
                "memory_after_gb": 4.672,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.73,
                "p90_inter_token_latency_ms": 12.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0107,
                "first_token_latency_s": 0.0147,
                "tokens_per_second": 85.03,
                "memory_before_gb": 4.672,
                "memory_after_gb": 4.673,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.75,
                "p90_inter_token_latency_ms": 12.16
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 85.28,
              "std_tokens_per_second": 0.23,
              "avg_first_token_latency_s": 0.0142,
              "avg_inter_token_latency_ms": 11.72,
              "avg_total_time_s": 3.002,
              "peak_memory_gb": 4.673,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.7638521194458,
              "cpu": {
                "avg_percent": 12.4,
                "max_percent": 17.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.41
              },
              "gpu": {
                "avg_utilization_percent": 88.1,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 5801.0,
                "max_temperature_c": 60.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.009,
                "first_token_latency_s": 0.015,
                "tokens_per_second": 85.08,
                "memory_before_gb": 4.673,
                "memory_after_gb": 4.673,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.74,
                "p90_inter_token_latency_ms": 12.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0054,
                "first_token_latency_s": 0.0139,
                "tokens_per_second": 85.18,
                "memory_before_gb": 4.673,
                "memory_after_gb": 4.673,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.73,
                "p90_inter_token_latency_ms": 12.28
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9921,
                "first_token_latency_s": 0.0135,
                "tokens_per_second": 85.56,
                "memory_before_gb": 4.673,
                "memory_after_gb": 4.673,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.68,
                "p90_inter_token_latency_ms": 12.09
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 85.27,
              "std_tokens_per_second": 0.21,
              "avg_first_token_latency_s": 0.0141,
              "avg_inter_token_latency_ms": 11.72,
              "avg_total_time_s": 3.0022,
              "peak_memory_gb": 4.673,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.766640424728394,
              "cpu": {
                "avg_percent": 12.3,
                "max_percent": 18.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.4
              },
              "gpu": {
                "avg_utilization_percent": 84.9,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 5799.0,
                "max_temperature_c": 62.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 85.33,
            "first_token_latency_s": 0.0137,
            "inter_token_latency_ms": 11.71,
            "peak_memory_gb": 4.672,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 85.28,
            "first_token_latency_s": 0.0142,
            "inter_token_latency_ms": 11.72,
            "peak_memory_gb": 4.673,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 85.27,
            "first_token_latency_s": 0.0141,
            "inter_token_latency_ms": 11.72,
            "peak_memory_gb": 4.673,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "temperature",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1381,
                "first_token_latency_s": 0.0229,
                "tokens_per_second": 49.82,
                "memory_before_gb": 7.913,
                "memory_after_gb": 7.914,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.06,
                "p90_inter_token_latency_ms": 20.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1301,
                "first_token_latency_s": 0.0217,
                "tokens_per_second": 49.9,
                "memory_before_gb": 7.914,
                "memory_after_gb": 7.914,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.03,
                "p90_inter_token_latency_ms": 20.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1266,
                "first_token_latency_s": 0.0235,
                "tokens_per_second": 49.94,
                "memory_before_gb": 7.914,
                "memory_after_gb": 7.914,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.01,
                "p90_inter_token_latency_ms": 20.6
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.89,
              "std_tokens_per_second": 0.05,
              "avg_first_token_latency_s": 0.0227,
              "avg_inter_token_latency_ms": 20.03,
              "avg_total_time_s": 5.1316,
              "peak_memory_gb": 7.914,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.362820148468018,
              "cpu": {
                "avg_percent": 12.3,
                "max_percent": 19.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.7,
                "peak_used_gb": 17.71
              },
              "gpu": {
                "avg_utilization_percent": 91.9,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 63.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1392,
                "first_token_latency_s": 0.0236,
                "tokens_per_second": 49.81,
                "memory_before_gb": 7.914,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.06,
                "p90_inter_token_latency_ms": 20.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1332,
                "first_token_latency_s": 0.0219,
                "tokens_per_second": 49.87,
                "memory_before_gb": 7.915,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.04,
                "p90_inter_token_latency_ms": 20.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1579,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 49.63,
                "memory_before_gb": 7.915,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.14,
                "p90_inter_token_latency_ms": 20.81
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.77,
              "std_tokens_per_second": 0.1,
              "avg_first_token_latency_s": 0.0228,
              "avg_inter_token_latency_ms": 20.08,
              "avg_total_time_s": 5.1434,
              "peak_memory_gb": 7.915,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.363048315048218,
              "cpu": {
                "avg_percent": 13.1,
                "max_percent": 19.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.7,
                "peak_used_gb": 17.68
              },
              "gpu": {
                "avg_utilization_percent": 89.6,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1369,
                "first_token_latency_s": 0.024,
                "tokens_per_second": 49.84,
                "memory_before_gb": 7.915,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.05,
                "p90_inter_token_latency_ms": 20.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1633,
                "first_token_latency_s": 0.0231,
                "tokens_per_second": 49.58,
                "memory_before_gb": 7.915,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.16,
                "p90_inter_token_latency_ms": 20.93
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1345,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 49.86,
                "memory_before_gb": 7.915,
                "memory_after_gb": 7.915,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.04,
                "p90_inter_token_latency_ms": 20.68
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.76,
              "std_tokens_per_second": 0.13,
              "avg_first_token_latency_s": 0.0233,
              "avg_inter_token_latency_ms": 20.08,
              "avg_total_time_s": 5.1449,
              "peak_memory_gb": 7.915,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.357780933380127,
              "cpu": {
                "avg_percent": 12.5,
                "max_percent": 17.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.7,
                "peak_used_gb": 17.74
              },
              "gpu": {
                "avg_utilization_percent": 89.4,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 66.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 49.89,
            "first_token_latency_s": 0.0227,
            "inter_token_latency_ms": 20.03,
            "peak_memory_gb": 7.914,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 49.77,
            "first_token_latency_s": 0.0228,
            "inter_token_latency_ms": 20.08,
            "peak_memory_gb": 7.915,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 49.76,
            "first_token_latency_s": 0.0233,
            "inter_token_latency_ms": 20.08,
            "peak_memory_gb": 7.915,
            "stability": "stable"
          }
        ]
      },
      "codellama-34b": {
        "axis": "temperature",
        "model_name": "CodeLlama 34B",
        "model_key": "codellama-34b",
        "params": "34B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 179.1856,
                "first_token_latency_s": 0.6071,
                "tokens_per_second": 1.43,
                "memory_before_gb": 28.499,
                "memory_after_gb": 28.559,
                "memory_delta_gb": 0.06,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 700.31,
                "p90_inter_token_latency_ms": 720.27
              },
              {
                "tokens_generated": 256,
                "total_time_s": 180.779,
                "first_token_latency_s": 0.7008,
                "tokens_per_second": 1.42,
                "memory_before_gb": 28.559,
                "memory_after_gb": 28.559,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 706.19,
                "p90_inter_token_latency_ms": 725.06
              },
              {
                "tokens_generated": 256,
                "total_time_s": 180.1993,
                "first_token_latency_s": 0.6967,
                "tokens_per_second": 1.42,
                "memory_before_gb": 28.559,
                "memory_after_gb": 28.559,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 703.93,
                "p90_inter_token_latency_ms": 719.3
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.42,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.6682,
              "avg_inter_token_latency_ms": 703.48,
              "avg_total_time_s": 180.0546,
              "peak_memory_gb": 28.559,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 981,
              "duration_s": 539.946790933609,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 28.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 61.3,
                "max_percent": 61.7,
                "peak_used_gb": 39.46
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11868.0,
                "max_temperature_c": 51.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 180.2097,
                "first_token_latency_s": 0.6943,
                "tokens_per_second": 1.42,
                "memory_before_gb": 28.559,
                "memory_after_gb": 28.258,
                "memory_delta_gb": -0.301,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 703.98,
                "p90_inter_token_latency_ms": 718.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 180.3108,
                "first_token_latency_s": 0.6881,
                "tokens_per_second": 1.42,
                "memory_before_gb": 28.258,
                "memory_after_gb": 28.258,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 704.4,
                "p90_inter_token_latency_ms": 719.05
              },
              {
                "tokens_generated": 256,
                "total_time_s": 154.0737,
                "first_token_latency_s": 0.6961,
                "tokens_per_second": 1.66,
                "memory_before_gb": 28.258,
                "memory_after_gb": 28.258,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 601.48,
                "p90_inter_token_latency_ms": 607.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.5,
              "std_tokens_per_second": 0.11,
              "avg_first_token_latency_s": 0.6928,
              "avg_inter_token_latency_ms": 669.95,
              "avg_total_time_s": 171.5314,
              "peak_memory_gb": 28.258,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 935,
              "duration_s": 514.3451964855194,
              "cpu": {
                "avg_percent": 7.6,
                "max_percent": 19.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 60.5,
                "max_percent": 60.6,
                "peak_used_gb": 38.76
              },
              "gpu": {
                "avg_utilization_percent": 99.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11795.0,
                "max_temperature_c": 46.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 151.8673,
                "first_token_latency_s": 0.5872,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.258,
                "memory_after_gb": 28.258,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 593.25,
                "p90_inter_token_latency_ms": 603.53
              },
              {
                "tokens_generated": 256,
                "total_time_s": 151.8746,
                "first_token_latency_s": 0.5856,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.258,
                "memory_after_gb": 28.259,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 593.29,
                "p90_inter_token_latency_ms": 604.02
              },
              {
                "tokens_generated": 256,
                "total_time_s": 151.7747,
                "first_token_latency_s": 0.5869,
                "tokens_per_second": 1.69,
                "memory_before_gb": 28.259,
                "memory_after_gb": 28.259,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 592.89,
                "p90_inter_token_latency_ms": 602.49
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.69,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.5866,
              "avg_inter_token_latency_ms": 593.14,
              "avg_total_time_s": 151.8389,
              "peak_memory_gb": 28.259,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 828,
              "duration_s": 455.08493208885193,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.9,
                "max_percent": 60.0,
                "peak_used_gb": 38.37
              },
              "gpu": {
                "avg_utilization_percent": 99.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11807.0,
                "max_temperature_c": 46.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 1.42,
            "first_token_latency_s": 0.6682,
            "inter_token_latency_ms": 703.48,
            "peak_memory_gb": 28.559,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 1.5,
            "first_token_latency_s": 0.6928,
            "inter_token_latency_ms": 669.95,
            "peak_memory_gb": 28.258,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 1.69,
            "first_token_latency_s": 0.5866,
            "inter_token_latency_ms": 593.14,
            "peak_memory_gb": 28.259,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8039,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 318.43,
                "memory_before_gb": 1.388,
                "memory_after_gb": 1.201,
                "memory_delta_gb": -0.187,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.13,
                "p90_inter_token_latency_ms": 3.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8024,
                "first_token_latency_s": 0.0045,
                "tokens_per_second": 319.06,
                "memory_before_gb": 1.201,
                "memory_after_gb": 1.196,
                "memory_delta_gb": -0.005,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.13,
                "p90_inter_token_latency_ms": 3.28
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8087,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 316.57,
                "memory_before_gb": 1.196,
                "memory_after_gb": 1.191,
                "memory_delta_gb": -0.006,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.15,
                "p90_inter_token_latency_ms": 3.34
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 318.02,
              "std_tokens_per_second": 1.06,
              "avg_first_token_latency_s": 0.0047,
              "avg_inter_token_latency_ms": 3.14,
              "avg_total_time_s": 0.805,
              "peak_memory_gb": 1.201,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.1958155632019043,
              "cpu": {
                "avg_percent": 9.3,
                "max_percent": 17.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.5,
                "max_percent": 17.7,
                "peak_used_gb": 11.31
              },
              "gpu": {
                "avg_utilization_percent": 75.4,
                "max_utilization_percent": 88.0,
                "peak_memory_mb": 2087.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8131,
                "first_token_latency_s": 0.0117,
                "tokens_per_second": 314.86,
                "memory_before_gb": 1.191,
                "memory_after_gb": 1.187,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.14,
                "p90_inter_token_latency_ms": 3.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.805,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 318.0,
                "memory_before_gb": 1.187,
                "memory_after_gb": 1.184,
                "memory_delta_gb": -0.003,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.14,
                "p90_inter_token_latency_ms": 3.37
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7969,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 321.26,
                "memory_before_gb": 1.184,
                "memory_after_gb": 1.181,
                "memory_delta_gb": -0.002,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.11,
                "p90_inter_token_latency_ms": 3.27
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 318.04,
              "std_tokens_per_second": 2.61,
              "avg_first_token_latency_s": 0.0068,
              "avg_inter_token_latency_ms": 3.13,
              "avg_total_time_s": 0.805,
              "peak_memory_gb": 1.187,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2324814796447754,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.4,
                "max_percent": 17.4,
                "peak_used_gb": 11.1
              },
              "gpu": {
                "avg_utilization_percent": 59.0,
                "max_utilization_percent": 76.0,
                "peak_memory_mb": 2087.0,
                "max_temperature_c": 50.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.849,
                "first_token_latency_s": 0.026,
                "tokens_per_second": 301.53,
                "memory_before_gb": 1.181,
                "memory_after_gb": 1.122,
                "memory_delta_gb": -0.059,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.23,
                "p90_inter_token_latency_ms": 3.42
              },
              {
                "tokens_generated": 202,
                "total_time_s": 0.8109,
                "first_token_latency_s": 0.0041,
                "tokens_per_second": 249.09,
                "memory_before_gb": 1.122,
                "memory_after_gb": 1.111,
                "memory_delta_gb": -0.011,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 4.01,
                "p90_inter_token_latency_ms": 8.85
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8205,
                "first_token_latency_s": 0.0051,
                "tokens_per_second": 311.99,
                "memory_before_gb": 1.111,
                "memory_after_gb": 1.101,
                "memory_delta_gb": -0.01,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.2,
                "p90_inter_token_latency_ms": 3.66
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 287.54,
              "std_tokens_per_second": 27.52,
              "avg_first_token_latency_s": 0.0117,
              "avg_inter_token_latency_ms": 3.48,
              "avg_total_time_s": 0.8268,
              "peak_memory_gb": 1.122,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.243001937866211,
              "cpu": {
                "avg_percent": 9.7,
                "max_percent": 11.5,
                "min_percent": 7.9
              },
              "ram": {
                "avg_percent": 17.3,
                "max_percent": 17.3,
                "peak_used_gb": 11.09
              },
              "gpu": {
                "avg_utilization_percent": 66.6,
                "max_utilization_percent": 74.0,
                "peak_memory_mb": 2089.0,
                "max_temperature_c": 50.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.825,
                "first_token_latency_s": 0.0231,
                "tokens_per_second": 310.3,
                "memory_before_gb": 1.101,
                "memory_after_gb": 1.067,
                "memory_delta_gb": -0.035,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.14,
                "p90_inter_token_latency_ms": 3.34
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.797,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 321.19,
                "memory_before_gb": 1.067,
                "memory_after_gb": 1.067,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.11,
                "p90_inter_token_latency_ms": 3.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7944,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 322.26,
                "memory_before_gb": 1.067,
                "memory_after_gb": 1.056,
                "memory_delta_gb": -0.01,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.1,
                "p90_inter_token_latency_ms": 3.26
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 317.92,
              "std_tokens_per_second": 5.4,
              "avg_first_token_latency_s": 0.0106,
              "avg_inter_token_latency_ms": 3.12,
              "avg_total_time_s": 0.8055,
              "peak_memory_gb": 1.067,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.233260154724121,
              "cpu": {
                "avg_percent": 7.6,
                "max_percent": 12.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.2,
                "max_percent": 17.2,
                "peak_used_gb": 11.02
              },
              "gpu": {
                "avg_utilization_percent": 59.4,
                "max_utilization_percent": 76.0,
                "peak_memory_mb": 2089.0,
                "max_temperature_c": 51.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8102,
                "first_token_latency_s": 0.0115,
                "tokens_per_second": 315.98,
                "memory_before_gb": 1.046,
                "memory_after_gb": 1.046,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.13,
                "p90_inter_token_latency_ms": 3.43
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8079,
                "first_token_latency_s": 0.0046,
                "tokens_per_second": 316.88,
                "memory_before_gb": 1.046,
                "memory_after_gb": 1.037,
                "memory_delta_gb": -0.009,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.15,
                "p90_inter_token_latency_ms": 3.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8032,
                "first_token_latency_s": 0.0044,
                "tokens_per_second": 318.71,
                "memory_before_gb": 1.037,
                "memory_after_gb": 1.027,
                "memory_delta_gb": -0.01,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.13,
                "p90_inter_token_latency_ms": 3.3
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 317.19,
              "std_tokens_per_second": 1.14,
              "avg_first_token_latency_s": 0.0068,
              "avg_inter_token_latency_ms": 3.14,
              "avg_total_time_s": 0.8071,
              "peak_memory_gb": 1.046,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.229539394378662,
              "cpu": {
                "avg_percent": 7.6,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.1,
                "max_percent": 17.2,
                "peak_used_gb": 10.97
              },
              "gpu": {
                "avg_utilization_percent": 68.8,
                "max_utilization_percent": 74.0,
                "peak_memory_mb": 2089.0,
                "max_temperature_c": 52.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8267,
                "first_token_latency_s": 0.0136,
                "tokens_per_second": 309.68,
                "memory_before_gb": 1.027,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.19,
                "p90_inter_token_latency_ms": 3.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8117,
                "first_token_latency_s": 0.0043,
                "tokens_per_second": 315.37,
                "memory_before_gb": 1.028,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.17,
                "p90_inter_token_latency_ms": 3.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8154,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 313.97,
                "memory_before_gb": 1.028,
                "memory_after_gb": 1.028,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.18,
                "p90_inter_token_latency_ms": 3.42
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 313.01,
              "std_tokens_per_second": 2.42,
              "avg_first_token_latency_s": 0.0078,
              "avg_inter_token_latency_ms": 3.18,
              "avg_total_time_s": 0.8179,
              "peak_memory_gb": 1.028,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.260096549987793,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 17.1,
                "max_percent": 17.1,
                "peak_used_gb": 10.96
              },
              "gpu": {
                "avg_utilization_percent": 59.6,
                "max_utilization_percent": 76.0,
                "peak_memory_mb": 2091.0,
                "max_temperature_c": 53.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 318.02,
            "first_token_latency_s": 0.0047,
            "inter_token_latency_ms": 3.14,
            "peak_memory_gb": 1.201,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 318.04,
            "first_token_latency_s": 0.0068,
            "inter_token_latency_ms": 3.13,
            "peak_memory_gb": 1.187,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 287.54,
            "first_token_latency_s": 0.0117,
            "inter_token_latency_ms": 3.48,
            "peak_memory_gb": 1.122,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 317.92,
            "first_token_latency_s": 0.0106,
            "inter_token_latency_ms": 3.12,
            "peak_memory_gb": 1.067,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 317.19,
            "first_token_latency_s": 0.0068,
            "inter_token_latency_ms": 3.14,
            "peak_memory_gb": 1.046,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 313.01,
            "first_token_latency_s": 0.0078,
            "inter_token_latency_ms": 3.18,
            "peak_memory_gb": 1.028,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "language",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9524,
                "first_token_latency_s": 0.0145,
                "tokens_per_second": 86.71,
                "memory_before_gb": 4.431,
                "memory_after_gb": 4.432,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.52,
                "p90_inter_token_latency_ms": 11.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9535,
                "first_token_latency_s": 0.0129,
                "tokens_per_second": 86.68,
                "memory_before_gb": 4.432,
                "memory_after_gb": 4.432,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.53,
                "p90_inter_token_latency_ms": 11.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.954,
                "first_token_latency_s": 0.0133,
                "tokens_per_second": 86.66,
                "memory_before_gb": 4.432,
                "memory_after_gb": 4.432,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.53,
                "p90_inter_token_latency_ms": 11.98
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 86.68,
              "std_tokens_per_second": 0.02,
              "avg_first_token_latency_s": 0.0136,
              "avg_inter_token_latency_ms": 11.53,
              "avg_total_time_s": 2.9533,
              "peak_memory_gb": 4.432,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.782695770263672,
              "cpu": {
                "avg_percent": 7.1,
                "max_percent": 9.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.39
              },
              "gpu": {
                "avg_utilization_percent": 91.7,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5803.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9761,
                "first_token_latency_s": 0.0242,
                "tokens_per_second": 86.02,
                "memory_before_gb": 4.432,
                "memory_after_gb": 4.433,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.58,
                "p90_inter_token_latency_ms": 11.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9643,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 86.36,
                "memory_before_gb": 4.433,
                "memory_after_gb": 4.433,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.57,
                "p90_inter_token_latency_ms": 11.98
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9771,
                "first_token_latency_s": 0.0145,
                "tokens_per_second": 85.99,
                "memory_before_gb": 4.433,
                "memory_after_gb": 4.434,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.62,
                "p90_inter_token_latency_ms": 11.94
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 86.12,
              "std_tokens_per_second": 0.17,
              "avg_first_token_latency_s": 0.0172,
              "avg_inter_token_latency_ms": 11.59,
              "avg_total_time_s": 2.9725,
              "peak_memory_gb": 4.434,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.797419548034668,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.39
              },
              "gpu": {
                "avg_utilization_percent": 85.9,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 5805.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 254,
                "total_time_s": 2.9794,
                "first_token_latency_s": 0.0238,
                "tokens_per_second": 85.25,
                "memory_before_gb": 4.434,
                "memory_after_gb": 4.434,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.68,
                "p90_inter_token_latency_ms": 11.9
              },
              {
                "tokens_generated": 250,
                "total_time_s": 2.965,
                "first_token_latency_s": 0.0132,
                "tokens_per_second": 84.32,
                "memory_before_gb": 4.434,
                "memory_after_gb": 4.435,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.85,
                "p90_inter_token_latency_ms": 11.83
              },
              {
                "tokens_generated": 242,
                "total_time_s": 2.9665,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 81.58,
                "memory_before_gb": 4.435,
                "memory_after_gb": 4.435,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.25,
                "p90_inter_token_latency_ms": 11.91
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 83.72,
              "std_tokens_per_second": 1.56,
              "avg_first_token_latency_s": 0.0167,
              "avg_inter_token_latency_ms": 11.93,
              "avg_total_time_s": 2.9703,
              "peak_memory_gb": 4.435,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.821584939956665,
              "cpu": {
                "avg_percent": 7.2,
                "max_percent": 12.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.4
              },
              "gpu": {
                "avg_utilization_percent": 85.1,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5805.0,
                "max_temperature_c": 63.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9758,
                "first_token_latency_s": 0.0243,
                "tokens_per_second": 86.03,
                "memory_before_gb": 4.435,
                "memory_after_gb": 4.436,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.57,
                "p90_inter_token_latency_ms": 11.95
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9623,
                "first_token_latency_s": 0.0132,
                "tokens_per_second": 86.42,
                "memory_before_gb": 4.436,
                "memory_after_gb": 4.436,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.56,
                "p90_inter_token_latency_ms": 11.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9686,
                "first_token_latency_s": 0.0131,
                "tokens_per_second": 86.24,
                "memory_before_gb": 4.436,
                "memory_after_gb": 4.436,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.59,
                "p90_inter_token_latency_ms": 11.9
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 86.23,
              "std_tokens_per_second": 0.16,
              "avg_first_token_latency_s": 0.0169,
              "avg_inter_token_latency_ms": 11.57,
              "avg_total_time_s": 2.9689,
              "peak_memory_gb": 4.436,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.835667371749878,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 11.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.37
              },
              "gpu": {
                "avg_utilization_percent": 85.7,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5805.0,
                "max_temperature_c": 64.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.9876,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 85.69,
                "memory_before_gb": 4.436,
                "memory_after_gb": 4.437,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.62,
                "p90_inter_token_latency_ms": 12.01
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9659,
                "first_token_latency_s": 0.0131,
                "tokens_per_second": 86.31,
                "memory_before_gb": 4.437,
                "memory_after_gb": 4.437,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.58,
                "p90_inter_token_latency_ms": 11.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9617,
                "first_token_latency_s": 0.0139,
                "tokens_per_second": 86.44,
                "memory_before_gb": 4.437,
                "memory_after_gb": 4.437,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.56,
                "p90_inter_token_latency_ms": 11.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 86.15,
              "std_tokens_per_second": 0.33,
              "avg_first_token_latency_s": 0.0172,
              "avg_inter_token_latency_ms": 11.59,
              "avg_total_time_s": 2.9717,
              "peak_memory_gb": 4.437,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.835994958877563,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.37
              },
              "gpu": {
                "avg_utilization_percent": 85.5,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5805.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.0031,
                "first_token_latency_s": 0.0321,
                "tokens_per_second": 85.24,
                "memory_before_gb": 4.437,
                "memory_after_gb": 4.438,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.65,
                "p90_inter_token_latency_ms": 11.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9824,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 85.84,
                "memory_before_gb": 4.438,
                "memory_after_gb": 4.438,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.64,
                "p90_inter_token_latency_ms": 12.0
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.9819,
                "first_token_latency_s": 0.0131,
                "tokens_per_second": 85.85,
                "memory_before_gb": 4.438,
                "memory_after_gb": 4.438,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.64,
                "p90_inter_token_latency_ms": 11.94
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 85.64,
              "std_tokens_per_second": 0.29,
              "avg_first_token_latency_s": 0.0194,
              "avg_inter_token_latency_ms": 11.64,
              "avg_total_time_s": 2.9891,
              "peak_memory_gb": 4.438,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.786365509033203,
              "cpu": {
                "avg_percent": 7.2,
                "max_percent": 10.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.5,
                "max_percent": 22.5,
                "peak_used_gb": 14.4
              },
              "gpu": {
                "avg_utilization_percent": 85.9,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5807.0,
                "max_temperature_c": 66.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 86.68,
            "first_token_latency_s": 0.0136,
            "inter_token_latency_ms": 11.53,
            "peak_memory_gb": 4.432,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 86.12,
            "first_token_latency_s": 0.0172,
            "inter_token_latency_ms": 11.59,
            "peak_memory_gb": 4.434,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 83.72,
            "first_token_latency_s": 0.0167,
            "inter_token_latency_ms": 11.93,
            "peak_memory_gb": 4.435,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 86.23,
            "first_token_latency_s": 0.0169,
            "inter_token_latency_ms": 11.57,
            "peak_memory_gb": 4.436,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 86.15,
            "first_token_latency_s": 0.0172,
            "inter_token_latency_ms": 11.59,
            "peak_memory_gb": 4.437,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 85.64,
            "first_token_latency_s": 0.0194,
            "inter_token_latency_ms": 11.64,
            "peak_memory_gb": 4.438,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "language",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 6.263,
                "first_token_latency_s": 0.0232,
                "tokens_per_second": 40.88,
                "memory_before_gb": 7.674,
                "memory_after_gb": 7.675,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 24.47,
                "p90_inter_token_latency_ms": 22.06
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.8556,
                "first_token_latency_s": 0.0243,
                "tokens_per_second": 43.72,
                "memory_before_gb": 7.675,
                "memory_after_gb": 7.676,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 22.87,
                "p90_inter_token_latency_ms": 22.07
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.2829,
                "first_token_latency_s": 0.0224,
                "tokens_per_second": 48.46,
                "memory_before_gb": 7.676,
                "memory_after_gb": 7.676,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.63,
                "p90_inter_token_latency_ms": 21.22
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 44.35,
              "std_tokens_per_second": 3.13,
              "avg_first_token_latency_s": 0.0233,
              "avg_inter_token_latency_ms": 22.66,
              "avg_total_time_s": 5.8005,
              "peak_memory_gb": 7.676,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 31,
              "duration_s": 17.400712251663208,
              "cpu": {
                "avg_percent": 16.9,
                "max_percent": 28.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.8,
                "max_percent": 27.9,
                "peak_used_gb": 17.86
              },
              "gpu": {
                "avg_utilization_percent": 90.1,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 11040.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3075,
                "first_token_latency_s": 0.0362,
                "tokens_per_second": 48.23,
                "memory_before_gb": 7.676,
                "memory_after_gb": 7.677,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.67,
                "p90_inter_token_latency_ms": 21.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1632,
                "first_token_latency_s": 0.0229,
                "tokens_per_second": 49.58,
                "memory_before_gb": 7.677,
                "memory_after_gb": 7.678,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.16,
                "p90_inter_token_latency_ms": 20.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.242,
                "first_token_latency_s": 0.0219,
                "tokens_per_second": 48.84,
                "memory_before_gb": 7.678,
                "memory_after_gb": 7.678,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.47,
                "p90_inter_token_latency_ms": 21.59
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.88,
              "std_tokens_per_second": 0.55,
              "avg_first_token_latency_s": 0.027,
              "avg_inter_token_latency_ms": 20.43,
              "avg_total_time_s": 5.2376,
              "peak_memory_gb": 7.678,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.356332302093506,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 15.1,
                "min_percent": 6.6
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.72
              },
              "gpu": {
                "avg_utilization_percent": 90.3,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10975.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3752,
                "first_token_latency_s": 0.043,
                "tokens_per_second": 47.63,
                "memory_before_gb": 7.678,
                "memory_after_gb": 7.678,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.91,
                "p90_inter_token_latency_ms": 21.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3698,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 47.67,
                "memory_before_gb": 7.678,
                "memory_after_gb": 7.679,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.97,
                "p90_inter_token_latency_ms": 21.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3437,
                "first_token_latency_s": 0.0232,
                "tokens_per_second": 47.91,
                "memory_before_gb": 7.679,
                "memory_after_gb": 7.679,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.86,
                "p90_inter_token_latency_ms": 21.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.74,
              "std_tokens_per_second": 0.12,
              "avg_first_token_latency_s": 0.0297,
              "avg_inter_token_latency_ms": 20.91,
              "avg_total_time_s": 5.3629,
              "peak_memory_gb": 7.679,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.92836046218872,
              "cpu": {
                "avg_percent": 8.9,
                "max_percent": 15.9,
                "min_percent": 6.7
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.71
              },
              "gpu": {
                "avg_utilization_percent": 90.2,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10966.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3449,
                "first_token_latency_s": 0.0387,
                "tokens_per_second": 47.9,
                "memory_before_gb": 7.679,
                "memory_after_gb": 7.679,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.81,
                "p90_inter_token_latency_ms": 21.45
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3336,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 48.0,
                "memory_before_gb": 7.679,
                "memory_after_gb": 7.68,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.83,
                "p90_inter_token_latency_ms": 21.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3298,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 48.03,
                "memory_before_gb": 7.68,
                "memory_after_gb": 7.68,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.81,
                "p90_inter_token_latency_ms": 21.35
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.98,
              "std_tokens_per_second": 0.06,
              "avg_first_token_latency_s": 0.028,
              "avg_inter_token_latency_ms": 20.82,
              "avg_total_time_s": 5.3361,
              "peak_memory_gb": 7.68,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.467979431152344,
              "cpu": {
                "avg_percent": 8.6,
                "max_percent": 12.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.72
              },
              "gpu": {
                "avg_utilization_percent": 89.8,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 10903.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3484,
                "first_token_latency_s": 0.0394,
                "tokens_per_second": 47.86,
                "memory_before_gb": 7.68,
                "memory_after_gb": 7.68,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.82,
                "p90_inter_token_latency_ms": 21.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3285,
                "first_token_latency_s": 0.0229,
                "tokens_per_second": 48.04,
                "memory_before_gb": 7.68,
                "memory_after_gb": 7.681,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.81,
                "p90_inter_token_latency_ms": 21.34
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.334,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 47.99,
                "memory_before_gb": 7.681,
                "memory_after_gb": 7.681,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.83,
                "p90_inter_token_latency_ms": 21.37
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.96,
              "std_tokens_per_second": 0.08,
              "avg_first_token_latency_s": 0.0283,
              "avg_inter_token_latency_ms": 20.82,
              "avg_total_time_s": 5.337,
              "peak_memory_gb": 7.681,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.970436811447144,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.72
              },
              "gpu": {
                "avg_utilization_percent": 92.4,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 10903.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3956,
                "first_token_latency_s": 0.052,
                "tokens_per_second": 47.45,
                "memory_before_gb": 7.681,
                "memory_after_gb": 7.682,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.95,
                "p90_inter_token_latency_ms": 21.44
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3659,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 47.71,
                "memory_before_gb": 7.682,
                "memory_after_gb": 7.682,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.95,
                "p90_inter_token_latency_ms": 21.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3735,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 47.64,
                "memory_before_gb": 7.682,
                "memory_after_gb": 7.682,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.98,
                "p90_inter_token_latency_ms": 21.54
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.6,
              "std_tokens_per_second": 0.11,
              "avg_first_token_latency_s": 0.0324,
              "avg_inter_token_latency_ms": 20.96,
              "avg_total_time_s": 5.3783,
              "peak_memory_gb": 7.682,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.902210474014282,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 10.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.7
              },
              "gpu": {
                "avg_utilization_percent": 90.4,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10905.0,
                "max_temperature_c": 69.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 44.35,
            "first_token_latency_s": 0.0233,
            "inter_token_latency_ms": 22.66,
            "peak_memory_gb": 7.676,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 48.88,
            "first_token_latency_s": 0.027,
            "inter_token_latency_ms": 20.43,
            "peak_memory_gb": 7.678,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 47.74,
            "first_token_latency_s": 0.0297,
            "inter_token_latency_ms": 20.91,
            "peak_memory_gb": 7.679,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 47.98,
            "first_token_latency_s": 0.028,
            "inter_token_latency_ms": 20.82,
            "peak_memory_gb": 7.68,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 47.96,
            "first_token_latency_s": 0.0283,
            "inter_token_latency_ms": 20.82,
            "peak_memory_gb": 7.681,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 47.6,
            "first_token_latency_s": 0.0324,
            "inter_token_latency_ms": 20.96,
            "peak_memory_gb": 7.682,
            "stability": "stable"
          }
        ]
      },
      "codellama-34b": {
        "axis": "language",
        "model_name": "CodeLlama 34B",
        "model_key": "codellama-34b",
        "params": "34B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 158.8954,
                "first_token_latency_s": 0.6104,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.385,
                "memory_after_gb": 28.328,
                "memory_delta_gb": -0.057,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 620.72,
                "p90_inter_token_latency_ms": 631.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.6524,
                "first_token_latency_s": 0.6102,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.328,
                "memory_after_gb": 28.328,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 619.77,
                "p90_inter_token_latency_ms": 630.27
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.6663,
                "first_token_latency_s": 0.6088,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.328,
                "memory_after_gb": 28.327,
                "memory_delta_gb": -0.002,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 619.83,
                "p90_inter_token_latency_ms": 630.48
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.61,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.6098,
              "avg_inter_token_latency_ms": 620.11,
              "avg_total_time_s": 158.738,
              "peak_memory_gb": 28.328,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 867,
              "duration_s": 476.2146911621094,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 16.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 60.4,
                "max_percent": 60.6,
                "peak_used_gb": 38.77
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11791.0,
                "max_temperature_c": 54.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 159.2427,
                "first_token_latency_s": 0.8334,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.327,
                "memory_after_gb": 28.328,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 621.21,
                "p90_inter_token_latency_ms": 631.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.0454,
                "first_token_latency_s": 0.6121,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.328,
                "memory_after_gb": 28.328,
                "memory_delta_gb": -0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 621.31,
                "p90_inter_token_latency_ms": 631.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.057,
                "first_token_latency_s": 0.6138,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.328,
                "memory_after_gb": 28.328,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 621.34,
                "p90_inter_token_latency_ms": 631.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.61,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.6864,
              "avg_inter_token_latency_ms": 621.29,
              "avg_total_time_s": 159.115,
              "peak_memory_gb": 28.328,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 869,
              "duration_s": 477.20143151283264,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 17.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.9,
                "max_percent": 60.2,
                "peak_used_gb": 38.5
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11713.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 157.3538,
                "first_token_latency_s": 1.0044,
                "tokens_per_second": 1.63,
                "memory_before_gb": 28.328,
                "memory_after_gb": 28.329,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 613.13,
                "p90_inter_token_latency_ms": 620.02
              },
              {
                "tokens_generated": 256,
                "total_time_s": 154.2476,
                "first_token_latency_s": 0.5913,
                "tokens_per_second": 1.66,
                "memory_before_gb": 28.329,
                "memory_after_gb": 28.329,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 602.57,
                "p90_inter_token_latency_ms": 612.96
              },
              {
                "tokens_generated": 256,
                "total_time_s": 154.2277,
                "first_token_latency_s": 0.5916,
                "tokens_per_second": 1.66,
                "memory_before_gb": 28.329,
                "memory_after_gb": 28.329,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 602.49,
                "p90_inter_token_latency_ms": 612.91
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.65,
              "std_tokens_per_second": 0.01,
              "avg_first_token_latency_s": 0.7291,
              "avg_inter_token_latency_ms": 606.06,
              "avg_total_time_s": 155.2764,
              "peak_memory_gb": 28.329,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 848,
              "duration_s": 465.477472782135,
              "cpu": {
                "avg_percent": 7.0,
                "max_percent": 21.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.6,
                "max_percent": 59.6,
                "peak_used_gb": 38.12
              },
              "gpu": {
                "avg_utilization_percent": 99.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11713.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 154.0238,
                "first_token_latency_s": 0.8531,
                "tokens_per_second": 1.66,
                "memory_before_gb": 28.329,
                "memory_after_gb": 28.33,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 600.67,
                "p90_inter_token_latency_ms": 610.14
              },
              {
                "tokens_generated": 256,
                "total_time_s": 153.7732,
                "first_token_latency_s": 0.5919,
                "tokens_per_second": 1.66,
                "memory_before_gb": 28.33,
                "memory_after_gb": 28.331,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 600.71,
                "p90_inter_token_latency_ms": 610.15
              },
              {
                "tokens_generated": 256,
                "total_time_s": 157.9785,
                "first_token_latency_s": 0.5943,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.331,
                "memory_after_gb": 28.331,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 617.19,
                "p90_inter_token_latency_ms": 637.23
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.65,
              "std_tokens_per_second": 0.02,
              "avg_first_token_latency_s": 0.6798,
              "avg_inter_token_latency_ms": 606.19,
              "avg_total_time_s": 155.2585,
              "peak_memory_gb": 28.331,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 846,
              "duration_s": 465.61708903312683,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 37.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.7,
                "max_percent": 60.5,
                "peak_used_gb": 38.7
              },
              "gpu": {
                "avg_utilization_percent": 99.3,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11817.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 159.8747,
                "first_token_latency_s": 0.9122,
                "tokens_per_second": 1.6,
                "memory_before_gb": 28.331,
                "memory_after_gb": 28.332,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 623.38,
                "p90_inter_token_latency_ms": 634.05
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.2862,
                "first_token_latency_s": 0.6119,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.332,
                "memory_after_gb": 28.332,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 622.25,
                "p90_inter_token_latency_ms": 632.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.3035,
                "first_token_latency_s": 0.614,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.332,
                "memory_after_gb": 28.332,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 622.31,
                "p90_inter_token_latency_ms": 632.33
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.61,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.7127,
              "avg_inter_token_latency_ms": 622.65,
              "avg_total_time_s": 159.4881,
              "peak_memory_gb": 28.332,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 870,
              "duration_s": 477.9810724258423,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 16.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.9,
                "max_percent": 60.4,
                "peak_used_gb": 38.61
              },
              "gpu": {
                "avg_utilization_percent": 99.3,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11693.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 161.3385,
                "first_token_latency_s": 1.2374,
                "tokens_per_second": 1.59,
                "memory_before_gb": 28.332,
                "memory_after_gb": 28.332,
                "memory_delta_gb": -0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 627.85,
                "p90_inter_token_latency_ms": 638.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 160.7513,
                "first_token_latency_s": 0.6215,
                "tokens_per_second": 1.59,
                "memory_before_gb": 28.332,
                "memory_after_gb": 28.332,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 627.96,
                "p90_inter_token_latency_ms": 638.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 160.8137,
                "first_token_latency_s": 0.616,
                "tokens_per_second": 1.59,
                "memory_before_gb": 28.332,
                "memory_after_gb": 28.332,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 628.23,
                "p90_inter_token_latency_ms": 638.34
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.59,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.825,
              "avg_inter_token_latency_ms": 628.01,
              "avg_total_time_s": 160.9678,
              "peak_memory_gb": 28.332,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 878,
              "duration_s": 482.53810572624207,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 29.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.4,
                "max_percent": 59.8,
                "peak_used_gb": 38.23
              },
              "gpu": {
                "avg_utilization_percent": 99.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11659.0,
                "max_temperature_c": 47.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 1.61,
            "first_token_latency_s": 0.6098,
            "inter_token_latency_ms": 620.11,
            "peak_memory_gb": 28.328,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 1.61,
            "first_token_latency_s": 0.6864,
            "inter_token_latency_ms": 621.29,
            "peak_memory_gb": 28.328,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 1.65,
            "first_token_latency_s": 0.7291,
            "inter_token_latency_ms": 606.06,
            "peak_memory_gb": 28.329,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 1.65,
            "first_token_latency_s": 0.6798,
            "inter_token_latency_ms": 606.19,
            "peak_memory_gb": 28.331,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 1.61,
            "first_token_latency_s": 0.7127,
            "inter_token_latency_ms": 622.65,
            "peak_memory_gb": 28.332,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 1.59,
            "first_token_latency_s": 0.825,
            "inter_token_latency_ms": 628.01,
            "peak_memory_gb": 28.332,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8268,
                "first_token_latency_s": 0.0056,
                "tokens_per_second": 309.62,
                "memory_before_gb": 1.206,
                "memory_after_gb": 1.074,
                "memory_delta_gb": -0.132,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.22,
                "p90_inter_token_latency_ms": 3.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8302,
                "first_token_latency_s": 0.0047,
                "tokens_per_second": 308.37,
                "memory_before_gb": 1.074,
                "memory_after_gb": 1.067,
                "memory_delta_gb": -0.006,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.23,
                "p90_inter_token_latency_ms": 3.56
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8322,
                "first_token_latency_s": 0.0057,
                "tokens_per_second": 307.6,
                "memory_before_gb": 1.067,
                "memory_after_gb": 1.068,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.24,
                "p90_inter_token_latency_ms": 3.56
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 308.53,
              "std_tokens_per_second": 0.83,
              "avg_first_token_latency_s": 0.0053,
              "avg_inter_token_latency_ms": 3.23,
              "avg_total_time_s": 0.8297,
              "peak_memory_gb": 1.074,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.206843376159668,
              "cpu": {
                "avg_percent": 9.0,
                "max_percent": 11.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 16.6,
                "max_percent": 16.8,
                "peak_used_gb": 10.73
              },
              "gpu": {
                "avg_utilization_percent": 61.4,
                "max_utilization_percent": 74.0,
                "peak_memory_mb": 2078.0,
                "max_temperature_c": 49.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8456,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 302.74,
                "memory_before_gb": 1.062,
                "memory_after_gb": 1.04,
                "memory_delta_gb": -0.023,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.26,
                "p90_inter_token_latency_ms": 3.72
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8333,
                "first_token_latency_s": 0.0049,
                "tokens_per_second": 307.22,
                "memory_before_gb": 1.04,
                "memory_after_gb": 1.04,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.25,
                "p90_inter_token_latency_ms": 3.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8374,
                "first_token_latency_s": 0.005,
                "tokens_per_second": 305.73,
                "memory_before_gb": 1.04,
                "memory_after_gb": 1.036,
                "memory_delta_gb": -0.004,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.26,
                "p90_inter_token_latency_ms": 3.58
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 305.23,
              "std_tokens_per_second": 1.86,
              "avg_first_token_latency_s": 0.0079,
              "avg_inter_token_latency_ms": 3.26,
              "avg_total_time_s": 0.8388,
              "peak_memory_gb": 1.04,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.252471685409546,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 11.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 16.6,
                "max_percent": 16.6,
                "peak_used_gb": 10.59
              },
              "gpu": {
                "avg_utilization_percent": 59.0,
                "max_utilization_percent": 76.0,
                "peak_memory_mb": 2080.0,
                "max_temperature_c": 50.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8551,
                "first_token_latency_s": 0.0261,
                "tokens_per_second": 299.38,
                "memory_before_gb": 1.033,
                "memory_after_gb": 1.034,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.25,
                "p90_inter_token_latency_ms": 3.55
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8392,
                "first_token_latency_s": 0.0048,
                "tokens_per_second": 305.07,
                "memory_before_gb": 1.034,
                "memory_after_gb": 1.032,
                "memory_delta_gb": -0.002,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.27,
                "p90_inter_token_latency_ms": 3.54
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8351,
                "first_token_latency_s": 0.0045,
                "tokens_per_second": 306.55,
                "memory_before_gb": 1.032,
                "memory_after_gb": 1.031,
                "memory_delta_gb": -0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.26,
                "p90_inter_token_latency_ms": 3.54
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 303.67,
              "std_tokens_per_second": 3.09,
              "avg_first_token_latency_s": 0.0118,
              "avg_inter_token_latency_ms": 3.26,
              "avg_total_time_s": 0.8431,
              "peak_memory_gb": 1.034,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.231980562210083,
              "cpu": {
                "avg_percent": 9.1,
                "max_percent": 14.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 16.6,
                "max_percent": 16.6,
                "peak_used_gb": 10.6
              },
              "gpu": {
                "avg_utilization_percent": 72.4,
                "max_utilization_percent": 74.0,
                "peak_memory_mb": 2080.0,
                "max_temperature_c": 51.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8408,
                "first_token_latency_s": 0.013,
                "tokens_per_second": 304.48,
                "memory_before_gb": 1.031,
                "memory_after_gb": 1.019,
                "memory_delta_gb": -0.012,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.25,
                "p90_inter_token_latency_ms": 3.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8318,
                "first_token_latency_s": 0.0044,
                "tokens_per_second": 307.75,
                "memory_before_gb": 1.019,
                "memory_after_gb": 1.019,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.24,
                "p90_inter_token_latency_ms": 3.55
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8203,
                "first_token_latency_s": 0.0045,
                "tokens_per_second": 312.09,
                "memory_before_gb": 1.019,
                "memory_after_gb": 1.019,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.2,
                "p90_inter_token_latency_ms": 3.49
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 308.11,
              "std_tokens_per_second": 3.12,
              "avg_first_token_latency_s": 0.0073,
              "avg_inter_token_latency_ms": 3.23,
              "avg_total_time_s": 0.831,
              "peak_memory_gb": 1.019,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2424135208129883,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 11.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 16.6,
                "max_percent": 16.6,
                "peak_used_gb": 10.59
              },
              "gpu": {
                "avg_utilization_percent": 70.4,
                "max_utilization_percent": 72.0,
                "peak_memory_mb": 2079.0,
                "max_temperature_c": 52.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.8466,
                "first_token_latency_s": 0.0136,
                "tokens_per_second": 302.37,
                "memory_before_gb": 1.019,
                "memory_after_gb": 1.019,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.27,
                "p90_inter_token_latency_ms": 3.57
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8328,
                "first_token_latency_s": 0.0044,
                "tokens_per_second": 307.39,
                "memory_before_gb": 1.019,
                "memory_after_gb": 1.019,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.25,
                "p90_inter_token_latency_ms": 3.61
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8496,
                "first_token_latency_s": 0.0062,
                "tokens_per_second": 301.3,
                "memory_before_gb": 1.019,
                "memory_after_gb": 1.02,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 3.31,
                "p90_inter_token_latency_ms": 3.69
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 303.69,
              "std_tokens_per_second": 2.65,
              "avg_first_token_latency_s": 0.0081,
              "avg_inter_token_latency_ms": 3.28,
              "avg_total_time_s": 0.843,
              "peak_memory_gb": 1.02,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2471213340759277,
              "cpu": {
                "avg_percent": 9.4,
                "max_percent": 14.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 16.6,
                "max_percent": 16.6,
                "peak_used_gb": 10.59
              },
              "gpu": {
                "avg_utilization_percent": 59.0,
                "max_utilization_percent": 78.0,
                "peak_memory_mb": 2079.0,
                "max_temperature_c": 53.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 308.53,
            "first_token_latency_s": 0.0053,
            "inter_token_latency_ms": 3.23,
            "peak_memory_gb": 1.074,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 305.23,
            "first_token_latency_s": 0.0079,
            "inter_token_latency_ms": 3.26,
            "peak_memory_gb": 1.04,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 303.67,
            "first_token_latency_s": 0.0118,
            "inter_token_latency_ms": 3.26,
            "peak_memory_gb": 1.034,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 308.11,
            "first_token_latency_s": 0.0073,
            "inter_token_latency_ms": 3.23,
            "peak_memory_gb": 1.019,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 303.69,
            "first_token_latency_s": 0.0081,
            "inter_token_latency_ms": 3.28,
            "peak_memory_gb": 1.02,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "prompt_type",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.0878,
                "first_token_latency_s": 0.0154,
                "tokens_per_second": 82.91,
                "memory_before_gb": 4.373,
                "memory_after_gb": 4.373,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.05,
                "p90_inter_token_latency_ms": 12.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1001,
                "first_token_latency_s": 0.0142,
                "tokens_per_second": 82.58,
                "memory_before_gb": 4.373,
                "memory_after_gb": 4.374,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.1,
                "p90_inter_token_latency_ms": 12.49
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1005,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 82.57,
                "memory_before_gb": 4.374,
                "memory_after_gb": 4.374,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.1,
                "p90_inter_token_latency_ms": 12.55
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.69,
              "std_tokens_per_second": 0.16,
              "avg_first_token_latency_s": 0.0144,
              "avg_inter_token_latency_ms": 12.08,
              "avg_total_time_s": 3.0961,
              "peak_memory_gb": 4.374,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.793630361557007,
              "cpu": {
                "avg_percent": 8.7,
                "max_percent": 13.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.8,
                "max_percent": 21.8,
                "peak_used_gb": 13.96
              },
              "gpu": {
                "avg_utilization_percent": 91.0,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 5799.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1063,
                "first_token_latency_s": 0.0264,
                "tokens_per_second": 82.41,
                "memory_before_gb": 4.374,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.08,
                "p90_inter_token_latency_ms": 12.44
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1001,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 82.58,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.1,
                "p90_inter_token_latency_ms": 12.56
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.0901,
                "first_token_latency_s": 0.0136,
                "tokens_per_second": 82.84,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.06,
                "p90_inter_token_latency_ms": 12.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.61,
              "std_tokens_per_second": 0.18,
              "avg_first_token_latency_s": 0.0179,
              "avg_inter_token_latency_ms": 12.08,
              "avg_total_time_s": 3.0988,
              "peak_memory_gb": 4.375,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.818086385726929,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 11.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.8,
                "max_percent": 21.8,
                "peak_used_gb": 13.95
              },
              "gpu": {
                "avg_utilization_percent": 91.2,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5801.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 183,
                "total_time_s": 2.2318,
                "first_token_latency_s": 0.0291,
                "tokens_per_second": 81.99,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.04,
                "p90_inter_token_latency_ms": 12.44
              },
              {
                "tokens_generated": 174,
                "total_time_s": 2.0983,
                "first_token_latency_s": 0.0139,
                "tokens_per_second": 82.92,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 11.98,
                "p90_inter_token_latency_ms": 12.38
              },
              {
                "tokens_generated": 186,
                "total_time_s": 2.2553,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 82.47,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.375,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.05,
                "p90_inter_token_latency_ms": 12.46
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.46,
              "std_tokens_per_second": 0.38,
              "avg_first_token_latency_s": 0.0189,
              "avg_inter_token_latency_ms": 12.02,
              "avg_total_time_s": 2.1951,
              "peak_memory_gb": 4.375,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 12,
              "duration_s": 6.102420806884766,
              "cpu": {
                "avg_percent": 9.1,
                "max_percent": 12.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.8,
                "max_percent": 21.8,
                "peak_used_gb": 13.93
              },
              "gpu": {
                "avg_utilization_percent": 91.3,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5801.0,
                "max_temperature_c": 63.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1127,
                "first_token_latency_s": 0.023,
                "tokens_per_second": 82.24,
                "memory_before_gb": 4.375,
                "memory_after_gb": 4.376,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.12,
                "p90_inter_token_latency_ms": 12.62
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1021,
                "first_token_latency_s": 0.0136,
                "tokens_per_second": 82.52,
                "memory_before_gb": 4.376,
                "memory_after_gb": 4.377,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.11,
                "p90_inter_token_latency_ms": 12.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.095,
                "first_token_latency_s": 0.0135,
                "tokens_per_second": 82.72,
                "memory_before_gb": 4.377,
                "memory_after_gb": 4.377,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.08,
                "p90_inter_token_latency_ms": 12.49
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.49,
              "std_tokens_per_second": 0.2,
              "avg_first_token_latency_s": 0.0167,
              "avg_inter_token_latency_ms": 12.1,
              "avg_total_time_s": 3.1033,
              "peak_memory_gb": 4.377,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.872095584869385,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.8,
                "max_percent": 21.8,
                "peak_used_gb": 13.94
              },
              "gpu": {
                "avg_utilization_percent": 90.8,
                "max_utilization_percent": 92.0,
                "peak_memory_mb": 5801.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.1244,
                "first_token_latency_s": 0.0312,
                "tokens_per_second": 81.94,
                "memory_before_gb": 4.377,
                "memory_after_gb": 4.377,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.13,
                "p90_inter_token_latency_ms": 12.56
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1098,
                "first_token_latency_s": 0.0141,
                "tokens_per_second": 82.32,
                "memory_before_gb": 4.377,
                "memory_after_gb": 4.377,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.14,
                "p90_inter_token_latency_ms": 12.57
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.1118,
                "first_token_latency_s": 0.0142,
                "tokens_per_second": 82.27,
                "memory_before_gb": 4.377,
                "memory_after_gb": 4.377,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 12.15,
                "p90_inter_token_latency_ms": 12.6
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 82.18,
              "std_tokens_per_second": 0.17,
              "avg_first_token_latency_s": 0.0198,
              "avg_inter_token_latency_ms": 12.14,
              "avg_total_time_s": 3.1153,
              "peak_memory_gb": 4.377,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 17,
              "duration_s": 8.818876266479492,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 21.8,
                "max_percent": 21.8,
                "peak_used_gb": 13.96
              },
              "gpu": {
                "avg_utilization_percent": 91.0,
                "max_utilization_percent": 93.0,
                "peak_memory_mb": 5801.0,
                "max_temperature_c": 65.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 82.69,
            "first_token_latency_s": 0.0144,
            "inter_token_latency_ms": 12.08,
            "peak_memory_gb": 4.374,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 82.61,
            "first_token_latency_s": 0.0179,
            "inter_token_latency_ms": 12.08,
            "peak_memory_gb": 4.375,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 82.46,
            "first_token_latency_s": 0.0189,
            "inter_token_latency_ms": 12.02,
            "peak_memory_gb": 4.375,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 82.49,
            "first_token_latency_s": 0.0167,
            "inter_token_latency_ms": 12.1,
            "peak_memory_gb": 4.377,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 82.18,
            "first_token_latency_s": 0.0198,
            "inter_token_latency_ms": 12.14,
            "peak_memory_gb": 4.377,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "prompt_type",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3133,
                "first_token_latency_s": 0.024,
                "tokens_per_second": 48.18,
                "memory_before_gb": 7.615,
                "memory_after_gb": 7.616,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.74,
                "p90_inter_token_latency_ms": 21.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3106,
                "first_token_latency_s": 0.0224,
                "tokens_per_second": 48.21,
                "memory_before_gb": 7.616,
                "memory_after_gb": 7.617,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.74,
                "p90_inter_token_latency_ms": 21.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3125,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 48.19,
                "memory_before_gb": 7.617,
                "memory_after_gb": 7.617,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.74,
                "p90_inter_token_latency_ms": 21.26
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.19,
              "std_tokens_per_second": 0.01,
              "avg_first_token_latency_s": 0.023,
              "avg_inter_token_latency_ms": 20.74,
              "avg_total_time_s": 5.3121,
              "peak_memory_gb": 7.617,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.904522895812988,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 26.9,
                "max_percent": 27.0,
                "peak_used_gb": 17.23
              },
              "gpu": {
                "avg_utilization_percent": 92.7,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 66.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3438,
                "first_token_latency_s": 0.0385,
                "tokens_per_second": 47.91,
                "memory_before_gb": 7.617,
                "memory_after_gb": 7.617,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.8,
                "p90_inter_token_latency_ms": 21.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.348,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 47.87,
                "memory_before_gb": 7.617,
                "memory_after_gb": 7.618,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.88,
                "p90_inter_token_latency_ms": 21.4
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3342,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 47.99,
                "memory_before_gb": 7.618,
                "memory_after_gb": 7.618,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.83,
                "p90_inter_token_latency_ms": 21.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.92,
              "std_tokens_per_second": 0.05,
              "avg_first_token_latency_s": 0.028,
              "avg_inter_token_latency_ms": 20.84,
              "avg_total_time_s": 5.342,
              "peak_memory_gb": 7.618,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.897581100463867,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 13.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.0,
                "max_percent": 27.0,
                "peak_used_gb": 17.25
              },
              "gpu": {
                "avg_utilization_percent": 90.0,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.373,
                "first_token_latency_s": 0.0473,
                "tokens_per_second": 47.65,
                "memory_before_gb": 7.618,
                "memory_after_gb": 7.618,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.88,
                "p90_inter_token_latency_ms": 21.41
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3359,
                "first_token_latency_s": 0.0231,
                "tokens_per_second": 47.98,
                "memory_before_gb": 7.618,
                "memory_after_gb": 7.618,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.83,
                "p90_inter_token_latency_ms": 21.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3519,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 47.83,
                "memory_before_gb": 7.618,
                "memory_after_gb": 7.618,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.9,
                "p90_inter_token_latency_ms": 21.55
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.82,
              "std_tokens_per_second": 0.13,
              "avg_first_token_latency_s": 0.031,
              "avg_inter_token_latency_ms": 20.87,
              "avg_total_time_s": 5.3536,
              "peak_memory_gb": 7.618,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.868726015090942,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.0,
                "max_percent": 27.0,
                "peak_used_gb": 17.24
              },
              "gpu": {
                "avg_utilization_percent": 89.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.337,
                "first_token_latency_s": 0.0356,
                "tokens_per_second": 47.97,
                "memory_before_gb": 7.618,
                "memory_after_gb": 7.619,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.79,
                "p90_inter_token_latency_ms": 21.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3286,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 48.04,
                "memory_before_gb": 7.619,
                "memory_after_gb": 7.619,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.81,
                "p90_inter_token_latency_ms": 21.24
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3316,
                "first_token_latency_s": 0.023,
                "tokens_per_second": 48.02,
                "memory_before_gb": 7.619,
                "memory_after_gb": 7.62,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.82,
                "p90_inter_token_latency_ms": 21.39
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.01,
              "std_tokens_per_second": 0.03,
              "avg_first_token_latency_s": 0.027,
              "avg_inter_token_latency_ms": 20.81,
              "avg_total_time_s": 5.3324,
              "peak_memory_gb": 7.62,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.920466899871826,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.0,
                "max_percent": 27.0,
                "peak_used_gb": 17.26
              },
              "gpu": {
                "avg_utilization_percent": 89.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.3745,
                "first_token_latency_s": 0.0472,
                "tokens_per_second": 47.63,
                "memory_before_gb": 7.62,
                "memory_after_gb": 7.62,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.89,
                "p90_inter_token_latency_ms": 21.44
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3548,
                "first_token_latency_s": 0.023,
                "tokens_per_second": 47.81,
                "memory_before_gb": 7.62,
                "memory_after_gb": 7.62,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.91,
                "p90_inter_token_latency_ms": 21.42
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.3574,
                "first_token_latency_s": 0.0234,
                "tokens_per_second": 47.78,
                "memory_before_gb": 7.62,
                "memory_after_gb": 7.62,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 20.92,
                "p90_inter_token_latency_ms": 21.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 47.74,
              "std_tokens_per_second": 0.08,
              "avg_first_token_latency_s": 0.0312,
              "avg_inter_token_latency_ms": 20.91,
              "avg_total_time_s": 5.3622,
              "peak_memory_gb": 7.62,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 30,
              "duration_s": 15.96733832359314,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 12.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.0,
                "max_percent": 27.0,
                "peak_used_gb": 17.27
              },
              "gpu": {
                "avg_utilization_percent": 89.9,
                "max_utilization_percent": 94.0,
                "peak_memory_mb": 10503.0,
                "max_temperature_c": 69.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 48.19,
            "first_token_latency_s": 0.023,
            "inter_token_latency_ms": 20.74,
            "peak_memory_gb": 7.617,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 47.92,
            "first_token_latency_s": 0.028,
            "inter_token_latency_ms": 20.84,
            "peak_memory_gb": 7.618,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 47.82,
            "first_token_latency_s": 0.031,
            "inter_token_latency_ms": 20.87,
            "peak_memory_gb": 7.618,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 48.01,
            "first_token_latency_s": 0.027,
            "inter_token_latency_ms": 20.81,
            "peak_memory_gb": 7.62,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 47.74,
            "first_token_latency_s": 0.0312,
            "inter_token_latency_ms": 20.91,
            "peak_memory_gb": 7.62,
            "stability": "stable"
          }
        ]
      },
      "codellama-34b": {
        "axis": "prompt_type",
        "model_name": "CodeLlama 34B",
        "model_key": "codellama-34b",
        "params": "34B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 157.8786,
                "first_token_latency_s": 0.6131,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.264,
                "memory_after_gb": 28.265,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 616.73,
                "p90_inter_token_latency_ms": 627.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 157.8768,
                "first_token_latency_s": 0.6068,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.265,
                "memory_after_gb": 28.265,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 616.74,
                "p90_inter_token_latency_ms": 627.94
              },
              {
                "tokens_generated": 256,
                "total_time_s": 157.9271,
                "first_token_latency_s": 0.6103,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.265,
                "memory_after_gb": 28.266,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 616.93,
                "p90_inter_token_latency_ms": 627.7
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.62,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.6101,
              "avg_inter_token_latency_ms": 616.8,
              "avg_total_time_s": 157.8942,
              "peak_memory_gb": 28.266,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 859,
              "duration_s": 473.31892013549805,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 29.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.5,
                "max_percent": 59.8,
                "peak_used_gb": 38.21
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11698.0,
                "max_temperature_c": 53.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 158.7514,
                "first_token_latency_s": 0.8923,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.266,
                "memory_after_gb": 28.266,
                "memory_delta_gb": -0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 619.05,
                "p90_inter_token_latency_ms": 629.18
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.4484,
                "first_token_latency_s": 0.6128,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.266,
                "memory_after_gb": 28.266,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 618.96,
                "p90_inter_token_latency_ms": 629.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.4335,
                "first_token_latency_s": 0.612,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.266,
                "memory_after_gb": 28.266,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 618.91,
                "p90_inter_token_latency_ms": 628.97
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.62,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.7057,
              "avg_inter_token_latency_ms": 618.97,
              "avg_total_time_s": 158.5444,
              "peak_memory_gb": 28.266,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 864,
              "duration_s": 475.4301347732544,
              "cpu": {
                "avg_percent": 7.7,
                "max_percent": 16.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.7,
                "max_percent": 59.8,
                "peak_used_gb": 38.2
              },
              "gpu": {
                "avg_utilization_percent": 99.7,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11709.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 159.5379,
                "first_token_latency_s": 1.0561,
                "tokens_per_second": 1.6,
                "memory_before_gb": 28.266,
                "memory_after_gb": 28.266,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 621.5,
                "p90_inter_token_latency_ms": 632.24
              },
              {
                "tokens_generated": 236,
                "total_time_s": 147.0517,
                "first_token_latency_s": 0.6088,
                "tokens_per_second": 1.6,
                "memory_before_gb": 28.266,
                "memory_after_gb": 28.267,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 620.47,
                "p90_inter_token_latency_ms": 629.75
              },
              {
                "tokens_generated": 247,
                "total_time_s": 153.9959,
                "first_token_latency_s": 0.6128,
                "tokens_per_second": 1.6,
                "memory_before_gb": 28.267,
                "memory_after_gb": 28.267,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 620.93,
                "p90_inter_token_latency_ms": 631.26
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.6,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.7592,
              "avg_inter_token_latency_ms": 620.97,
              "avg_total_time_s": 153.5285,
              "peak_memory_gb": 28.267,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 836,
              "duration_s": 460.52775502204895,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 15.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.7,
                "max_percent": 59.8,
                "peak_used_gb": 38.2
              },
              "gpu": {
                "avg_utilization_percent": 99.6,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11719.0,
                "max_temperature_c": 47.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 158.4071,
                "first_token_latency_s": 0.8315,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.267,
                "memory_after_gb": 28.268,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 617.94,
                "p90_inter_token_latency_ms": 628.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.2967,
                "first_token_latency_s": 0.6091,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.268,
                "memory_after_gb": 28.268,
                "memory_delta_gb": 0.001,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 618.38,
                "p90_inter_token_latency_ms": 628.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 158.2885,
                "first_token_latency_s": 0.6146,
                "tokens_per_second": 1.62,
                "memory_before_gb": 28.268,
                "memory_after_gb": 28.269,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 618.33,
                "p90_inter_token_latency_ms": 628.62
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.62,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.6851,
              "avg_inter_token_latency_ms": 618.22,
              "avg_total_time_s": 158.3308,
              "peak_memory_gb": 28.269,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 862,
              "duration_s": 474.58315682411194,
              "cpu": {
                "avg_percent": 7.9,
                "max_percent": 20.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.4,
                "max_percent": 59.7,
                "peak_used_gb": 38.19
              },
              "gpu": {
                "avg_utilization_percent": 99.5,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11730.0,
                "max_temperature_c": 48.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 159.9867,
                "first_token_latency_s": 1.089,
                "tokens_per_second": 1.6,
                "memory_before_gb": 28.269,
                "memory_after_gb": 28.269,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 623.13,
                "p90_inter_token_latency_ms": 632.14
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.232,
                "first_token_latency_s": 0.6133,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.269,
                "memory_after_gb": 28.269,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 622.03,
                "p90_inter_token_latency_ms": 632.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 159.2421,
                "first_token_latency_s": 0.6155,
                "tokens_per_second": 1.61,
                "memory_before_gb": 28.269,
                "memory_after_gb": 28.269,
                "memory_delta_gb": 0.0,
                "error": null,
                "success": true,
                "avg_inter_token_latency_ms": 622.06,
                "p90_inter_token_latency_ms": 632.46
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 1.61,
              "std_tokens_per_second": 0.0,
              "avg_first_token_latency_s": 0.7726,
              "avg_inter_token_latency_ms": 622.41,
              "avg_total_time_s": 159.4869,
              "peak_memory_gb": 28.269,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 869,
              "duration_s": 478.0960385799408,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 16.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 59.5,
                "max_percent": 59.6,
                "peak_used_gb": 38.09
              },
              "gpu": {
                "avg_utilization_percent": 99.7,
                "max_utilization_percent": 100.0,
                "peak_memory_mb": 11702.0,
                "max_temperature_c": 47.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 1.62,
            "first_token_latency_s": 0.6101,
            "inter_token_latency_ms": 616.8,
            "peak_memory_gb": 28.266,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 1.62,
            "first_token_latency_s": 0.7057,
            "inter_token_latency_ms": 618.97,
            "peak_memory_gb": 28.266,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 1.6,
            "first_token_latency_s": 0.7592,
            "inter_token_latency_ms": 620.97,
            "peak_memory_gb": 28.267,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 1.62,
            "first_token_latency_s": 0.6851,
            "inter_token_latency_ms": 618.22,
            "peak_memory_gb": 28.269,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 1.61,
            "first_token_latency_s": 0.7726,
            "inter_token_latency_ms": 622.41,
            "peak_memory_gb": 28.269,
            "stability": "stable"
          }
        ]
      }
    }
  }
}