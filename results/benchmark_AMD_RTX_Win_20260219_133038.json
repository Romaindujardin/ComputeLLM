{
  "id": "20260219_133038",
  "timestamp": "2026-02-19T13:30:38.030944",
  "version": "1.0.0",
  "hardware": {
    "os": {
      "system": "Windows",
      "release": "10",
      "version": "10.0.26200",
      "machine": "AMD64",
      "architecture": "64bit",
      "platform": "Windows-10-10.0.26200-SP0",
      "python_version": "3.11.9"
    },
    "cpu": {
      "physical_cores": 12,
      "logical_cores": 24,
      "architecture": "AMD64",
      "detection_error": "[WinError 2] Le fichier spécifié est introuvable",
      "model": "AMD64 Family 25 Model 33 Stepping 2, AuthenticAMD",
      "is_apple_silicon": false,
      "architecture_type": "AMD64",
      "frequency_mhz": {
        "current": 3701.0,
        "min": null,
        "max": 3701.0
      }
    },
    "gpu": {
      "gpus": [
        {
          "type": "NVIDIA",
          "name": "NVIDIA GeForce RTX 4070",
          "vram_total_mb": 12282.0,
          "vram_free_mb": 10011.0,
          "driver_version": "591.74",
          "compute_capability": "8.9",
          "backend": "cuda",
          "device_index": 0,
          "gpu_index": 0
        }
      ],
      "backends": [
        "cuda",
        "cpu"
      ],
      "primary_backend": "cuda",
      "python_backends": {
        "pytorch": true,
        "pytorch_version": "2.5.1+cu121",
        "pytorch_cuda": true,
        "pytorch_cuda_version": "12.1",
        "pytorch_mps": false,
        "pytorch_xpu": false,
        "llama_cpp": true,
        "llama_cpp_version": "0.3.4",
        "llama_server": false,
        "pytorch_rocm": false,
        "ipex": false,
        "directml": false
      }
    },
    "ram": {
      "total_gb": 63.93,
      "available_gb": 49.04,
      "used_gb": 14.89,
      "percent_used": 23.3,
      "swap_total_gb": 4.0,
      "swap_used_gb": 0.0,
      "unified_memory": false
    },
    "selected_gpu": {
      "gpu_index": 0,
      "name": "NVIDIA GeForce RTX 4070",
      "backend": "cuda"
    }
  },
  "classic_benchmarks": {
    "type": "classic_benchmarks",
    "total_time_s": 10.01,
    "benchmarks": {
      "cpu_single_thread": {
        "test": "CPU Single-Thread",
        "method": "Matrix multiplication (NumPy, 1 thread, subprocess isolé)",
        "results": {
          "512x512": {
            "times_s": [
              0.0022,
              0.0022,
              0.0022
            ],
            "mean_s": 0.0022,
            "median_s": 0.0022,
            "std_s": 0.0,
            "gflops": 122.45
          },
          "1024x1024": {
            "times_s": [
              0.0163,
              0.0166,
              0.0165
            ],
            "mean_s": 0.0164,
            "median_s": 0.0165,
            "std_s": 0.0001,
            "gflops": 130.3
          },
          "2048x2048": {
            "times_s": [
              0.1287,
              0.1262,
              0.1268
            ],
            "mean_s": 0.1273,
            "median_s": 0.1268,
            "std_s": 0.0011,
            "gflops": 135.46
          }
        }
      },
      "cpu_multi_thread": {
        "test": "CPU Multi-Thread",
        "method": "Matrix multiplication (NumPy, 24 threads, subprocess isolé)",
        "n_threads": 24,
        "results": {
          "512x512": {
            "times_s": [
              0.0009,
              0.0011,
              0.001
            ],
            "mean_s": 0.001,
            "median_s": 0.001,
            "std_s": 0.0001,
            "gflops": 275.97
          },
          "1024x1024": {
            "times_s": [
              0.0041,
              0.0039,
              0.0052
            ],
            "mean_s": 0.0044,
            "median_s": 0.0041,
            "std_s": 0.0006,
            "gflops": 529.85
          },
          "2048x2048": {
            "times_s": [
              0.0237,
              0.0222,
              0.0253
            ],
            "mean_s": 0.0238,
            "median_s": 0.0237,
            "std_s": 0.0013,
            "gflops": 724.44
          }
        }
      },
      "memory_bandwidth": {
        "test": "Memory Bandwidth",
        "method": "NumPy array operations (256 Mo)",
        "data_size_gb": 0.25,
        "results": {
          "write": {
            "mean_s": 0.0402,
            "median_s": 0.0406,
            "bandwidth_gb_s": 6.16
          },
          "read": {
            "mean_s": 0.0361,
            "median_s": 0.0327,
            "bandwidth_gb_s": 7.66
          },
          "copy": {
            "mean_s": 0.0454,
            "median_s": 0.0467,
            "bandwidth_gb_s": 5.35
          }
        }
      },
      "gpu_compute": {
        "test": "GPU Compute (Raw)",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 4070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "times_s": [
              0.0013,
              0.0086,
              0.0067
            ],
            "mean_s": 0.0055,
            "median_s": 0.0067,
            "gflops": 318.34
          },
          "2048x2048": {
            "times_s": [
              0.0655,
              0.0522,
              0.0011
            ],
            "mean_s": 0.0396,
            "median_s": 0.0522,
            "gflops": 329.12
          },
          "4096x4096": {
            "times_s": [
              0.0074,
              0.0066,
              0.0076
            ],
            "mean_s": 0.0072,
            "median_s": 0.0074,
            "gflops": 18682.66
          }
        }
      },
      "gpu_system": {
        "test": "GPU System Score",
        "status": "completed",
        "device": "NVIDIA GeForce RTX 4070",
        "backend": "CUDA",
        "gpu_index": 0,
        "results": {
          "1024x1024": {
            "pipeline_times_s": [
              0.0014,
              0.0014,
              0.0015
            ],
            "pipeline_median_s": 0.0014,
            "transfer_to_median_s": 0.0008,
            "compute_median_s": 0.0003,
            "transfer_back_median_s": 0.0004,
            "gflops_pipeline": 1503.73,
            "gflops_compute": 8134.41,
            "transfer_bandwidth_gb_s": 9.99,
            "data_transferred_gb": 0.0117,
            "pct_transfer_to": 54.0,
            "pct_compute": 18.5,
            "pct_transfer_back": 28.1
          },
          "2048x2048": {
            "pipeline_times_s": [
              0.0064,
              0.0065,
              0.0059
            ],
            "pipeline_median_s": 0.0064,
            "transfer_to_median_s": 0.0034,
            "compute_median_s": 0.0011,
            "transfer_back_median_s": 0.0017,
            "gflops_pipeline": 2669.42,
            "gflops_compute": 15632.27,
            "transfer_bandwidth_gb_s": 9.18,
            "data_transferred_gb": 0.0469,
            "pct_transfer_to": 52.5,
            "pct_compute": 17.1,
            "pct_transfer_back": 26.8
          },
          "4096x4096": {
            "pipeline_times_s": [
              0.0287,
              0.0381,
              0.0382
            ],
            "pipeline_median_s": 0.0381,
            "transfer_to_median_s": 0.0121,
            "compute_median_s": 0.0157,
            "transfer_back_median_s": 0.0095,
            "gflops_pipeline": 3609.91,
            "gflops_compute": 8736.04,
            "transfer_bandwidth_gb_s": 8.68,
            "data_transferred_gb": 0.1875,
            "pct_transfer_to": 31.7,
            "pct_compute": 41.3,
            "pct_transfer_back": 25.1
          }
        }
      }
    },
    "resource_usage": {
      "n_samples": 18,
      "duration_s": 9.44801926612854,
      "cpu": {
        "avg_percent": 10.2,
        "max_percent": 20.6,
        "min_percent": 0.0
      },
      "ram": {
        "avg_percent": 23.1,
        "max_percent": 24.0,
        "peak_used_gb": 15.33
      },
      "gpu": {
        "avg_utilization_percent": 14.3,
        "max_utilization_percent": 58.0,
        "peak_memory_mb": 2146.0,
        "max_temperature_c": 39.0
      }
    }
  },
  "ai_benchmarks": {
    "type": "ai_benchmarks",
    "inference_mode": "server",
    "prompt": "Explain the concept of artificial intelligence in simple terms. What are its main applications and how does it impact our daily lives? Provide specific examples.",
    "inference_config": {
      "max_tokens": 256,
      "temperature": 0.7,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "n_ctx": 2048,
      "seed": 42,
      "n_warmup_runs": 2,
      "n_benchmark_runs": 3
    },
    "total_time_s": 1522.35,
    "models_tested": 3,
    "results": {
      "tinyllama-1.1b": {
        "model": "TinyLlama 1.1B",
        "params": "1.1B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 0.6694,
            "first_token_latency_s": 0.0054,
            "tokens_per_second": 382.44,
            "memory_before_gb": 1.788,
            "memory_after_gb": 1.789,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 0.932,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.6,
            "p90_inter_token_latency_ms": 3.03
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.6465,
            "first_token_latency_s": 0.0088,
            "tokens_per_second": 396.0,
            "memory_before_gb": 1.789,
            "memory_after_gb": 1.795,
            "memory_delta_gb": 0.007,
            "server_memory_gb": 0.939,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.5,
            "p90_inter_token_latency_ms": 2.77
          },
          {
            "tokens_generated": 256,
            "total_time_s": 0.6571,
            "first_token_latency_s": 0.0071,
            "tokens_per_second": 389.58,
            "memory_before_gb": 1.795,
            "memory_after_gb": 1.795,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 0.939,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 2.55,
            "p90_inter_token_latency_ms": 2.8
          }
        ],
        "model_load_time_s": 1.56,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 4,
          "duration_s": 1.6902647018432617,
          "cpu": {
            "avg_percent": 12.4,
            "max_percent": 20.8,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 23.3,
            "max_percent": 23.3,
            "peak_used_gb": 14.91
          },
          "gpu": {
            "avg_utilization_percent": 57.0,
            "max_utilization_percent": 85.0,
            "peak_memory_mb": 2592.0,
            "max_temperature_c": 50.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 389.34,
          "std_tokens_per_second": 5.54,
          "avg_first_token_latency_s": 0.0071,
          "avg_total_time_s": 0.6577,
          "peak_memory_gb": 1.795,
          "stability": "stable"
        }
      },
      "mistral-7b": {
        "model": "Mistral 7B",
        "params": "7B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 2.8274,
            "first_token_latency_s": 0.0138,
            "tokens_per_second": 90.54,
            "memory_before_gb": 5.216,
            "memory_after_gb": 5.216,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 4.36,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 11.03,
            "p90_inter_token_latency_ms": 11.32
          },
          {
            "tokens_generated": 256,
            "total_time_s": 2.849,
            "first_token_latency_s": 0.0387,
            "tokens_per_second": 89.86,
            "memory_before_gb": 5.216,
            "memory_after_gb": 5.253,
            "memory_delta_gb": 0.037,
            "server_memory_gb": 4.396,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 11.02,
            "p90_inter_token_latency_ms": 11.34
          },
          {
            "tokens_generated": 256,
            "total_time_s": 2.8462,
            "first_token_latency_s": 0.0326,
            "tokens_per_second": 89.94,
            "memory_before_gb": 5.253,
            "memory_after_gb": 5.253,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 4.396,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 11.03,
            "p90_inter_token_latency_ms": 11.38
          }
        ],
        "model_load_time_s": 2.6,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 16,
          "duration_s": 8.283692121505737,
          "cpu": {
            "avg_percent": 7.9,
            "max_percent": 11.0,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 28.8,
            "max_percent": 28.8,
            "peak_used_gb": 18.41
          },
          "gpu": {
            "avg_utilization_percent": 93.6,
            "max_utilization_percent": 95.0,
            "peak_memory_mb": 6332.0,
            "max_temperature_c": 58.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 90.11,
          "std_tokens_per_second": 0.3,
          "avg_first_token_latency_s": 0.0284,
          "avg_total_time_s": 2.8409,
          "peak_memory_gb": 5.253,
          "stability": "stable"
        }
      },
      "llama2-13b": {
        "model": "Llama 2 13B",
        "params": "13B",
        "status": "completed",
        "inference_mode": "server",
        "runs": [
          {
            "tokens_generated": 256,
            "total_time_s": 5.0313,
            "first_token_latency_s": 0.0227,
            "tokens_per_second": 50.88,
            "memory_before_gb": 8.464,
            "memory_after_gb": 8.465,
            "memory_delta_gb": 0.001,
            "server_memory_gb": 7.608,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 19.64,
            "p90_inter_token_latency_ms": 20.11
          },
          {
            "tokens_generated": 256,
            "total_time_s": 5.1103,
            "first_token_latency_s": 0.0969,
            "tokens_per_second": 50.09,
            "memory_before_gb": 8.465,
            "memory_after_gb": 8.719,
            "memory_delta_gb": 0.255,
            "server_memory_gb": 7.863,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 19.66,
            "p90_inter_token_latency_ms": 20.18
          },
          {
            "tokens_generated": 256,
            "total_time_s": 5.0527,
            "first_token_latency_s": 0.0374,
            "tokens_per_second": 50.67,
            "memory_before_gb": 8.719,
            "memory_after_gb": 8.719,
            "memory_delta_gb": 0.0,
            "server_memory_gb": 7.863,
            "error": null,
            "success": true,
            "inference_mode": "server",
            "avg_inter_token_latency_ms": 19.67,
            "p90_inter_token_latency_ms": 20.2
          }
        ],
        "model_load_time_s": 4.66,
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server",
          "server_url": "http://127.0.0.1:8080"
        },
        "resource_usage": {
          "n_samples": 28,
          "duration_s": 14.887704372406006,
          "cpu": {
            "avg_percent": 8.6,
            "max_percent": 15.0,
            "min_percent": 0.0
          },
          "ram": {
            "avg_percent": 34.0,
            "max_percent": 34.1,
            "peak_used_gb": 21.83
          },
          "gpu": {
            "avg_utilization_percent": 95.7,
            "max_utilization_percent": 97.0,
            "peak_memory_mb": 10990.0,
            "max_temperature_c": 58.0
          }
        },
        "summary": {
          "n_successful_runs": 3,
          "n_total_runs": 3,
          "avg_tokens_per_second": 50.55,
          "std_tokens_per_second": 0.33,
          "avg_first_token_latency_s": 0.0523,
          "avg_total_time_s": 5.0648,
          "peak_memory_gb": 8.719,
          "stability": "stable"
        }
      }
    },
    "quantization_comparison": {
      "tinyllama-1.1b": {
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6594,
                "first_token_latency_s": 0.0235,
                "tokens_per_second": 388.22,
                "memory_before_gb": 1.631,
                "memory_after_gb": 1.632,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.775,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.49,
                "p90_inter_token_latency_ms": 2.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6695,
                "first_token_latency_s": 0.0337,
                "tokens_per_second": 382.35,
                "memory_before_gb": 1.632,
                "memory_after_gb": 1.638,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.781,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.49,
                "p90_inter_token_latency_ms": 2.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6559,
                "first_token_latency_s": 0.0235,
                "tokens_per_second": 390.29,
                "memory_before_gb": 1.638,
                "memory_after_gb": 1.638,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.781,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.68
              }
            ],
            "actual_file_size_gb": 0.45,
            "model_load_time_s": 0.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.604,
            "server_memory_after_load_gb": 0.747,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6916606426239014,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.0,
                "max_percent": 23.0,
                "peak_used_gb": 14.7
              },
              "gpu": {
                "avg_utilization_percent": 59.2,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2402.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 386.95,
              "std_tokens_per_second": 3.36,
              "min_tokens_per_second": 382.35,
              "max_tokens_per_second": 390.29,
              "avg_first_token_latency_s": 0.0269,
              "avg_inter_token_latency_ms": 2.49,
              "avg_total_time_s": 0.6616,
              "peak_memory_gb": 1.638,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.51,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6394,
                "first_token_latency_s": 0.0057,
                "tokens_per_second": 400.36,
                "memory_before_gb": 1.694,
                "memory_after_gb": 1.695,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.838,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6435,
                "first_token_latency_s": 0.0092,
                "tokens_per_second": 397.83,
                "memory_before_gb": 1.695,
                "memory_after_gb": 1.701,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.844,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.49,
                "p90_inter_token_latency_ms": 2.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6835,
                "first_token_latency_s": 0.0306,
                "tokens_per_second": 374.52,
                "memory_before_gb": 1.701,
                "memory_after_gb": 1.701,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.844,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.56,
                "p90_inter_token_latency_ms": 2.81
              }
            ],
            "actual_file_size_gb": 0.513,
            "model_load_time_s": 0.56,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.661,
            "server_memory_after_load_gb": 0.804,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6528816223144531,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 13.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.1,
                "max_percent": 23.1,
                "peak_used_gb": 14.78
              },
              "gpu": {
                "avg_utilization_percent": 63.8,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2460.0,
                "max_temperature_c": 55.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 390.9,
              "std_tokens_per_second": 11.63,
              "min_tokens_per_second": 374.52,
              "max_tokens_per_second": 400.36,
              "avg_first_token_latency_s": 0.0152,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6555,
              "peak_memory_gb": 1.701,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.62,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6414,
                "first_token_latency_s": 0.0177,
                "tokens_per_second": 399.15,
                "memory_before_gb": 1.788,
                "memory_after_gb": 1.788,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.45,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6446,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 397.16,
                "memory_before_gb": 1.788,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.938,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.44,
                "p90_inter_token_latency_ms": 2.68
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7083,
                "first_token_latency_s": 0.0193,
                "tokens_per_second": 361.41,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.938,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.7,
                "p90_inter_token_latency_ms": 2.95
              }
            ],
            "actual_file_size_gb": 0.623,
            "model_load_time_s": 1.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.762,
            "server_memory_after_load_gb": 0.905,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6776833534240723,
              "cpu": {
                "avg_percent": 6.8,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.2,
                "max_percent": 23.2,
                "peak_used_gb": 14.86
              },
              "gpu": {
                "avg_utilization_percent": 54.2,
                "max_utilization_percent": 83.0,
                "peak_memory_mb": 2564.0,
                "max_temperature_c": 52.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 385.91,
              "std_tokens_per_second": 17.34,
              "min_tokens_per_second": 361.41,
              "max_tokens_per_second": 399.15,
              "avg_first_token_latency_s": 0.0199,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6648,
              "peak_memory_gb": 1.795,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.73,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7248,
                "first_token_latency_s": 0.0282,
                "tokens_per_second": 353.22,
                "memory_before_gb": 1.887,
                "memory_after_gb": 1.888,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.031,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.73,
                "p90_inter_token_latency_ms": 3.06
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7076,
                "first_token_latency_s": 0.0257,
                "tokens_per_second": 361.78,
                "memory_before_gb": 1.888,
                "memory_after_gb": 1.894,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.038,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.67,
                "p90_inter_token_latency_ms": 2.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.7202,
                "first_token_latency_s": 0.0194,
                "tokens_per_second": 355.45,
                "memory_before_gb": 1.894,
                "memory_after_gb": 1.894,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.038,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.75,
                "p90_inter_token_latency_ms": 3.13
              }
            ],
            "actual_file_size_gb": 0.729,
            "model_load_time_s": 1.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.861,
            "server_memory_after_load_gb": 1.004,
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6860966682434082,
              "cpu": {
                "avg_percent": 6.8,
                "max_percent": 10.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.4,
                "max_percent": 23.4,
                "peak_used_gb": 14.98
              },
              "gpu": {
                "avg_utilization_percent": 63.8,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2666.0,
                "max_temperature_c": 52.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 356.82,
              "std_tokens_per_second": 3.63,
              "min_tokens_per_second": 353.22,
              "max_tokens_per_second": 361.78,
              "avg_first_token_latency_s": 0.0244,
              "avg_inter_token_latency_ms": 2.72,
              "avg_total_time_s": 0.7175,
              "peak_memory_gb": 1.894,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.84,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.7658,
                "first_token_latency_s": 0.0172,
                "tokens_per_second": 334.3,
                "memory_before_gb": 1.985,
                "memory_after_gb": 1.985,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.129,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.93,
                "p90_inter_token_latency_ms": 3.16
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8008,
                "first_token_latency_s": 0.025,
                "tokens_per_second": 319.69,
                "memory_before_gb": 1.985,
                "memory_after_gb": 1.992,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.135,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.04,
                "p90_inter_token_latency_ms": 3.28
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.8035,
                "first_token_latency_s": 0.0227,
                "tokens_per_second": 318.61,
                "memory_before_gb": 1.992,
                "memory_after_gb": 1.992,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.135,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.06,
                "p90_inter_token_latency_ms": 3.32
              }
            ],
            "actual_file_size_gb": 0.842,
            "model_load_time_s": 1.59,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 1.966,
            "server_memory_after_load_gb": 1.109,
            "resource_usage": {
              "n_samples": 5,
              "duration_s": 2.2184200286865234,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.0,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.6,
                "max_percent": 23.6,
                "peak_used_gb": 15.09
              },
              "gpu": {
                "avg_utilization_percent": 68.4,
                "max_utilization_percent": 86.0,
                "peak_memory_mb": 2772.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 324.2,
              "std_tokens_per_second": 7.16,
              "min_tokens_per_second": 318.61,
              "max_tokens_per_second": 334.3,
              "avg_first_token_latency_s": 0.0216,
              "avg_inter_token_latency_ms": 3.01,
              "avg_total_time_s": 0.79,
              "peak_memory_gb": 1.992,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.9074,
                "first_token_latency_s": 0.0068,
                "tokens_per_second": 282.13,
                "memory_before_gb": 2.217,
                "memory_after_gb": 2.218,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.361,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.53,
                "p90_inter_token_latency_ms": 3.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9191,
                "first_token_latency_s": 0.0101,
                "tokens_per_second": 278.53,
                "memory_before_gb": 2.218,
                "memory_after_gb": 2.224,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.368,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.56,
                "p90_inter_token_latency_ms": 3.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.9264,
                "first_token_latency_s": 0.0248,
                "tokens_per_second": 276.34,
                "memory_before_gb": 2.224,
                "memory_after_gb": 2.224,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 1.368,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 3.53,
                "p90_inter_token_latency_ms": 3.79
              }
            ],
            "actual_file_size_gb": 1.09,
            "model_load_time_s": 1.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 2.2,
            "server_memory_after_load_gb": 1.343,
            "resource_usage": {
              "n_samples": 6,
              "duration_s": 2.7651419639587402,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 23.9,
                "max_percent": 23.9,
                "peak_used_gb": 15.31
              },
              "gpu": {
                "avg_utilization_percent": 76.5,
                "max_utilization_percent": 89.0,
                "peak_memory_mb": 3012.0,
                "max_temperature_c": 49.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 279.0,
              "std_tokens_per_second": 2.39,
              "min_tokens_per_second": 276.34,
              "max_tokens_per_second": 282.13,
              "avg_first_token_latency_s": 0.0139,
              "avg_inter_token_latency_ms": 3.54,
              "avg_total_time_s": 0.9176,
              "peak_memory_gb": 2.224,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 0.45,
            "tokens_per_second": 386.95,
            "first_token_latency_s": 0.0269,
            "inter_token_latency_ms": 2.49,
            "peak_memory_gb": 1.638,
            "model_load_time_s": 0.56,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 0.513,
            "tokens_per_second": 390.9,
            "first_token_latency_s": 0.0152,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.701,
            "model_load_time_s": 0.56,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 0.623,
            "tokens_per_second": 385.91,
            "first_token_latency_s": 0.0199,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.795,
            "model_load_time_s": 1.58,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 0.729,
            "tokens_per_second": 356.82,
            "first_token_latency_s": 0.0244,
            "inter_token_latency_ms": 2.72,
            "peak_memory_gb": 1.894,
            "model_load_time_s": 1.58,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 0.842,
            "tokens_per_second": 324.2,
            "first_token_latency_s": 0.0216,
            "inter_token_latency_ms": 3.01,
            "peak_memory_gb": 1.992,
            "model_load_time_s": 1.59,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 1.09,
            "tokens_per_second": 279.0,
            "first_token_latency_s": 0.0139,
            "inter_token_latency_ms": 3.54,
            "peak_memory_gb": 2.224,
            "model_load_time_s": 1.58,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.87,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6112,
                "first_token_latency_s": 0.0137,
                "tokens_per_second": 98.04,
                "memory_before_gb": 4.049,
                "memory_after_gb": 4.049,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 3.193,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.19,
                "p90_inter_token_latency_ms": 10.47
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.637,
                "first_token_latency_s": 0.0374,
                "tokens_per_second": 97.08,
                "memory_before_gb": 4.049,
                "memory_after_gb": 4.086,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 3.229,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.19,
                "p90_inter_token_latency_ms": 10.46
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6269,
                "first_token_latency_s": 0.0155,
                "tokens_per_second": 97.45,
                "memory_before_gb": 4.086,
                "memory_after_gb": 4.086,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 3.229,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.24,
                "p90_inter_token_latency_ms": 10.49
              }
            ],
            "actual_file_size_gb": 2.871,
            "model_load_time_s": 2.61,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 4.02,
            "server_memory_after_load_gb": 3.163,
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.70949649810791,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 12.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 26.8,
                "max_percent": 26.8,
                "peak_used_gb": 17.16
              },
              "gpu": {
                "avg_utilization_percent": 93.7,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 5124.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 97.52,
              "std_tokens_per_second": 0.4,
              "min_tokens_per_second": 97.08,
              "max_tokens_per_second": 98.04,
              "avg_first_token_latency_s": 0.0222,
              "avg_inter_token_latency_ms": 10.21,
              "avg_total_time_s": 2.625,
              "peak_memory_gb": 4.086,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.28,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.6813,
                "first_token_latency_s": 0.0256,
                "tokens_per_second": 95.48,
                "memory_before_gb": 4.448,
                "memory_after_gb": 4.449,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 3.592,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.41,
                "p90_inter_token_latency_ms": 10.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6921,
                "first_token_latency_s": 0.0429,
                "tokens_per_second": 95.09,
                "memory_before_gb": 4.449,
                "memory_after_gb": 4.485,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 3.628,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.39,
                "p90_inter_token_latency_ms": 10.65
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.6774,
                "first_token_latency_s": 0.0158,
                "tokens_per_second": 95.62,
                "memory_before_gb": 4.485,
                "memory_after_gb": 4.485,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 3.628,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 10.44,
                "p90_inter_token_latency_ms": 10.71
              }
            ],
            "actual_file_size_gb": 3.277,
            "model_load_time_s": 2.61,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 4.414,
            "server_memory_after_load_gb": 3.557,
            "resource_usage": {
              "n_samples": 15,
              "duration_s": 7.685590028762817,
              "cpu": {
                "avg_percent": 8.7,
                "max_percent": 12.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.5,
                "max_percent": 27.5,
                "peak_used_gb": 17.58
              },
              "gpu": {
                "avg_utilization_percent": 94.7,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 5526.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 95.4,
              "std_tokens_per_second": 0.22,
              "min_tokens_per_second": 95.09,
              "max_tokens_per_second": 95.62,
              "avg_first_token_latency_s": 0.0281,
              "avg_inter_token_latency_ms": 10.41,
              "avg_total_time_s": 2.6836,
              "peak_memory_gb": 4.485,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.07,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8433,
                "first_token_latency_s": 0.0292,
                "tokens_per_second": 90.04,
                "memory_before_gb": 5.216,
                "memory_after_gb": 5.216,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.36,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.04,
                "p90_inter_token_latency_ms": 11.35
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8539,
                "first_token_latency_s": 0.0426,
                "tokens_per_second": 89.7,
                "memory_before_gb": 5.216,
                "memory_after_gb": 5.253,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.396,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.02,
                "p90_inter_token_latency_ms": 11.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8428,
                "first_token_latency_s": 0.016,
                "tokens_per_second": 90.05,
                "memory_before_gb": 5.253,
                "memory_after_gb": 5.253,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.396,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.43
              }
            ],
            "actual_file_size_gb": 4.068,
            "model_load_time_s": 2.58,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 5.188,
            "server_memory_after_load_gb": 4.332,
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.256115436553955,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 12.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.7,
                "max_percent": 28.7,
                "peak_used_gb": 18.33
              },
              "gpu": {
                "avg_utilization_percent": 94.6,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6320.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.93,
              "std_tokens_per_second": 0.16,
              "min_tokens_per_second": 89.7,
              "max_tokens_per_second": 90.05,
              "avg_first_token_latency_s": 0.0293,
              "avg_inter_token_latency_ms": 11.05,
              "avg_total_time_s": 2.8467,
              "peak_memory_gb": 5.253,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.78,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.2604,
                "first_token_latency_s": 0.0307,
                "tokens_per_second": 78.52,
                "memory_before_gb": 5.911,
                "memory_after_gb": 5.912,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 5.055,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.66,
                "p90_inter_token_latency_ms": 12.97
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.2736,
                "first_token_latency_s": 0.0506,
                "tokens_per_second": 78.2,
                "memory_before_gb": 5.912,
                "memory_after_gb": 5.949,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 5.092,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.64,
                "p90_inter_token_latency_ms": 12.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.2787,
                "first_token_latency_s": 0.0339,
                "tokens_per_second": 78.08,
                "memory_before_gb": 5.949,
                "memory_after_gb": 5.949,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.092,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 12.72,
                "p90_inter_token_latency_ms": 13.03
              }
            ],
            "actual_file_size_gb": 4.779,
            "model_load_time_s": 3.64,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 5.884,
            "server_memory_after_load_gb": 5.027,
            "resource_usage": {
              "n_samples": 18,
              "duration_s": 9.377394437789917,
              "cpu": {
                "avg_percent": 9.0,
                "max_percent": 14.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 29.8,
                "max_percent": 29.8,
                "peak_used_gb": 19.05
              },
              "gpu": {
                "avg_utilization_percent": 95.2,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 7032.0,
                "max_temperature_c": 58.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 78.27,
              "std_tokens_per_second": 0.19,
              "min_tokens_per_second": 78.08,
              "max_tokens_per_second": 78.52,
              "avg_first_token_latency_s": 0.0384,
              "avg_inter_token_latency_ms": 12.67,
              "avg_total_time_s": 3.2709,
              "peak_memory_gb": 5.949,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.53,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 3.7623,
                "first_token_latency_s": 0.0309,
                "tokens_per_second": 68.04,
                "memory_before_gb": 6.643,
                "memory_after_gb": 6.643,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 5.787,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 14.63,
                "p90_inter_token_latency_ms": 14.84
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.7708,
                "first_token_latency_s": 0.0382,
                "tokens_per_second": 67.89,
                "memory_before_gb": 6.643,
                "memory_after_gb": 6.68,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 5.823,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 14.64,
                "p90_inter_token_latency_ms": 14.9
              },
              {
                "tokens_generated": 256,
                "total_time_s": 3.769,
                "first_token_latency_s": 0.0195,
                "tokens_per_second": 67.92,
                "memory_before_gb": 6.68,
                "memory_after_gb": 6.68,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.823,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 14.7,
                "p90_inter_token_latency_ms": 14.96
              }
            ],
            "actual_file_size_gb": 5.534,
            "model_load_time_s": 3.61,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 6.622,
            "server_memory_after_load_gb": 5.766,
            "resource_usage": {
              "n_samples": 21,
              "duration_s": 11.052912950515747,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 14.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 31.0,
                "max_percent": 31.0,
                "peak_used_gb": 19.81
              },
              "gpu": {
                "avg_utilization_percent": 94.5,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 7788.0,
                "max_temperature_c": 60.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 67.95,
              "std_tokens_per_second": 0.06,
              "min_tokens_per_second": 67.89,
              "max_tokens_per_second": 68.04,
              "avg_first_token_latency_s": 0.0295,
              "avg_inter_token_latency_ms": 14.66,
              "avg_total_time_s": 3.7674,
              "peak_memory_gb": 6.68,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.17,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.6512,
                "first_token_latency_s": 0.0211,
                "tokens_per_second": 55.04,
                "memory_before_gb": 8.246,
                "memory_after_gb": 8.246,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.39,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.16,
                "p90_inter_token_latency_ms": 18.4
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.7099,
                "first_token_latency_s": 0.0585,
                "tokens_per_second": 54.35,
                "memory_before_gb": 8.246,
                "memory_after_gb": 8.283,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 7.426,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.24,
                "p90_inter_token_latency_ms": 18.5
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.6984,
                "first_token_latency_s": 0.042,
                "tokens_per_second": 54.49,
                "memory_before_gb": 8.283,
                "memory_after_gb": 8.283,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 7.426,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.26,
                "p90_inter_token_latency_ms": 18.57
              }
            ],
            "actual_file_size_gb": 7.167,
            "model_load_time_s": 4.62,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 8.227,
            "server_memory_after_load_gb": 7.37,
            "resource_usage": {
              "n_samples": 26,
              "duration_s": 13.763888835906982,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.4,
                "max_percent": 33.4,
                "peak_used_gb": 21.36
              },
              "gpu": {
                "avg_utilization_percent": 95.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 9430.0,
                "max_temperature_c": 56.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 54.63,
              "std_tokens_per_second": 0.3,
              "min_tokens_per_second": 54.35,
              "max_tokens_per_second": 55.04,
              "avg_first_token_latency_s": 0.0405,
              "avg_inter_token_latency_ms": 18.22,
              "avg_total_time_s": 4.6865,
              "peak_memory_gb": 8.283,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 2.871,
            "tokens_per_second": 97.52,
            "first_token_latency_s": 0.0222,
            "inter_token_latency_ms": 10.21,
            "peak_memory_gb": 4.086,
            "model_load_time_s": 2.61,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 3.277,
            "tokens_per_second": 95.4,
            "first_token_latency_s": 0.0281,
            "inter_token_latency_ms": 10.41,
            "peak_memory_gb": 4.485,
            "model_load_time_s": 2.61,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 4.068,
            "tokens_per_second": 89.93,
            "first_token_latency_s": 0.0293,
            "inter_token_latency_ms": 11.05,
            "peak_memory_gb": 5.253,
            "model_load_time_s": 2.58,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 4.779,
            "tokens_per_second": 78.27,
            "first_token_latency_s": 0.0384,
            "inter_token_latency_ms": 12.67,
            "peak_memory_gb": 5.949,
            "model_load_time_s": 3.64,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 5.534,
            "tokens_per_second": 67.95,
            "first_token_latency_s": 0.0295,
            "inter_token_latency_ms": 14.66,
            "peak_memory_gb": 6.68,
            "model_load_time_s": 3.61,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 7.167,
            "tokens_per_second": 54.63,
            "first_token_latency_s": 0.0405,
            "inter_token_latency_ms": 18.22,
            "peak_memory_gb": 8.283,
            "model_load_time_s": 4.62,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M",
          "Q5_K_M",
          "Q6_K",
          "Q8_0"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.13,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.572,
                "first_token_latency_s": 0.0434,
                "tokens_per_second": 55.99,
                "memory_before_gb": 6.231,
                "memory_after_gb": 6.232,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 5.375,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 17.76,
                "p90_inter_token_latency_ms": 18.22
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.6797,
                "first_token_latency_s": 0.1187,
                "tokens_per_second": 54.7,
                "memory_before_gb": 6.232,
                "memory_after_gb": 6.487,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 5.63,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 17.89,
                "p90_inter_token_latency_ms": 18.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.5876,
                "first_token_latency_s": 0.0371,
                "tokens_per_second": 55.8,
                "memory_before_gb": 6.487,
                "memory_after_gb": 6.487,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 5.63,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 17.84,
                "p90_inter_token_latency_ms": 18.21
              }
            ],
            "actual_file_size_gb": 5.056,
            "model_load_time_s": 3.62,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 6.201,
            "server_memory_after_load_gb": 5.344,
            "resource_usage": {
              "n_samples": 26,
              "duration_s": 13.780981302261353,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 30.4,
                "max_percent": 30.5,
                "peak_used_gb": 19.51
              },
              "gpu": {
                "avg_utilization_percent": 95.0,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 8698.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 55.5,
              "std_tokens_per_second": 0.57,
              "min_tokens_per_second": 54.7,
              "max_tokens_per_second": 55.99,
              "avg_first_token_latency_s": 0.0664,
              "avg_inter_token_latency_ms": 17.83,
              "avg_total_time_s": 4.6131,
              "peak_memory_gb": 6.487,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 6.34,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 4.743,
                "first_token_latency_s": 0.0342,
                "tokens_per_second": 53.97,
                "memory_before_gb": 7.068,
                "memory_after_gb": 7.068,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 6.212,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.46,
                "p90_inter_token_latency_ms": 18.93
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.8263,
                "first_token_latency_s": 0.1046,
                "tokens_per_second": 53.04,
                "memory_before_gb": 7.068,
                "memory_after_gb": 7.323,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 6.466,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.52,
                "p90_inter_token_latency_ms": 18.92
              },
              {
                "tokens_generated": 256,
                "total_time_s": 4.7586,
                "first_token_latency_s": 0.0365,
                "tokens_per_second": 53.8,
                "memory_before_gb": 7.323,
                "memory_after_gb": 7.323,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 6.466,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 18.52,
                "p90_inter_token_latency_ms": 18.92
              }
            ],
            "actual_file_size_gb": 5.903,
            "model_load_time_s": 4.61,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 7.031,
            "server_memory_after_load_gb": 6.175,
            "resource_usage": {
              "n_samples": 27,
              "duration_s": 14.277941226959229,
              "cpu": {
                "avg_percent": 8.6,
                "max_percent": 13.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 31.6,
                "max_percent": 31.7,
                "peak_used_gb": 20.27
              },
              "gpu": {
                "avg_utilization_percent": 95.3,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 9550.0,
                "max_temperature_c": 63.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 53.6,
              "std_tokens_per_second": 0.4,
              "min_tokens_per_second": 53.04,
              "max_tokens_per_second": 53.97,
              "avg_first_token_latency_s": 0.0584,
              "avg_inter_token_latency_ms": 18.5,
              "avg_total_time_s": 4.776,
              "peak_memory_gb": 7.323,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.87,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0322,
                "first_token_latency_s": 0.0225,
                "tokens_per_second": 50.87,
                "memory_before_gb": 8.463,
                "memory_after_gb": 8.464,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.607,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.64,
                "p90_inter_token_latency_ms": 20.11
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1507,
                "first_token_latency_s": 0.1165,
                "tokens_per_second": 49.7,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0517,
                "first_token_latency_s": 0.0436,
                "tokens_per_second": 50.68,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.64,
                "p90_inter_token_latency_ms": 20.16
              }
            ],
            "actual_file_size_gb": 7.326,
            "model_load_time_s": 4.62,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 8.434,
            "server_memory_after_load_gb": 7.578,
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.848648309707642,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 13.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.8,
                "max_percent": 33.9,
                "peak_used_gb": 21.67
              },
              "gpu": {
                "avg_utilization_percent": 96.5,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10986.0,
                "max_temperature_c": 62.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.42,
              "std_tokens_per_second": 0.51,
              "min_tokens_per_second": 49.7,
              "max_tokens_per_second": 50.87,
              "avg_first_token_latency_s": 0.0609,
              "avg_inter_token_latency_ms": 19.67,
              "avg_total_time_s": 5.0782,
              "peak_memory_gb": 8.719,
              "stability": "stable"
            }
          },
          "Q5_K_M": {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.6,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 8.5753,
                "first_token_latency_s": 0.055,
                "tokens_per_second": 29.85,
                "memory_before_gb": 9.813,
                "memory_after_gb": 9.814,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.957,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 33.41,
                "p90_inter_token_latency_ms": 34.25
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.6289,
                "first_token_latency_s": 0.1186,
                "tokens_per_second": 29.67,
                "memory_before_gb": 9.814,
                "memory_after_gb": 10.069,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 9.212,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 33.37,
                "p90_inter_token_latency_ms": 34.17
              },
              {
                "tokens_generated": 256,
                "total_time_s": 8.5673,
                "first_token_latency_s": 0.0501,
                "tokens_per_second": 29.88,
                "memory_before_gb": 10.069,
                "memory_after_gb": 10.069,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 9.212,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 33.4,
                "p90_inter_token_latency_ms": 34.13
              }
            ],
            "actual_file_size_gb": 8.596,
            "model_load_time_s": 5.65,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 9.774,
            "server_memory_after_load_gb": 8.917,
            "resource_usage": {
              "n_samples": 46,
              "duration_s": 25.309431314468384,
              "cpu": {
                "avg_percent": 54.8,
                "max_percent": 60.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 36.1,
                "max_percent": 36.2,
                "peak_used_gb": 23.15
              },
              "gpu": {
                "avg_utilization_percent": 63.3,
                "max_utilization_percent": 65.0,
                "peak_memory_mb": 11647.0,
                "max_temperature_c": 59.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 29.8,
              "std_tokens_per_second": 0.09,
              "min_tokens_per_second": 29.67,
              "max_tokens_per_second": 29.88,
              "avg_first_token_latency_s": 0.0746,
              "avg_inter_token_latency_ms": 33.39,
              "avg_total_time_s": 8.5905,
              "peak_memory_gb": 10.069,
              "stability": "stable"
            }
          },
          "Q6_K": {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.95,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 18.2037,
                "first_token_latency_s": 0.0951,
                "tokens_per_second": 14.06,
                "memory_before_gb": 11.33,
                "memory_after_gb": 11.331,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 10.474,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 71.01,
                "p90_inter_token_latency_ms": 73.99
              },
              {
                "tokens_generated": 256,
                "total_time_s": 18.7156,
                "first_token_latency_s": 0.1741,
                "tokens_per_second": 13.68,
                "memory_before_gb": 11.331,
                "memory_after_gb": 11.586,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 10.729,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 72.71,
                "p90_inter_token_latency_ms": 74.58
              },
              {
                "tokens_generated": 256,
                "total_time_s": 18.4973,
                "first_token_latency_s": 0.1006,
                "tokens_per_second": 13.84,
                "memory_before_gb": 11.586,
                "memory_after_gb": 11.586,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 10.729,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 72.14,
                "p90_inter_token_latency_ms": 74.27
              }
            ],
            "actual_file_size_gb": 9.946,
            "model_load_time_s": 5.64,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 11.297,
            "server_memory_after_load_gb": 10.44,
            "resource_usage": {
              "n_samples": 96,
              "duration_s": 55.03486728668213,
              "cpu": {
                "avg_percent": 57.7,
                "max_percent": 68.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 38.4,
                "max_percent": 38.6,
                "peak_used_gb": 24.67
              },
              "gpu": {
                "avg_utilization_percent": 36.3,
                "max_utilization_percent": 52.0,
                "peak_memory_mb": 11528.0,
                "max_temperature_c": 50.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 13.86,
              "std_tokens_per_second": 0.16,
              "min_tokens_per_second": 13.68,
              "max_tokens_per_second": 14.06,
              "avg_first_token_latency_s": 0.1233,
              "avg_inter_token_latency_ms": 71.95,
              "avg_total_time_s": 18.4722,
              "peak_memory_gb": 11.586,
              "stability": "stable"
            }
          },
          "Q8_0": {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 13.83,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 42.4296,
                "first_token_latency_s": 0.171,
                "tokens_per_second": 6.03,
                "memory_before_gb": 14.5,
                "memory_after_gb": 14.502,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 13.645,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 165.72,
                "p90_inter_token_latency_ms": 169.75
              },
              {
                "tokens_generated": 256,
                "total_time_s": 42.662,
                "first_token_latency_s": 0.2568,
                "tokens_per_second": 6.0,
                "memory_before_gb": 14.502,
                "memory_after_gb": 14.757,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 13.9,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 166.29,
                "p90_inter_token_latency_ms": 170.13
              },
              {
                "tokens_generated": 256,
                "total_time_s": 42.2088,
                "first_token_latency_s": 0.1689,
                "tokens_per_second": 6.07,
                "memory_before_gb": 14.757,
                "memory_after_gb": 14.757,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 13.9,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 164.86,
                "p90_inter_token_latency_ms": 168.33
              }
            ],
            "actual_file_size_gb": 12.881,
            "model_load_time_s": 6.64,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 14.468,
            "server_memory_after_load_gb": 13.611,
            "resource_usage": {
              "n_samples": 218,
              "duration_s": 126.79633975028992,
              "cpu": {
                "avg_percent": 58.6,
                "max_percent": 65.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.4,
                "max_percent": 43.5,
                "peak_used_gb": 27.83
              },
              "gpu": {
                "avg_utilization_percent": 34.6,
                "max_utilization_percent": 50.0,
                "peak_memory_mb": 11472.0,
                "max_temperature_c": 46.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 6.03,
              "std_tokens_per_second": 0.03,
              "min_tokens_per_second": 6.0,
              "max_tokens_per_second": 6.07,
              "avg_first_token_latency_s": 0.1989,
              "avg_inter_token_latency_ms": 165.62,
              "avg_total_time_s": 42.4335,
              "peak_memory_gb": 14.757,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 5.056,
            "tokens_per_second": 55.5,
            "first_token_latency_s": 0.0664,
            "inter_token_latency_ms": 17.83,
            "peak_memory_gb": 6.487,
            "model_load_time_s": 3.62,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 5.903,
            "tokens_per_second": 53.6,
            "first_token_latency_s": 0.0584,
            "inter_token_latency_ms": 18.5,
            "peak_memory_gb": 7.323,
            "model_load_time_s": 4.61,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 7.326,
            "tokens_per_second": 50.42,
            "first_token_latency_s": 0.0609,
            "inter_token_latency_ms": 19.67,
            "peak_memory_gb": 8.719,
            "model_load_time_s": 4.62,
            "stability": "stable"
          },
          {
            "quantization": "Q5_K_M",
            "bits": 5,
            "file_size_gb": 8.596,
            "tokens_per_second": 29.8,
            "first_token_latency_s": 0.0746,
            "inter_token_latency_ms": 33.39,
            "peak_memory_gb": 10.069,
            "model_load_time_s": 5.65,
            "stability": "stable"
          },
          {
            "quantization": "Q6_K",
            "bits": 6,
            "file_size_gb": 9.946,
            "tokens_per_second": 13.86,
            "first_token_latency_s": 0.1233,
            "inter_token_latency_ms": 71.95,
            "peak_memory_gb": 11.586,
            "model_load_time_s": 5.64,
            "stability": "stable"
          },
          {
            "quantization": "Q8_0",
            "bits": 8,
            "file_size_gb": 12.881,
            "tokens_per_second": 6.03,
            "first_token_latency_s": 0.1989,
            "inter_token_latency_ms": 165.62,
            "peak_memory_gb": 14.757,
            "model_load_time_s": 6.64,
            "stability": "stable"
          }
        ]
      },
      "codellama-34b": {
        "model_name": "CodeLlama 34B",
        "model_key": "codellama-34b",
        "params": "34B",
        "variants_tested": [
          "Q2_K",
          "Q3_K_M",
          "Q4_K_M"
        ],
        "results": {
          "Q2_K": {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 12.8,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 11,
                "total_time_s": 1.8335,
                "first_token_latency_s": 0.1636,
                "tokens_per_second": 6.0,
                "memory_before_gb": 14.522,
                "memory_after_gb": 14.522,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 13.665,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 151.73,
                "p90_inter_token_latency_ms": 154.65
              },
              {
                "tokens_generated": 11,
                "total_time_s": 2.0682,
                "first_token_latency_s": 0.1795,
                "tokens_per_second": 5.32,
                "memory_before_gb": 14.522,
                "memory_after_gb": 14.522,
                "memory_delta_gb": -0.0,
                "server_memory_gb": 13.665,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 173.15,
                "p90_inter_token_latency_ms": 178.32
              },
              {
                "tokens_generated": 11,
                "total_time_s": 2.0717,
                "first_token_latency_s": 0.1826,
                "tokens_per_second": 5.31,
                "memory_before_gb": 14.522,
                "memory_after_gb": 14.522,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 13.665,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 172.87,
                "p90_inter_token_latency_ms": 174.65
              }
            ],
            "actual_file_size_gb": 13.235,
            "model_load_time_s": 8.72,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 14.479,
            "server_memory_after_load_gb": 13.622,
            "resource_usage": {
              "n_samples": 11,
              "duration_s": 5.827523708343506,
              "cpu": {
                "avg_percent": 53.3,
                "max_percent": 61.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 43.1,
                "max_percent": 43.1,
                "peak_used_gb": 27.58
              },
              "gpu": {
                "avg_utilization_percent": 29.1,
                "max_utilization_percent": 48.0,
                "peak_memory_mb": 11586.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 5.54,
              "std_tokens_per_second": 0.32,
              "min_tokens_per_second": 5.31,
              "max_tokens_per_second": 6.0,
              "avg_first_token_latency_s": 0.1752,
              "avg_inter_token_latency_ms": 165.92,
              "avg_total_time_s": 1.9911,
              "peak_memory_gb": 14.522,
              "stability": "stable"
            }
          },
          "Q3_K_M": {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 15.8,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 60.3659,
                "first_token_latency_s": 0.2412,
                "tokens_per_second": 4.24,
                "memory_before_gb": 16.464,
                "memory_after_gb": 16.466,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 15.609,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 235.78,
                "p90_inter_token_latency_ms": 240.17
              },
              {
                "tokens_generated": 256,
                "total_time_s": 60.3936,
                "first_token_latency_s": 0.2791,
                "tokens_per_second": 4.24,
                "memory_before_gb": 16.466,
                "memory_after_gb": 16.527,
                "memory_delta_gb": 0.061,
                "server_memory_gb": 15.67,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 235.74,
                "p90_inter_token_latency_ms": 240.35
              },
              {
                "tokens_generated": 256,
                "total_time_s": 60.4527,
                "first_token_latency_s": 0.27,
                "tokens_per_second": 4.23,
                "memory_before_gb": 16.527,
                "memory_after_gb": 16.527,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 15.67,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 236.01,
                "p90_inter_token_latency_ms": 240.48
              }
            ],
            "actual_file_size_gb": 15.165,
            "model_load_time_s": 8.66,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 16.415,
            "server_memory_after_load_gb": 15.558,
            "resource_usage": {
              "n_samples": 311,
              "duration_s": 180.82948303222656,
              "cpu": {
                "avg_percent": 58.4,
                "max_percent": 69.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 45.5,
                "max_percent": 46.2,
                "peak_used_gb": 29.53
              },
              "gpu": {
                "avg_utilization_percent": 33.7,
                "max_utilization_percent": 80.0,
                "peak_memory_mb": 11600.0,
                "max_temperature_c": 53.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 4.24,
              "std_tokens_per_second": 0.0,
              "min_tokens_per_second": 4.23,
              "max_tokens_per_second": 4.24,
              "avg_first_token_latency_s": 0.2634,
              "avg_inter_token_latency_ms": 235.84,
              "avg_total_time_s": 60.4041,
              "peak_memory_gb": 16.527,
              "stability": "stable"
            }
          },
          "Q4_K_M": {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 20.2,
            "status": "completed",
            "inference_mode": "server",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 84.4088,
                "first_token_latency_s": 0.3367,
                "tokens_per_second": 3.03,
                "memory_before_gb": 20.137,
                "memory_after_gb": 20.139,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 19.282,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 329.69,
                "p90_inter_token_latency_ms": 337.05
              },
              {
                "tokens_generated": 256,
                "total_time_s": 84.6094,
                "first_token_latency_s": 0.3604,
                "tokens_per_second": 3.03,
                "memory_before_gb": 20.139,
                "memory_after_gb": 20.2,
                "memory_delta_gb": 0.061,
                "server_memory_gb": 19.343,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 330.39,
                "p90_inter_token_latency_ms": 337.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 84.5954,
                "first_token_latency_s": 0.3596,
                "tokens_per_second": 3.03,
                "memory_before_gb": 20.2,
                "memory_after_gb": 20.2,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 19.343,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 330.34,
                "p90_inter_token_latency_ms": 337.72
              }
            ],
            "actual_file_size_gb": 18.831,
            "model_load_time_s": 10.72,
            "backend": {
              "backend": "cuda",
              "n_gpu_layers": -1,
              "details": "NVIDIA GPU détecté, utilisation de CUDA",
              "inference_mode": "server",
              "server_url": "http://127.0.0.1:8080"
            },
            "memory_after_load_gb": 20.095,
            "server_memory_after_load_gb": 19.238,
            "resource_usage": {
              "n_samples": 427,
              "duration_s": 253.26409554481506,
              "cpu": {
                "avg_percent": 59.3,
                "max_percent": 68.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 51.2,
                "max_percent": 51.3,
                "peak_used_gb": 32.8
              },
              "gpu": {
                "avg_utilization_percent": 26.3,
                "max_utilization_percent": 80.0,
                "peak_memory_mb": 11489.0,
                "max_temperature_c": 51.0
              }
            },
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 3.03,
              "std_tokens_per_second": 0.0,
              "min_tokens_per_second": 3.03,
              "max_tokens_per_second": 3.03,
              "avg_first_token_latency_s": 0.3522,
              "avg_inter_token_latency_ms": 330.14,
              "avg_total_time_s": 84.5379,
              "peak_memory_gb": 20.2,
              "stability": "stable"
            }
          }
        },
        "comparison_table": [
          {
            "quantization": "Q2_K",
            "bits": 2,
            "file_size_gb": 13.235,
            "tokens_per_second": 5.54,
            "first_token_latency_s": 0.1752,
            "inter_token_latency_ms": 165.92,
            "peak_memory_gb": 14.522,
            "model_load_time_s": 8.72,
            "stability": "stable"
          },
          {
            "quantization": "Q3_K_M",
            "bits": 3,
            "file_size_gb": 15.165,
            "tokens_per_second": 4.24,
            "first_token_latency_s": 0.2634,
            "inter_token_latency_ms": 235.84,
            "peak_memory_gb": 16.527,
            "model_load_time_s": 8.66,
            "stability": "stable"
          },
          {
            "quantization": "Q4_K_M",
            "bits": 4,
            "file_size_gb": 18.831,
            "tokens_per_second": 3.03,
            "first_token_latency_s": 0.3522,
            "inter_token_latency_ms": 330.14,
            "peak_memory_gb": 20.2,
            "model_load_time_s": 10.72,
            "stability": "stable"
          }
        ]
      }
    },
    "temperature_comparison": {
      "tinyllama-1.1b": {
        "axis": "temperature",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6287,
                "first_token_latency_s": 0.0054,
                "tokens_per_second": 407.18,
                "memory_before_gb": 1.788,
                "memory_after_gb": 1.789,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.44,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6616,
                "first_token_latency_s": 0.0327,
                "tokens_per_second": 386.92,
                "memory_before_gb": 1.789,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.47,
                "p90_inter_token_latency_ms": 2.69
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6703,
                "first_token_latency_s": 0.0251,
                "tokens_per_second": 381.92,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.53,
                "p90_inter_token_latency_ms": 2.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 392.01,
              "std_tokens_per_second": 10.92,
              "avg_first_token_latency_s": 0.0211,
              "avg_inter_token_latency_ms": 2.48,
              "avg_total_time_s": 0.6535,
              "peak_memory_gb": 1.795,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6908228397369385,
              "cpu": {
                "avg_percent": 7.6,
                "max_percent": 11.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.2
              },
              "gpu": {
                "avg_utilization_percent": 75.8,
                "max_utilization_percent": 84.0,
                "peak_memory_mb": 2434.0,
                "max_temperature_c": 60.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6835,
                "first_token_latency_s": 0.0273,
                "tokens_per_second": 374.53,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.796,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.57,
                "p90_inter_token_latency_ms": 2.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6711,
                "first_token_latency_s": 0.0238,
                "tokens_per_second": 381.46,
                "memory_before_gb": 1.796,
                "memory_after_gb": 1.802,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.78
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6671,
                "first_token_latency_s": 0.0198,
                "tokens_per_second": 383.73,
                "memory_before_gb": 1.802,
                "memory_after_gb": 1.802,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.77
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 379.91,
              "std_tokens_per_second": 3.91,
              "avg_first_token_latency_s": 0.0236,
              "avg_inter_token_latency_ms": 2.55,
              "avg_total_time_s": 0.6739,
              "peak_memory_gb": 1.802,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6699318885803223,
              "cpu": {
                "avg_percent": 9.9,
                "max_percent": 14.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.2
              },
              "gpu": {
                "avg_utilization_percent": 80.2,
                "max_utilization_percent": 81.0,
                "peak_memory_mb": 2434.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6746,
                "first_token_latency_s": 0.0277,
                "tokens_per_second": 379.5,
                "memory_before_gb": 1.802,
                "memory_after_gb": 1.803,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.946,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6722,
                "first_token_latency_s": 0.0294,
                "tokens_per_second": 380.87,
                "memory_before_gb": 1.803,
                "memory_after_gb": 1.809,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.953,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6748,
                "first_token_latency_s": 0.0317,
                "tokens_per_second": 379.37,
                "memory_before_gb": 1.809,
                "memory_after_gb": 1.809,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.953,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.75
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 379.91,
              "std_tokens_per_second": 0.68,
              "avg_first_token_latency_s": 0.0296,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6739,
              "peak_memory_gb": 1.809,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6743600368499756,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 12.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.2
              },
              "gpu": {
                "avg_utilization_percent": 53.2,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2434.0,
                "max_temperature_c": 62.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 392.01,
            "first_token_latency_s": 0.0211,
            "inter_token_latency_ms": 2.48,
            "peak_memory_gb": 1.795,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 379.91,
            "first_token_latency_s": 0.0236,
            "inter_token_latency_ms": 2.55,
            "peak_memory_gb": 1.802,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 379.91,
            "first_token_latency_s": 0.0296,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.809,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "temperature",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8666,
                "first_token_latency_s": 0.0299,
                "tokens_per_second": 89.3,
                "memory_before_gb": 5.217,
                "memory_after_gb": 5.217,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.361,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.12,
                "p90_inter_token_latency_ms": 11.46
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.869,
                "first_token_latency_s": 0.0504,
                "tokens_per_second": 89.23,
                "memory_before_gb": 5.217,
                "memory_after_gb": 5.254,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.397,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.05,
                "p90_inter_token_latency_ms": 11.31
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8621,
                "first_token_latency_s": 0.037,
                "tokens_per_second": 89.44,
                "memory_before_gb": 5.254,
                "memory_after_gb": 5.254,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.397,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.38
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.32,
              "std_tokens_per_second": 0.09,
              "avg_first_token_latency_s": 0.0391,
              "avg_inter_token_latency_ms": 11.08,
              "avg_total_time_s": 2.8659,
              "peak_memory_gb": 5.254,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.286717891693115,
              "cpu": {
                "avg_percent": 9.9,
                "max_percent": 16.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.6,
                "peak_used_gb": 17.67
              },
              "gpu": {
                "avg_utilization_percent": 92.3,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 6220.0,
                "max_temperature_c": 66.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8656,
                "first_token_latency_s": 0.0325,
                "tokens_per_second": 89.33,
                "memory_before_gb": 5.254,
                "memory_after_gb": 5.255,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.398,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.11,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.851,
                "first_token_latency_s": 0.0278,
                "tokens_per_second": 89.79,
                "memory_before_gb": 5.255,
                "memory_after_gb": 5.291,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.434,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.07,
                "p90_inter_token_latency_ms": 11.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8471,
                "first_token_latency_s": 0.0283,
                "tokens_per_second": 89.92,
                "memory_before_gb": 5.291,
                "memory_after_gb": 5.291,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.434,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.05,
                "p90_inter_token_latency_ms": 11.32
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.68,
              "std_tokens_per_second": 0.25,
              "avg_first_token_latency_s": 0.0295,
              "avg_inter_token_latency_ms": 11.08,
              "avg_total_time_s": 2.8546,
              "peak_memory_gb": 5.291,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.23147177696228,
              "cpu": {
                "avg_percent": 7.8,
                "max_percent": 10.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.71
              },
              "gpu": {
                "avg_utilization_percent": 87.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6218.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.852,
                "first_token_latency_s": 0.0367,
                "tokens_per_second": 89.76,
                "memory_before_gb": 5.291,
                "memory_after_gb": 5.292,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.435,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.04,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8643,
                "first_token_latency_s": 0.0386,
                "tokens_per_second": 89.38,
                "memory_before_gb": 5.292,
                "memory_after_gb": 5.328,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.471,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8608,
                "first_token_latency_s": 0.0399,
                "tokens_per_second": 89.49,
                "memory_before_gb": 5.328,
                "memory_after_gb": 5.328,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.471,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.33
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.54,
              "std_tokens_per_second": 0.16,
              "avg_first_token_latency_s": 0.0384,
              "avg_inter_token_latency_ms": 11.06,
              "avg_total_time_s": 2.859,
              "peak_memory_gb": 5.328,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.260417222976685,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.7,
                "peak_used_gb": 17.74
              },
              "gpu": {
                "avg_utilization_percent": 94.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6218.0,
                "max_temperature_c": 67.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 89.32,
            "first_token_latency_s": 0.0391,
            "inter_token_latency_ms": 11.08,
            "peak_memory_gb": 5.254,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 89.68,
            "first_token_latency_s": 0.0295,
            "inter_token_latency_ms": 11.08,
            "peak_memory_gb": 5.291,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 89.54,
            "first_token_latency_s": 0.0384,
            "inter_token_latency_ms": 11.06,
            "peak_memory_gb": 5.328,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "temperature",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "low",
          "medium",
          "high"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "low": {
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0273,
                "first_token_latency_s": 0.0235,
                "tokens_per_second": 50.92,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.464,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.608,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.62,
                "p90_inter_token_latency_ms": 20.12
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.139,
                "first_token_latency_s": 0.1059,
                "tokens_per_second": 49.81,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 7.863,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.17
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0564,
                "first_token_latency_s": 0.0352,
                "tokens_per_second": 50.63,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.863,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.69,
                "p90_inter_token_latency_ms": 20.14
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.45,
              "std_tokens_per_second": 0.47,
              "avg_first_token_latency_s": 0.0549,
              "avg_inter_token_latency_ms": 19.68,
              "avg_total_time_s": 5.0742,
              "peak_memory_gb": 8.719,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.801562786102295,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 13.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 32.9,
                "max_percent": 33.1,
                "peak_used_gb": 21.16
              },
              "gpu": {
                "avg_utilization_percent": 94.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10884.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "medium": {
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.052,
                "first_token_latency_s": 0.0259,
                "tokens_per_second": 50.67,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.72,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.863,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.22
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1473,
                "first_token_latency_s": 0.133,
                "tokens_per_second": 49.73,
                "memory_before_gb": 8.72,
                "memory_after_gb": 8.974,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.118,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.66,
                "p90_inter_token_latency_ms": 20.22
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0664,
                "first_token_latency_s": 0.0405,
                "tokens_per_second": 50.53,
                "memory_before_gb": 8.974,
                "memory_after_gb": 8.974,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.118,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.1
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.31,
              "std_tokens_per_second": 0.41,
              "avg_first_token_latency_s": 0.0665,
              "avg_inter_token_latency_ms": 19.69,
              "avg_total_time_s": 5.0886,
              "peak_memory_gb": 8.974,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.833497524261475,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.4,
                "max_percent": 33.5,
                "peak_used_gb": 21.41
              },
              "gpu": {
                "avg_utilization_percent": 94.8,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10884.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "high": {
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0576,
                "first_token_latency_s": 0.0261,
                "tokens_per_second": 50.62,
                "memory_before_gb": 8.974,
                "memory_after_gb": 8.975,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.118,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.73,
                "p90_inter_token_latency_ms": 20.23
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1458,
                "first_token_latency_s": 0.1202,
                "tokens_per_second": 49.75,
                "memory_before_gb": 8.975,
                "memory_after_gb": 9.23,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 8.373,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.18
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0746,
                "first_token_latency_s": 0.0476,
                "tokens_per_second": 50.45,
                "memory_before_gb": 9.23,
                "memory_after_gb": 9.23,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 8.373,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.26
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.27,
              "std_tokens_per_second": 0.38,
              "avg_first_token_latency_s": 0.0646,
              "avg_inter_token_latency_ms": 19.72,
              "avg_total_time_s": 5.0927,
              "peak_memory_gb": 9.23,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.833482503890991,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 13.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.8,
                "max_percent": 33.9,
                "peak_used_gb": 21.67
              },
              "gpu": {
                "avg_utilization_percent": 96.1,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10884.0,
                "max_temperature_c": 67.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "temperature_key": "low",
            "temperature": 0.25,
            "label": "Basse (0.25)",
            "tokens_per_second": 50.45,
            "first_token_latency_s": 0.0549,
            "inter_token_latency_ms": 19.68,
            "peak_memory_gb": 8.719,
            "stability": "stable"
          },
          {
            "temperature_key": "medium",
            "temperature": 0.5,
            "label": "Moyenne (0.50)",
            "tokens_per_second": 50.31,
            "first_token_latency_s": 0.0665,
            "inter_token_latency_ms": 19.69,
            "peak_memory_gb": 8.974,
            "stability": "stable"
          },
          {
            "temperature_key": "high",
            "temperature": 0.75,
            "label": "Haute (0.75)",
            "tokens_per_second": 50.27,
            "first_token_latency_s": 0.0646,
            "inter_token_latency_ms": 19.72,
            "peak_memory_gb": 9.23,
            "stability": "stable"
          }
        ]
      }
    },
    "language_comparison": {
      "tinyllama-1.1b": {
        "axis": "language",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6346,
                "first_token_latency_s": 0.0058,
                "tokens_per_second": 403.42,
                "memory_before_gb": 1.788,
                "memory_after_gb": 1.789,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.47,
                "p90_inter_token_latency_ms": 2.7
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6564,
                "first_token_latency_s": 0.0244,
                "tokens_per_second": 390.03,
                "memory_before_gb": 1.789,
                "memory_after_gb": 1.796,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.674,
                "first_token_latency_s": 0.0274,
                "tokens_per_second": 379.82,
                "memory_before_gb": 1.796,
                "memory_after_gb": 1.796,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.76
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 391.09,
              "std_tokens_per_second": 9.66,
              "avg_first_token_latency_s": 0.0192,
              "avg_inter_token_latency_ms": 2.5,
              "avg_total_time_s": 0.655,
              "peak_memory_gb": 1.796,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.693089485168457,
              "cpu": {
                "avg_percent": 8.6,
                "max_percent": 12.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.17
              },
              "gpu": {
                "avg_utilization_percent": 70.5,
                "max_utilization_percent": 85.0,
                "peak_memory_mb": 2450.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6894,
                "first_token_latency_s": 0.0241,
                "tokens_per_second": 371.34,
                "memory_before_gb": 1.796,
                "memory_after_gb": 1.797,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.94,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.61,
                "p90_inter_token_latency_ms": 2.83
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.68,
                "first_token_latency_s": 0.0299,
                "tokens_per_second": 376.47,
                "memory_before_gb": 1.797,
                "memory_after_gb": 1.804,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.947,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.55,
                "p90_inter_token_latency_ms": 2.78
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6596,
                "first_token_latency_s": 0.0081,
                "tokens_per_second": 388.1,
                "memory_before_gb": 1.804,
                "memory_after_gb": 1.811,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.954,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.55,
                "p90_inter_token_latency_ms": 2.78
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 378.64,
              "std_tokens_per_second": 7.01,
              "avg_first_token_latency_s": 0.0207,
              "avg_inter_token_latency_ms": 2.57,
              "avg_total_time_s": 0.6763,
              "peak_memory_gb": 1.811,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.642831802368164,
              "cpu": {
                "avg_percent": 8.9,
                "max_percent": 12.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.19
              },
              "gpu": {
                "avg_utilization_percent": 79.8,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2450.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6597,
                "first_token_latency_s": 0.0234,
                "tokens_per_second": 388.04,
                "memory_before_gb": 1.811,
                "memory_after_gb": 1.812,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.955,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.49,
                "p90_inter_token_latency_ms": 2.73
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6568,
                "first_token_latency_s": 0.0099,
                "tokens_per_second": 389.75,
                "memory_before_gb": 1.812,
                "memory_after_gb": 1.82,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.963,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6698,
                "first_token_latency_s": 0.0309,
                "tokens_per_second": 382.2,
                "memory_before_gb": 1.82,
                "memory_after_gb": 1.827,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.971,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.74
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 386.66,
              "std_tokens_per_second": 3.23,
              "avg_first_token_latency_s": 0.0214,
              "avg_inter_token_latency_ms": 2.51,
              "avg_total_time_s": 0.6621,
              "peak_memory_gb": 1.827,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6896650791168213,
              "cpu": {
                "avg_percent": 7.3,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.22
              },
              "gpu": {
                "avg_utilization_percent": 59.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2450.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6536,
                "first_token_latency_s": 0.0115,
                "tokens_per_second": 391.68,
                "memory_before_gb": 1.827,
                "memory_after_gb": 1.828,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.971,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.76
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.691,
                "first_token_latency_s": 0.0332,
                "tokens_per_second": 370.47,
                "memory_before_gb": 1.828,
                "memory_after_gb": 1.835,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.978,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.58,
                "p90_inter_token_latency_ms": 2.87
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6731,
                "first_token_latency_s": 0.0191,
                "tokens_per_second": 380.31,
                "memory_before_gb": 1.835,
                "memory_after_gb": 1.842,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.56,
                "p90_inter_token_latency_ms": 2.89
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 380.82,
              "std_tokens_per_second": 8.67,
              "avg_first_token_latency_s": 0.0213,
              "avg_inter_token_latency_ms": 2.55,
              "avg_total_time_s": 0.6726,
              "peak_memory_gb": 1.842,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6781363487243652,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 10.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.3,
                "peak_used_gb": 14.23
              },
              "gpu": {
                "avg_utilization_percent": 72.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2450.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6613,
                "first_token_latency_s": 0.0123,
                "tokens_per_second": 387.09,
                "memory_before_gb": 1.842,
                "memory_after_gb": 1.843,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.88
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6584,
                "first_token_latency_s": 0.0199,
                "tokens_per_second": 388.8,
                "memory_before_gb": 1.843,
                "memory_after_gb": 1.85,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.994,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.689,
                "first_token_latency_s": 0.022,
                "tokens_per_second": 371.53,
                "memory_before_gb": 1.85,
                "memory_after_gb": 1.857,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 1.001,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.62,
                "p90_inter_token_latency_ms": 3.02
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 382.47,
              "std_tokens_per_second": 7.77,
              "avg_first_token_latency_s": 0.0181,
              "avg_inter_token_latency_ms": 2.55,
              "avg_total_time_s": 0.6696,
              "peak_memory_gb": 1.857,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6707212924957275,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.3,
                "max_percent": 22.3,
                "peak_used_gb": 14.24
              },
              "gpu": {
                "avg_utilization_percent": 79.2,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2450.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6969,
                "first_token_latency_s": 0.0222,
                "tokens_per_second": 367.36,
                "memory_before_gb": 1.857,
                "memory_after_gb": 1.858,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 1.002,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.64,
                "p90_inter_token_latency_ms": 2.94
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.661,
                "first_token_latency_s": 0.0202,
                "tokens_per_second": 387.28,
                "memory_before_gb": 1.858,
                "memory_after_gb": 1.867,
                "memory_delta_gb": 0.009,
                "server_memory_gb": 1.01,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.51,
                "p90_inter_token_latency_ms": 2.77
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6852,
                "first_token_latency_s": 0.0211,
                "tokens_per_second": 373.61,
                "memory_before_gb": 1.867,
                "memory_after_gb": 1.875,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.018,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.6,
                "p90_inter_token_latency_ms": 2.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 376.08,
              "std_tokens_per_second": 8.32,
              "avg_first_token_latency_s": 0.0212,
              "avg_inter_token_latency_ms": 2.58,
              "avg_total_time_s": 0.681,
              "peak_memory_gb": 1.875,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.686413049697876,
              "cpu": {
                "avg_percent": 7.5,
                "max_percent": 10.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.3,
                "max_percent": 22.3,
                "peak_used_gb": 14.27
              },
              "gpu": {
                "avg_utilization_percent": 75.5,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2452.0,
                "max_temperature_c": 62.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 391.09,
            "first_token_latency_s": 0.0192,
            "inter_token_latency_ms": 2.5,
            "peak_memory_gb": 1.796,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 378.64,
            "first_token_latency_s": 0.0207,
            "inter_token_latency_ms": 2.57,
            "peak_memory_gb": 1.811,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 386.66,
            "first_token_latency_s": 0.0214,
            "inter_token_latency_ms": 2.51,
            "peak_memory_gb": 1.827,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 380.82,
            "first_token_latency_s": 0.0213,
            "inter_token_latency_ms": 2.55,
            "peak_memory_gb": 1.842,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 382.47,
            "first_token_latency_s": 0.0181,
            "inter_token_latency_ms": 2.55,
            "peak_memory_gb": 1.857,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 376.08,
            "first_token_latency_s": 0.0212,
            "inter_token_latency_ms": 2.58,
            "peak_memory_gb": 1.875,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "language",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8529,
                "first_token_latency_s": 0.0345,
                "tokens_per_second": 89.73,
                "memory_before_gb": 5.216,
                "memory_after_gb": 5.217,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.36,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.05,
                "p90_inter_token_latency_ms": 11.34
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8481,
                "first_token_latency_s": 0.0268,
                "tokens_per_second": 89.88,
                "memory_before_gb": 5.217,
                "memory_after_gb": 5.254,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.397,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.36
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8546,
                "first_token_latency_s": 0.0297,
                "tokens_per_second": 89.68,
                "memory_before_gb": 5.254,
                "memory_after_gb": 5.254,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.397,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.76,
              "std_tokens_per_second": 0.08,
              "avg_first_token_latency_s": 0.0303,
              "avg_inter_token_latency_ms": 11.06,
              "avg_total_time_s": 2.8519,
              "peak_memory_gb": 5.254,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.229456424713135,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 14.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.6,
                "peak_used_gb": 17.66
              },
              "gpu": {
                "avg_utilization_percent": 92.4,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 6183.0,
                "max_temperature_c": 64.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8507,
                "first_token_latency_s": 0.0295,
                "tokens_per_second": 89.8,
                "memory_before_gb": 5.254,
                "memory_after_gb": 5.256,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 4.399,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.36
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8783,
                "first_token_latency_s": 0.0475,
                "tokens_per_second": 88.94,
                "memory_before_gb": 5.256,
                "memory_after_gb": 5.295,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.438,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.1,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8661,
                "first_token_latency_s": 0.0434,
                "tokens_per_second": 89.32,
                "memory_before_gb": 5.295,
                "memory_after_gb": 5.334,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.477,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.07,
                "p90_inter_token_latency_ms": 11.31
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.35,
              "std_tokens_per_second": 0.35,
              "avg_first_token_latency_s": 0.0401,
              "avg_inter_token_latency_ms": 11.08,
              "avg_total_time_s": 2.865,
              "peak_memory_gb": 5.334,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.330359697341919,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.8,
                "peak_used_gb": 17.75
              },
              "gpu": {
                "avg_utilization_percent": 89.2,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6183.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 236,
                "total_time_s": 2.8616,
                "first_token_latency_s": 0.044,
                "tokens_per_second": 82.47,
                "memory_before_gb": 5.334,
                "memory_after_gb": 5.335,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.478,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.99,
                "p90_inter_token_latency_ms": 11.41
              },
              {
                "tokens_generated": 247,
                "total_time_s": 2.8634,
                "first_token_latency_s": 0.0408,
                "tokens_per_second": 86.26,
                "memory_before_gb": 5.335,
                "memory_after_gb": 5.374,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.517,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.47,
                "p90_inter_token_latency_ms": 11.35
              },
              {
                "tokens_generated": 247,
                "total_time_s": 2.8463,
                "first_token_latency_s": 0.0268,
                "tokens_per_second": 86.78,
                "memory_before_gb": 5.374,
                "memory_after_gb": 5.413,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.556,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.46,
                "p90_inter_token_latency_ms": 11.41
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 85.17,
              "std_tokens_per_second": 1.92,
              "avg_first_token_latency_s": 0.0372,
              "avg_inter_token_latency_ms": 11.64,
              "avg_total_time_s": 2.8571,
              "peak_memory_gb": 5.413,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.258462905883789,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.8,
                "max_percent": 27.9,
                "peak_used_gb": 17.86
              },
              "gpu": {
                "avg_utilization_percent": 89.1,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6183.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8681,
                "first_token_latency_s": 0.0467,
                "tokens_per_second": 89.26,
                "memory_before_gb": 5.413,
                "memory_after_gb": 5.413,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.557,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8724,
                "first_token_latency_s": 0.0479,
                "tokens_per_second": 89.12,
                "memory_before_gb": 5.413,
                "memory_after_gb": 5.453,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.596,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8625,
                "first_token_latency_s": 0.0374,
                "tokens_per_second": 89.43,
                "memory_before_gb": 5.453,
                "memory_after_gb": 5.493,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.636,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.36
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.27,
              "std_tokens_per_second": 0.13,
              "avg_first_token_latency_s": 0.044,
              "avg_inter_token_latency_ms": 11.07,
              "avg_total_time_s": 2.8677,
              "peak_memory_gb": 5.493,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.196125268936157,
              "cpu": {
                "avg_percent": 7.7,
                "max_percent": 9.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.9,
                "max_percent": 28.0,
                "peak_used_gb": 17.9
              },
              "gpu": {
                "avg_utilization_percent": 94.6,
                "max_utilization_percent": 96.0,
                "peak_memory_mb": 6182.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8734,
                "first_token_latency_s": 0.0491,
                "tokens_per_second": 89.09,
                "memory_before_gb": 5.493,
                "memory_after_gb": 5.494,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.637,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.07,
                "p90_inter_token_latency_ms": 11.33
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8713,
                "first_token_latency_s": 0.0489,
                "tokens_per_second": 89.16,
                "memory_before_gb": 5.494,
                "memory_after_gb": 5.534,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.677,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.07,
                "p90_inter_token_latency_ms": 11.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8585,
                "first_token_latency_s": 0.0372,
                "tokens_per_second": 89.56,
                "memory_before_gb": 5.534,
                "memory_after_gb": 5.574,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.717,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.3
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.27,
              "std_tokens_per_second": 0.21,
              "avg_first_token_latency_s": 0.0451,
              "avg_inter_token_latency_ms": 11.07,
              "avg_total_time_s": 2.8677,
              "peak_memory_gb": 5.574,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.241077423095703,
              "cpu": {
                "avg_percent": 8.5,
                "max_percent": 12.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.1,
                "max_percent": 28.2,
                "peak_used_gb": 18.0
              },
              "gpu": {
                "avg_utilization_percent": 88.5,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6183.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 250,
                "total_time_s": 2.8948,
                "first_token_latency_s": 0.0382,
                "tokens_per_second": 86.36,
                "memory_before_gb": 5.574,
                "memory_after_gb": 5.575,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.718,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.47,
                "p90_inter_token_latency_ms": 11.58
              },
              {
                "tokens_generated": 250,
                "total_time_s": 2.9137,
                "first_token_latency_s": 0.0529,
                "tokens_per_second": 85.8,
                "memory_before_gb": 5.575,
                "memory_after_gb": 5.621,
                "memory_delta_gb": 0.046,
                "server_memory_gb": 4.764,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.49,
                "p90_inter_token_latency_ms": 11.59
              },
              {
                "tokens_generated": 250,
                "total_time_s": 2.9052,
                "first_token_latency_s": 0.0416,
                "tokens_per_second": 86.05,
                "memory_before_gb": 5.621,
                "memory_after_gb": 5.666,
                "memory_delta_gb": 0.045,
                "server_memory_gb": 4.809,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.5,
                "p90_inter_token_latency_ms": 11.62
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 86.07,
              "std_tokens_per_second": 0.23,
              "avg_first_token_latency_s": 0.0442,
              "avg_inter_token_latency_ms": 11.49,
              "avg_total_time_s": 2.9046,
              "peak_memory_gb": 5.666,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.232248544692993,
              "cpu": {
                "avg_percent": 9.2,
                "max_percent": 11.5,
                "min_percent": 7.7
              },
              "ram": {
                "avg_percent": 28.2,
                "max_percent": 28.3,
                "peak_used_gb": 18.06
              },
              "gpu": {
                "avg_utilization_percent": 94.4,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6187.0,
                "max_temperature_c": 68.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 89.76,
            "first_token_latency_s": 0.0303,
            "inter_token_latency_ms": 11.06,
            "peak_memory_gb": 5.254,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 89.35,
            "first_token_latency_s": 0.0401,
            "inter_token_latency_ms": 11.08,
            "peak_memory_gb": 5.334,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 85.17,
            "first_token_latency_s": 0.0372,
            "inter_token_latency_ms": 11.64,
            "peak_memory_gb": 5.413,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 89.27,
            "first_token_latency_s": 0.044,
            "inter_token_latency_ms": 11.07,
            "peak_memory_gb": 5.493,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 89.27,
            "first_token_latency_s": 0.0451,
            "inter_token_latency_ms": 11.07,
            "peak_memory_gb": 5.574,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 86.07,
            "first_token_latency_s": 0.0442,
            "inter_token_latency_ms": 11.49,
            "peak_memory_gb": 5.666,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "language",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "en",
          "fr",
          "zh",
          "es",
          "de",
          "ar"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "en": {
            "language": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0339,
                "first_token_latency_s": 0.0224,
                "tokens_per_second": 50.86,
                "memory_before_gb": 8.463,
                "memory_after_gb": 8.464,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.607,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.65,
                "p90_inter_token_latency_ms": 20.11
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1243,
                "first_token_latency_s": 0.101,
                "tokens_per_second": 49.96,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.7,
                "p90_inter_token_latency_ms": 20.18
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0775,
                "first_token_latency_s": 0.0497,
                "tokens_per_second": 50.42,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.72,
                "p90_inter_token_latency_ms": 20.14
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.41,
              "std_tokens_per_second": 0.37,
              "avg_first_token_latency_s": 0.0577,
              "avg_inter_token_latency_ms": 19.69,
              "avg_total_time_s": 5.0786,
              "peak_memory_gb": 8.719,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.807584762573242,
              "cpu": {
                "avg_percent": 8.9,
                "max_percent": 14.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.0,
                "max_percent": 33.1,
                "peak_used_gb": 21.16
              },
              "gpu": {
                "avg_utilization_percent": 94.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10876.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "fr": {
            "language": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0689,
                "first_token_latency_s": 0.0429,
                "tokens_per_second": 50.5,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.721,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 7.864,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.2
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1137,
                "first_token_latency_s": 0.0857,
                "tokens_per_second": 50.06,
                "memory_before_gb": 8.721,
                "memory_after_gb": 8.987,
                "memory_delta_gb": 0.267,
                "server_memory_gb": 8.131,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.72,
                "p90_inter_token_latency_ms": 20.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1229,
                "first_token_latency_s": 0.0984,
                "tokens_per_second": 49.97,
                "memory_before_gb": 8.987,
                "memory_after_gb": 9.254,
                "memory_delta_gb": 0.266,
                "server_memory_gb": 8.397,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.7,
                "p90_inter_token_latency_ms": 20.2
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.18,
              "std_tokens_per_second": 0.23,
              "avg_first_token_latency_s": 0.0757,
              "avg_inter_token_latency_ms": 19.71,
              "avg_total_time_s": 5.1018,
              "peak_memory_gb": 9.254,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.830565929412842,
              "cpu": {
                "avg_percent": 8.6,
                "max_percent": 13.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.5,
                "max_percent": 33.9,
                "peak_used_gb": 21.67
              },
              "gpu": {
                "avg_utilization_percent": 94.9,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10876.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "zh": {
            "language": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "runs": [
              {
                "tokens_generated": 213,
                "total_time_s": 5.1183,
                "first_token_latency_s": 0.1229,
                "tokens_per_second": 41.62,
                "memory_before_gb": 9.254,
                "memory_after_gb": 9.255,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 8.399,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 23.56,
                "p90_inter_token_latency_ms": 21.12
              },
              {
                "tokens_generated": 210,
                "total_time_s": 5.1588,
                "first_token_latency_s": 0.1641,
                "tokens_per_second": 40.71,
                "memory_before_gb": 9.255,
                "memory_after_gb": 9.54,
                "memory_delta_gb": 0.285,
                "server_memory_gb": 8.683,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 23.8,
                "p90_inter_token_latency_ms": 39.48
              },
              {
                "tokens_generated": 210,
                "total_time_s": 5.1748,
                "first_token_latency_s": 0.1687,
                "tokens_per_second": 40.58,
                "memory_before_gb": 9.54,
                "memory_after_gb": 9.825,
                "memory_delta_gb": 0.285,
                "server_memory_gb": 8.968,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 23.86,
                "p90_inter_token_latency_ms": 39.22
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 40.97,
              "std_tokens_per_second": 0.46,
              "avg_first_token_latency_s": 0.1519,
              "avg_inter_token_latency_ms": 23.74,
              "avg_total_time_s": 5.1506,
              "peak_memory_gb": 9.825,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.45067048072815,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 11.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 34.3,
                "max_percent": 34.8,
                "peak_used_gb": 22.24
              },
              "gpu": {
                "avg_utilization_percent": 94.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10878.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "es": {
            "language": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0934,
                "first_token_latency_s": 0.0694,
                "tokens_per_second": 50.26,
                "memory_before_gb": 9.825,
                "memory_after_gb": 9.826,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.969,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.7,
                "p90_inter_token_latency_ms": 20.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1774,
                "first_token_latency_s": 0.1348,
                "tokens_per_second": 49.45,
                "memory_before_gb": 9.826,
                "memory_after_gb": 10.096,
                "memory_delta_gb": 0.271,
                "server_memory_gb": 9.24,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.77,
                "p90_inter_token_latency_ms": 20.21
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1509,
                "first_token_latency_s": 0.121,
                "tokens_per_second": 49.7,
                "memory_before_gb": 10.096,
                "memory_after_gb": 10.367,
                "memory_delta_gb": 0.271,
                "server_memory_gb": 9.511,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.72,
                "p90_inter_token_latency_ms": 20.17
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.8,
              "std_tokens_per_second": 0.34,
              "avg_first_token_latency_s": 0.1084,
              "avg_inter_token_latency_ms": 19.73,
              "avg_total_time_s": 5.1406,
              "peak_memory_gb": 10.367,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.423887491226196,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 14.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 35.2,
                "max_percent": 35.7,
                "peak_used_gb": 22.8
              },
              "gpu": {
                "avg_utilization_percent": 90.7,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10878.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "de": {
            "language": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0915,
                "first_token_latency_s": 0.0482,
                "tokens_per_second": 50.28,
                "memory_before_gb": 10.367,
                "memory_after_gb": 10.368,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.511,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.78,
                "p90_inter_token_latency_ms": 20.27
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1685,
                "first_token_latency_s": 0.1339,
                "tokens_per_second": 49.53,
                "memory_before_gb": 10.368,
                "memory_after_gb": 10.642,
                "memory_delta_gb": 0.274,
                "server_memory_gb": 9.785,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.24
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1451,
                "first_token_latency_s": 0.1103,
                "tokens_per_second": 49.76,
                "memory_before_gb": 10.642,
                "memory_after_gb": 10.915,
                "memory_delta_gb": 0.273,
                "server_memory_gb": 10.058,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.2
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.86,
              "std_tokens_per_second": 0.31,
              "avg_first_token_latency_s": 0.0975,
              "avg_inter_token_latency_ms": 19.75,
              "avg_total_time_s": 5.135,
              "peak_memory_gb": 10.915,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.377537250518799,
              "cpu": {
                "avg_percent": 8.6,
                "max_percent": 15.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 36.1,
                "max_percent": 36.5,
                "peak_used_gb": 23.35
              },
              "gpu": {
                "avg_utilization_percent": 90.9,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10878.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "ar": {
            "language": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "runs": [
              {
                "tokens_generated": 239,
                "total_time_s": 5.1159,
                "first_token_latency_s": 0.0647,
                "tokens_per_second": 46.72,
                "memory_before_gb": 10.915,
                "memory_after_gb": 10.916,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 10.059,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 21.14,
                "p90_inter_token_latency_ms": 20.41
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.2133,
                "first_token_latency_s": 0.1606,
                "tokens_per_second": 49.11,
                "memory_before_gb": 10.916,
                "memory_after_gb": 11.23,
                "memory_delta_gb": 0.314,
                "server_memory_gb": 10.373,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.81,
                "p90_inter_token_latency_ms": 20.28
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.2093,
                "first_token_latency_s": 0.1408,
                "tokens_per_second": 49.14,
                "memory_before_gb": 11.23,
                "memory_after_gb": 11.544,
                "memory_delta_gb": 0.314,
                "server_memory_gb": 10.687,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.88,
                "p90_inter_token_latency_ms": 20.33
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 48.32,
              "std_tokens_per_second": 1.13,
              "avg_first_token_latency_s": 0.122,
              "avg_inter_token_latency_ms": 20.28,
              "avg_total_time_s": 5.1795,
              "peak_memory_gb": 11.544,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.477108240127563,
              "cpu": {
                "avg_percent": 8.8,
                "max_percent": 14.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 37.0,
                "max_percent": 37.5,
                "peak_used_gb": 23.97
              },
              "gpu": {
                "avg_utilization_percent": 90.4,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10880.0,
                "max_temperature_c": 69.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "language_key": "en",
            "label": "Anglais",
            "flag": "🇬🇧",
            "tokens_per_second": 50.41,
            "first_token_latency_s": 0.0577,
            "inter_token_latency_ms": 19.69,
            "peak_memory_gb": 8.719,
            "stability": "stable"
          },
          {
            "language_key": "fr",
            "label": "Français",
            "flag": "🇫🇷",
            "tokens_per_second": 50.18,
            "first_token_latency_s": 0.0757,
            "inter_token_latency_ms": 19.71,
            "peak_memory_gb": 9.254,
            "stability": "stable"
          },
          {
            "language_key": "zh",
            "label": "Mandarin",
            "flag": "🇨🇳",
            "tokens_per_second": 40.97,
            "first_token_latency_s": 0.1519,
            "inter_token_latency_ms": 23.74,
            "peak_memory_gb": 9.825,
            "stability": "stable"
          },
          {
            "language_key": "es",
            "label": "Espagnol",
            "flag": "🇪🇸",
            "tokens_per_second": 49.8,
            "first_token_latency_s": 0.1084,
            "inter_token_latency_ms": 19.73,
            "peak_memory_gb": 10.367,
            "stability": "stable"
          },
          {
            "language_key": "de",
            "label": "Allemand",
            "flag": "🇩🇪",
            "tokens_per_second": 49.86,
            "first_token_latency_s": 0.0975,
            "inter_token_latency_ms": 19.75,
            "peak_memory_gb": 10.915,
            "stability": "stable"
          },
          {
            "language_key": "ar",
            "label": "Arabe",
            "flag": "🇸🇦",
            "tokens_per_second": 48.32,
            "first_token_latency_s": 0.122,
            "inter_token_latency_ms": 20.28,
            "peak_memory_gb": 11.544,
            "stability": "stable"
          }
        ]
      }
    },
    "prompt_type_comparison": {
      "tinyllama-1.1b": {
        "axis": "prompt_type",
        "model_name": "TinyLlama 1.1B",
        "model_key": "tinyllama-1.1b",
        "params": "1.1B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6498,
                "first_token_latency_s": 0.0176,
                "tokens_per_second": 393.95,
                "memory_before_gb": 1.788,
                "memory_after_gb": 1.789,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.932,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.48,
                "p90_inter_token_latency_ms": 2.71
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6523,
                "first_token_latency_s": 0.027,
                "tokens_per_second": 392.45,
                "memory_before_gb": 1.789,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.938,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.45,
                "p90_inter_token_latency_ms": 2.67
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6749,
                "first_token_latency_s": 0.0174,
                "tokens_per_second": 379.31,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.795,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.939,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.58,
                "p90_inter_token_latency_ms": 2.83
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 388.57,
              "std_tokens_per_second": 6.58,
              "avg_first_token_latency_s": 0.0207,
              "avg_inter_token_latency_ms": 2.5,
              "avg_total_time_s": 0.659,
              "peak_memory_gb": 1.795,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.674079179763794,
              "cpu": {
                "avg_percent": 6.6,
                "max_percent": 9.4,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.17
              },
              "gpu": {
                "avg_utilization_percent": 60.2,
                "max_utilization_percent": 84.0,
                "peak_memory_mb": 2462.0,
                "max_temperature_c": 61.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6855,
                "first_token_latency_s": 0.0336,
                "tokens_per_second": 373.46,
                "memory_before_gb": 1.795,
                "memory_after_gb": 1.797,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.94,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.56,
                "p90_inter_token_latency_ms": 2.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6475,
                "first_token_latency_s": 0.0096,
                "tokens_per_second": 395.39,
                "memory_before_gb": 1.797,
                "memory_after_gb": 1.804,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.947,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6615,
                "first_token_latency_s": 0.0198,
                "tokens_per_second": 387.0,
                "memory_before_gb": 1.804,
                "memory_after_gb": 1.811,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.955,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.78
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 385.28,
              "std_tokens_per_second": 9.03,
              "avg_first_token_latency_s": 0.021,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6648,
              "peak_memory_gb": 1.811,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6517102718353271,
              "cpu": {
                "avg_percent": 8.9,
                "max_percent": 14.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.18
              },
              "gpu": {
                "avg_utilization_percent": 64.2,
                "max_utilization_percent": 83.0,
                "peak_memory_mb": 2462.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6757,
                "first_token_latency_s": 0.0332,
                "tokens_per_second": 378.85,
                "memory_before_gb": 1.811,
                "memory_after_gb": 1.812,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.956,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.79
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6759,
                "first_token_latency_s": 0.028,
                "tokens_per_second": 378.77,
                "memory_before_gb": 1.812,
                "memory_after_gb": 1.82,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.964,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.86
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6542,
                "first_token_latency_s": 0.0103,
                "tokens_per_second": 391.29,
                "memory_before_gb": 1.82,
                "memory_after_gb": 1.828,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.971,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.86
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 382.97,
              "std_tokens_per_second": 5.88,
              "avg_first_token_latency_s": 0.0238,
              "avg_inter_token_latency_ms": 2.53,
              "avg_total_time_s": 0.6686,
              "peak_memory_gb": 1.828,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6722888946533203,
              "cpu": {
                "avg_percent": 6.9,
                "max_percent": 10.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.2
              },
              "gpu": {
                "avg_utilization_percent": 76.5,
                "max_utilization_percent": 83.0,
                "peak_memory_mb": 2464.0,
                "max_temperature_c": 62.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6616,
                "first_token_latency_s": 0.0129,
                "tokens_per_second": 386.94,
                "memory_before_gb": 1.828,
                "memory_after_gb": 1.829,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 0.972,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.54,
                "p90_inter_token_latency_ms": 2.89
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6643,
                "first_token_latency_s": 0.0286,
                "tokens_per_second": 385.35,
                "memory_before_gb": 1.829,
                "memory_after_gb": 1.836,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.979,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.49,
                "p90_inter_token_latency_ms": 2.81
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6656,
                "first_token_latency_s": 0.0226,
                "tokens_per_second": 384.62,
                "memory_before_gb": 1.836,
                "memory_after_gb": 1.843,
                "memory_delta_gb": 0.007,
                "server_memory_gb": 0.986,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.52,
                "p90_inter_token_latency_ms": 2.8
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 385.64,
              "std_tokens_per_second": 0.97,
              "avg_first_token_latency_s": 0.0214,
              "avg_inter_token_latency_ms": 2.52,
              "avg_total_time_s": 0.6638,
              "peak_memory_gb": 1.843,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6898984909057617,
              "cpu": {
                "avg_percent": 9.6,
                "max_percent": 14.1,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.2,
                "peak_used_gb": 14.22
              },
              "gpu": {
                "avg_utilization_percent": 78.0,
                "max_utilization_percent": 82.0,
                "peak_memory_mb": 2464.0,
                "max_temperature_c": 63.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 0.6626,
                "first_token_latency_s": 0.0246,
                "tokens_per_second": 386.34,
                "memory_before_gb": 1.843,
                "memory_after_gb": 1.843,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 0.987,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.5,
                "p90_inter_token_latency_ms": 2.74
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6739,
                "first_token_latency_s": 0.0201,
                "tokens_per_second": 379.9,
                "memory_before_gb": 1.843,
                "memory_after_gb": 1.851,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 0.994,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.56,
                "p90_inter_token_latency_ms": 2.82
              },
              {
                "tokens_generated": 256,
                "total_time_s": 0.6866,
                "first_token_latency_s": 0.0228,
                "tokens_per_second": 372.83,
                "memory_before_gb": 1.851,
                "memory_after_gb": 1.859,
                "memory_delta_gb": 0.008,
                "server_memory_gb": 1.002,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 2.6,
                "p90_inter_token_latency_ms": 2.87
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 379.69,
              "std_tokens_per_second": 5.52,
              "avg_first_token_latency_s": 0.0225,
              "avg_inter_token_latency_ms": 2.55,
              "avg_total_time_s": 0.6744,
              "peak_memory_gb": 1.859,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 4,
              "duration_s": 1.6581077575683594,
              "cpu": {
                "avg_percent": 8.0,
                "max_percent": 10.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 22.2,
                "max_percent": 22.3,
                "peak_used_gb": 14.25
              },
              "gpu": {
                "avg_utilization_percent": 64.8,
                "max_utilization_percent": 81.0,
                "peak_memory_mb": 2464.0,
                "max_temperature_c": 62.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 388.57,
            "first_token_latency_s": 0.0207,
            "inter_token_latency_ms": 2.5,
            "peak_memory_gb": 1.795,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 385.28,
            "first_token_latency_s": 0.021,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.811,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 382.97,
            "first_token_latency_s": 0.0238,
            "inter_token_latency_ms": 2.53,
            "peak_memory_gb": 1.828,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 385.64,
            "first_token_latency_s": 0.0214,
            "inter_token_latency_ms": 2.52,
            "peak_memory_gb": 1.843,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 379.69,
            "first_token_latency_s": 0.0225,
            "inter_token_latency_ms": 2.55,
            "peak_memory_gb": 1.859,
            "stability": "stable"
          }
        ]
      },
      "mistral-7b": {
        "axis": "prompt_type",
        "model_name": "Mistral 7B",
        "model_key": "mistral-7b",
        "params": "7B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8463,
                "first_token_latency_s": 0.035,
                "tokens_per_second": 89.94,
                "memory_before_gb": 5.216,
                "memory_after_gb": 5.216,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.36,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.02,
                "p90_inter_token_latency_ms": 11.29
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8633,
                "first_token_latency_s": 0.0449,
                "tokens_per_second": 89.41,
                "memory_before_gb": 5.216,
                "memory_after_gb": 5.253,
                "memory_delta_gb": 0.037,
                "server_memory_gb": 4.396,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.05,
                "p90_inter_token_latency_ms": 11.34
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8577,
                "first_token_latency_s": 0.0288,
                "tokens_per_second": 89.58,
                "memory_before_gb": 5.253,
                "memory_after_gb": 5.253,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 4.396,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.09,
                "p90_inter_token_latency_ms": 11.49
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.64,
              "std_tokens_per_second": 0.22,
              "avg_first_token_latency_s": 0.0362,
              "avg_inter_token_latency_ms": 11.05,
              "avg_total_time_s": 2.8558,
              "peak_memory_gb": 5.253,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.300511837005615,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 13.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.6,
                "max_percent": 27.7,
                "peak_used_gb": 17.68
              },
              "gpu": {
                "avg_utilization_percent": 93.2,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6214.0,
                "max_temperature_c": 65.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8606,
                "first_token_latency_s": 0.0404,
                "tokens_per_second": 89.49,
                "memory_before_gb": 5.253,
                "memory_after_gb": 5.255,
                "memory_delta_gb": 0.002,
                "server_memory_gb": 4.398,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.06,
                "p90_inter_token_latency_ms": 11.39
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.878,
                "first_token_latency_s": 0.0404,
                "tokens_per_second": 88.95,
                "memory_before_gb": 5.255,
                "memory_after_gb": 5.294,
                "memory_delta_gb": 0.04,
                "server_memory_gb": 4.437,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.13,
                "p90_inter_token_latency_ms": 11.43
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8761,
                "first_token_latency_s": 0.0468,
                "tokens_per_second": 89.01,
                "memory_before_gb": 5.294,
                "memory_after_gb": 5.334,
                "memory_delta_gb": 0.039,
                "server_memory_gb": 4.477,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.09,
                "p90_inter_token_latency_ms": 11.35
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.15,
              "std_tokens_per_second": 0.24,
              "avg_first_token_latency_s": 0.0425,
              "avg_inter_token_latency_ms": 11.09,
              "avg_total_time_s": 2.8716,
              "peak_memory_gb": 5.334,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.24382495880127,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 12.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.7,
                "max_percent": 27.8,
                "peak_used_gb": 17.76
              },
              "gpu": {
                "avg_utilization_percent": 86.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6214.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 183,
                "total_time_s": 2.0503,
                "first_token_latency_s": 0.0315,
                "tokens_per_second": 89.26,
                "memory_before_gb": 5.334,
                "memory_after_gb": 5.334,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.478,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.03,
                "p90_inter_token_latency_ms": 11.23
              },
              {
                "tokens_generated": 166,
                "total_time_s": 1.8722,
                "first_token_latency_s": 0.0375,
                "tokens_per_second": 88.66,
                "memory_before_gb": 5.334,
                "memory_after_gb": 5.368,
                "memory_delta_gb": 0.033,
                "server_memory_gb": 4.511,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.05,
                "p90_inter_token_latency_ms": 11.3
              },
              {
                "tokens_generated": 166,
                "total_time_s": 1.8573,
                "first_token_latency_s": 0.0239,
                "tokens_per_second": 89.38,
                "memory_before_gb": 5.368,
                "memory_after_gb": 5.399,
                "memory_delta_gb": 0.031,
                "server_memory_gb": 4.542,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.04,
                "p90_inter_token_latency_ms": 11.31
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.1,
              "std_tokens_per_second": 0.31,
              "avg_first_token_latency_s": 0.031,
              "avg_inter_token_latency_ms": 11.04,
              "avg_total_time_s": 1.9266,
              "peak_memory_gb": 5.399,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 11,
              "duration_s": 5.558166265487671,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 10.5,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.8,
                "max_percent": 27.9,
                "peak_used_gb": 17.81
              },
              "gpu": {
                "avg_utilization_percent": 91.8,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6214.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8652,
                "first_token_latency_s": 0.0384,
                "tokens_per_second": 89.35,
                "memory_before_gb": 5.399,
                "memory_after_gb": 5.399,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.543,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.08,
                "p90_inter_token_latency_ms": 11.38
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8573,
                "first_token_latency_s": 0.0278,
                "tokens_per_second": 89.6,
                "memory_before_gb": 5.399,
                "memory_after_gb": 5.438,
                "memory_delta_gb": 0.038,
                "server_memory_gb": 4.581,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.1,
                "p90_inter_token_latency_ms": 11.43
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8696,
                "first_token_latency_s": 0.0417,
                "tokens_per_second": 89.21,
                "memory_before_gb": 5.438,
                "memory_after_gb": 5.475,
                "memory_delta_gb": 0.038,
                "server_memory_gb": 4.618,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.09,
                "p90_inter_token_latency_ms": 11.43
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.39,
              "std_tokens_per_second": 0.16,
              "avg_first_token_latency_s": 0.036,
              "avg_inter_token_latency_ms": 11.09,
              "avg_total_time_s": 2.864,
              "peak_memory_gb": 5.475,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.298261642456055,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 10.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 27.9,
                "max_percent": 28.0,
                "peak_used_gb": 17.88
              },
              "gpu": {
                "avg_utilization_percent": 94.6,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6214.0,
                "max_temperature_c": 68.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 2.8641,
                "first_token_latency_s": 0.0355,
                "tokens_per_second": 89.38,
                "memory_before_gb": 5.475,
                "memory_after_gb": 5.476,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 4.62,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.09,
                "p90_inter_token_latency_ms": 11.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8664,
                "first_token_latency_s": 0.0256,
                "tokens_per_second": 89.31,
                "memory_before_gb": 5.476,
                "memory_after_gb": 5.519,
                "memory_delta_gb": 0.043,
                "server_memory_gb": 4.663,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.14,
                "p90_inter_token_latency_ms": 11.41
              },
              {
                "tokens_generated": 256,
                "total_time_s": 2.8522,
                "first_token_latency_s": 0.0282,
                "tokens_per_second": 89.76,
                "memory_before_gb": 5.519,
                "memory_after_gb": 5.562,
                "memory_delta_gb": 0.043,
                "server_memory_gb": 4.706,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 11.07,
                "p90_inter_token_latency_ms": 11.33
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 89.48,
              "std_tokens_per_second": 0.2,
              "avg_first_token_latency_s": 0.0298,
              "avg_inter_token_latency_ms": 11.1,
              "avg_total_time_s": 2.8609,
              "peak_memory_gb": 5.562,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 16,
              "duration_s": 8.24686884880066,
              "cpu": {
                "avg_percent": 8.2,
                "max_percent": 11.6,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 28.0,
                "max_percent": 28.1,
                "peak_used_gb": 17.98
              },
              "gpu": {
                "avg_utilization_percent": 94.6,
                "max_utilization_percent": 95.0,
                "peak_memory_mb": 6216.0,
                "max_temperature_c": 69.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 89.64,
            "first_token_latency_s": 0.0362,
            "inter_token_latency_ms": 11.05,
            "peak_memory_gb": 5.253,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 89.15,
            "first_token_latency_s": 0.0425,
            "inter_token_latency_ms": 11.09,
            "peak_memory_gb": 5.334,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 89.1,
            "first_token_latency_s": 0.031,
            "inter_token_latency_ms": 11.04,
            "peak_memory_gb": 5.399,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 89.39,
            "first_token_latency_s": 0.036,
            "inter_token_latency_ms": 11.09,
            "peak_memory_gb": 5.475,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 89.48,
            "first_token_latency_s": 0.0298,
            "inter_token_latency_ms": 11.1,
            "peak_memory_gb": 5.562,
            "stability": "stable"
          }
        ]
      },
      "llama2-13b": {
        "axis": "prompt_type",
        "model_name": "Llama 2 13B",
        "model_key": "llama2-13b",
        "params": "13B",
        "variants_tested": [
          "general",
          "code",
          "reasoning",
          "creative",
          "math"
        ],
        "inference_mode": "server",
        "status": "completed",
        "results": {
          "general": {
            "prompt_type": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0338,
                "first_token_latency_s": 0.023,
                "tokens_per_second": 50.86,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.464,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.608,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.65,
                "p90_inter_token_latency_ms": 20.13
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1218,
                "first_token_latency_s": 0.0928,
                "tokens_per_second": 49.98,
                "memory_before_gb": 8.464,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.255,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.72,
                "p90_inter_token_latency_ms": 20.2
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.0678,
                "first_token_latency_s": 0.0478,
                "tokens_per_second": 50.51,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.719,
                "memory_delta_gb": 0.0,
                "server_memory_gb": 7.862,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.69,
                "p90_inter_token_latency_ms": 20.17
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.45,
              "std_tokens_per_second": 0.36,
              "avg_first_token_latency_s": 0.0545,
              "avg_inter_token_latency_ms": 19.69,
              "avg_total_time_s": 5.0745,
              "peak_memory_gb": 8.719,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 28,
              "duration_s": 14.800323247909546,
              "cpu": {
                "avg_percent": 8.1,
                "max_percent": 11.9,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.0,
                "max_percent": 33.1,
                "peak_used_gb": 21.15
              },
              "gpu": {
                "avg_utilization_percent": 94.9,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10857.0,
                "max_temperature_c": 67.0
              }
            }
          },
          "code": {
            "prompt_type": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1058,
                "first_token_latency_s": 0.0677,
                "tokens_per_second": 50.14,
                "memory_before_gb": 8.719,
                "memory_after_gb": 8.721,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 7.864,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.76,
                "p90_inter_token_latency_ms": 20.3
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1431,
                "first_token_latency_s": 0.098,
                "tokens_per_second": 49.78,
                "memory_before_gb": 8.721,
                "memory_after_gb": 8.993,
                "memory_delta_gb": 0.273,
                "server_memory_gb": 8.136,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.78,
                "p90_inter_token_latency_ms": 20.28
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1601,
                "first_token_latency_s": 0.114,
                "tokens_per_second": 49.61,
                "memory_before_gb": 8.993,
                "memory_after_gb": 9.266,
                "memory_delta_gb": 0.272,
                "server_memory_gb": 8.409,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.79,
                "p90_inter_token_latency_ms": 20.17
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.84,
              "std_tokens_per_second": 0.22,
              "avg_first_token_latency_s": 0.0932,
              "avg_inter_token_latency_ms": 19.78,
              "avg_total_time_s": 5.1363,
              "peak_memory_gb": 9.266,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.312761068344116,
              "cpu": {
                "avg_percent": 9.5,
                "max_percent": 19.8,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 33.5,
                "max_percent": 33.9,
                "peak_used_gb": 21.7
              },
              "gpu": {
                "avg_utilization_percent": 92.7,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10884.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "reasoning": {
            "prompt_type": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0975,
                "first_token_latency_s": 0.0531,
                "tokens_per_second": 50.22,
                "memory_before_gb": 9.265,
                "memory_after_gb": 9.267,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.41,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.78,
                "p90_inter_token_latency_ms": 20.24
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1403,
                "first_token_latency_s": 0.1073,
                "tokens_per_second": 49.8,
                "memory_before_gb": 9.267,
                "memory_after_gb": 9.558,
                "memory_delta_gb": 0.292,
                "server_memory_gb": 8.702,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.26
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1783,
                "first_token_latency_s": 0.1064,
                "tokens_per_second": 49.44,
                "memory_before_gb": 9.558,
                "memory_after_gb": 9.85,
                "memory_delta_gb": 0.291,
                "server_memory_gb": 8.993,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.89,
                "p90_inter_token_latency_ms": 20.39
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.82,
              "std_tokens_per_second": 0.32,
              "avg_first_token_latency_s": 0.0889,
              "avg_inter_token_latency_ms": 19.8,
              "avg_total_time_s": 5.1387,
              "peak_memory_gb": 9.85,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.371500968933105,
              "cpu": {
                "avg_percent": 9.7,
                "max_percent": 19.2,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 34.4,
                "max_percent": 35.0,
                "peak_used_gb": 22.35
              },
              "gpu": {
                "avg_utilization_percent": 93.3,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10884.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "creative": {
            "prompt_type": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.0743,
                "first_token_latency_s": 0.0469,
                "tokens_per_second": 50.45,
                "memory_before_gb": 9.85,
                "memory_after_gb": 9.85,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 8.994,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.71,
                "p90_inter_token_latency_ms": 20.18
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1445,
                "first_token_latency_s": 0.1113,
                "tokens_per_second": 49.76,
                "memory_before_gb": 9.85,
                "memory_after_gb": 10.115,
                "memory_delta_gb": 0.265,
                "server_memory_gb": 9.259,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.74,
                "p90_inter_token_latency_ms": 20.2
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1214,
                "first_token_latency_s": 0.1034,
                "tokens_per_second": 49.99,
                "memory_before_gb": 10.115,
                "memory_after_gb": 10.38,
                "memory_delta_gb": 0.265,
                "server_memory_gb": 9.523,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.68,
                "p90_inter_token_latency_ms": 20.11
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 50.07,
              "std_tokens_per_second": 0.29,
              "avg_first_token_latency_s": 0.0872,
              "avg_inter_token_latency_ms": 19.71,
              "avg_total_time_s": 5.1134,
              "peak_memory_gb": 10.38,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.32267689704895,
              "cpu": {
                "avg_percent": 8.4,
                "max_percent": 14.3,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 35.3,
                "max_percent": 35.7,
                "peak_used_gb": 22.84
              },
              "gpu": {
                "avg_utilization_percent": 94.3,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10886.0,
                "max_temperature_c": 69.0
              }
            }
          },
          "math": {
            "prompt_type": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "runs": [
              {
                "tokens_generated": 256,
                "total_time_s": 5.1268,
                "first_token_latency_s": 0.0694,
                "tokens_per_second": 49.93,
                "memory_before_gb": 10.38,
                "memory_after_gb": 10.381,
                "memory_delta_gb": 0.001,
                "server_memory_gb": 9.525,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.83,
                "p90_inter_token_latency_ms": 20.32
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1401,
                "first_token_latency_s": 0.0949,
                "tokens_per_second": 49.8,
                "memory_before_gb": 10.381,
                "memory_after_gb": 10.678,
                "memory_delta_gb": 0.296,
                "server_memory_gb": 9.821,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.78,
                "p90_inter_token_latency_ms": 20.18
              },
              {
                "tokens_generated": 256,
                "total_time_s": 5.1531,
                "first_token_latency_s": 0.1055,
                "tokens_per_second": 49.68,
                "memory_before_gb": 10.678,
                "memory_after_gb": 10.974,
                "memory_delta_gb": 0.296,
                "server_memory_gb": 10.117,
                "error": null,
                "success": true,
                "inference_mode": "server",
                "avg_inter_token_latency_ms": 19.79,
                "p90_inter_token_latency_ms": 20.21
              }
            ],
            "summary": {
              "n_successful_runs": 3,
              "n_total_runs": 3,
              "avg_tokens_per_second": 49.8,
              "std_tokens_per_second": 0.1,
              "avg_first_token_latency_s": 0.0899,
              "avg_inter_token_latency_ms": 19.8,
              "avg_total_time_s": 5.14,
              "peak_memory_gb": 10.974,
              "stability": "stable"
            },
            "resource_usage": {
              "n_samples": 29,
              "duration_s": 15.318413496017456,
              "cpu": {
                "avg_percent": 8.3,
                "max_percent": 14.7,
                "min_percent": 0.0
              },
              "ram": {
                "avg_percent": 36.2,
                "max_percent": 36.7,
                "peak_used_gb": 23.45
              },
              "gpu": {
                "avg_utilization_percent": 91.9,
                "max_utilization_percent": 97.0,
                "peak_memory_mb": 10888.0,
                "max_temperature_c": 69.0
              }
            }
          }
        },
        "backend": {
          "backend": "cuda",
          "n_gpu_layers": -1,
          "details": "NVIDIA GPU détecté, utilisation de CUDA",
          "inference_mode": "server"
        },
        "comparison_table": [
          {
            "prompt_type_key": "general",
            "label": "Général / Connaissances",
            "icon": "📚",
            "tokens_per_second": 50.45,
            "first_token_latency_s": 0.0545,
            "inter_token_latency_ms": 19.69,
            "peak_memory_gb": 8.719,
            "stability": "stable"
          },
          {
            "prompt_type_key": "code",
            "label": "Code / Programmation",
            "icon": "💻",
            "tokens_per_second": 49.84,
            "first_token_latency_s": 0.0932,
            "inter_token_latency_ms": 19.78,
            "peak_memory_gb": 9.266,
            "stability": "stable"
          },
          {
            "prompt_type_key": "reasoning",
            "label": "Raisonnement / Logique",
            "icon": "🧠",
            "tokens_per_second": 49.82,
            "first_token_latency_s": 0.0889,
            "inter_token_latency_ms": 19.8,
            "peak_memory_gb": 9.85,
            "stability": "stable"
          },
          {
            "prompt_type_key": "creative",
            "label": "Créatif / Rédaction",
            "icon": "✍️",
            "tokens_per_second": 50.07,
            "first_token_latency_s": 0.0872,
            "inter_token_latency_ms": 19.71,
            "peak_memory_gb": 10.38,
            "stability": "stable"
          },
          {
            "prompt_type_key": "math",
            "label": "Mathématiques",
            "icon": "🔢",
            "tokens_per_second": 49.8,
            "first_token_latency_s": 0.0899,
            "inter_token_latency_ms": 19.8,
            "peak_memory_gb": 10.974,
            "stability": "stable"
          }
        ]
      }
    }
  }
}